"openapi": "3.1.0"
"info": {"title": "Gcore OpenAPI – Streaming API", "description": "This OpenAPI is an aggregated OpenAPI specification that unifies all Gcore products into a single file. It covers Cloud, CDN, DNS, WAAP, DDoS Protection, Object Storage, Streaming, and FastEdge services.", "version": "2025-06-16T15:19:34.893394+00:00"}
"servers": ["url": "https://api.gcore.com"]
paths:
  "/streaming/streams":
    "get": {"tags": ["Streams"], "summary": "Get all live streams", "description": "Returns a list of streams.", "operationId": "get_streams", "parameters": [{"name": "page", "in": "query", "description": "Query parameter. Use it to list the paginated content", "schema": {"type": "integer"}}, {"name": "with_broadcasts", "in": "query", "description": "Query parameter. Set to 1 to get details of the broadcasts associated with the stream", "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/stream"}}}}}}}
    "post": {"tags": ["Streams"], "summary": "Create live stream", "description": "Use this method to create a new live stream entity for broadcasting.\n  \nThe input in API may contain streams of different formats, including the most common ones RTMP, RTMPS, SRT, HLS. Note that multicast MPEG-TS over UDP and others are supported too, ask the Support Team please.\nFor ingestion, you can use both PUSH and PULL methods.\nAlso you can use the main and backup servers, which are geographically located in different locations. By default, any free ingest points in the world are used. Settings have been applied that deliver low-latency streams in the optimal way. If for some reason you need to set a fixed ingest point, or if you need to set the main and backup ingest points in the same region (for example, do not send streams outside the EU or US), then contact our Support Team.\n  \nThe output is HLS and MPEG-DASH with ABR. We transcode video for you by our cloud-based infrastructure. ABR ladder supports all qualities from SD to 8K HDR 60fps.\nAll our streams are Low Latency enabled. We support a delay of ±4 seconds for video streams by utilizing Common Media Application Format (CMAF) technology. So you obtain latency from the traditional 30-50 seconds to ±4 seconds only by default. If you need legacy non-low-latency HLS, then look at HLS MPEGTS delivery below.\n  \nYou have access to additional functions such as:\n- DVR\n- Recording\n- Live clipping\n- Restreaming\n- (soon) AI Automatic Speech Recognition for subtitles/captions generating\n  \nFor more information see specific API methods, and the Knowledge Base.\nTo organize streaming with ultra-low latency, look for WebRTC delivery in different section in the Knowledge Base.\n![HTML Overlays](https://demo-files.gvideo.io/apidocs/low-latency-football.gif)", "operationId": "post_streams_id", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/createStream"}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/stream"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified", "content": {}}}, "x-codegen-request-body-name": "body", "parameters": []}
  "/streaming/streams/{stream_id}":
    "get": {"tags": ["Streams"], "summary": "Get live stream", "description": "Returns stream details", "operationId": "get_streams_id", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID.   \nIDs of all created streams can be received via Get All Streams request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/stream"}}}}}}
    "delete": {"tags": ["Streams"], "summary": "Delete live stream", "operationId": "delete_streams_id", "description": "Delete a live stream.\n  \nAfter deleting the live stream, all associated data is deleted: settings, PUSH and PULL links, video playback links, etc.\nLive stream information is deleted permanently and irreversibly. Therefore, it is impossible to restore data and files after this.\nBut if the live had recordings, they continue to remain independent Video entities. The \"`stream_id`\" parameter will simply point to a stream that no longer exists.\n  \nPerhaps, instead of deleting, you may use the stream deactivation:\n```\nPATCH /videos/{`stream_id`}\n{ \"active\": false }\n```\nFor details, see the Product Documentation.", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID.   \nIDs of all created streams can be received via Get All Streams request", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Stream has been deleted successfully", "content": {}}}}
    "patch": {"tags": ["Streams"], "summary": "Change live stream", "description": "Updates stream settings", "operationId": "patch_streams_id", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID.   \nIDs of all created streams can be received via Get All Streams request", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"stream": {"$ref": "#/components/schemas/createStream"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/stream"}}}}}, "x-codegen-request-body-name": "body"}
  "/streaming/streams/{stream_id}/dvr_cleanup":
    "put": {"tags": ["Streams"], "summary": "Clear live stream DVR", "operationId": "put_streams_id_dvr_cleanup", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID.   \nIDs of all created streams can be received via Get All Streams request", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "DVR has been cleaned successfully", "content": {}}}}
  "/streaming/streams/{stream_id}/start_recording":
    "put": {"tags": ["Streams"], "summary": "Start recording", "description": "Start recording a stream.\n  \nStream will be recorded and automatically saved in our video hosting as a separate video VOD:\n- ID of the stream from which the recording was organized is added to \"`stream_id`\" field. You can find the video by that value later.\n- Title of the video is based on pattern \"Stream Record: {`stream_title`}, {`recording_end_time_utc`}\".\n- Recording start time is stored in \"`recording_started_at`\" field.\n- You can record the original stream or the transcoded one. Only the transcoded version will contain overlays. Set the appropriate recording method when creating the stream or before calling this recording method. Details in the \"`record_type`\" parameter of the stream.\n- If you have access to the premium feature of saving the original stream (so not just transcoded renditions), then the link to the original file will be in the \"`origin_url`\" field. Look at the description of the field how to use it.\nStream must be live for the recording to start, please check fields \"live\" and/or \"`backup_live`\". After the recording starts, field \"recording\" will switch to \"true\", and the recording duration in seconds will appear in the \"`recording_duration`\" field.\nPlease, keep in mind that recording doesn't start instantly, it takes ±3-7 seconds to initialize the process after executing this method.\n  \nStream recording stops when:\n- Explicit execution of the method /`stop_recording`. In this case, the file will be completely saved and closed. When you execute the stream recording method again, the recording will be made to a new video file.\n- When sending the stream stops on the client side, or stops accidentally. In this case, recording process is waiting for 10 seconds to resume recording:\n- If the stream resumes within that period, recording will continue to the same file.\n- After that period, the file will be completely saved and closed.\n- If the stream suddenly resumes after this period, the recording will go to a new file, because old file is closed already.\nPlease, also note that if you have long broadcasts, the recording will be cut into 4-hour videos. This value is fixed, but can be changed upon request to the Support Team.", "operationId": "put_streams_id_start_recording", "parameters": [{"name": "stream_id", "in": "path", "description": "ID of a stream to record", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Recording task was set successfully, but there are some actions you need to pay attention", "content": {"application/json": {"schema": {"type": "object", "properties": {"data": {"type": "object", "description": "Stream data", "properties": {"stream": {"$ref": "#/components/schemas/startRecordingStream"}}}, "warnings": {"type": "array", "description": "List of warnings received on starting recording process", "items": {"type": "object", "anyOf": ["$ref": "#/components/schemas/clientStorageAlmostExceededWarning"]}}, "errors": {"type": "array", "description": "List of errors received on attempt to start recording process", "items": {"type": "object"}}}}}}}, "204": {"description": "Recording task was set successfully, no extra actions needed"}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"Error text: No space for recording the stream.\" ] } }**   \n *Name* is a required parameter, so it must be specified"}}}
  "/streaming/streams/{stream_id}/stop_recording":
    "put": {"tags": ["Streams"], "summary": "Stop recording", "description": "Stop recording a stream.\n  \nStream must be in \"recording: true\" state for recording to be stopped.\n  \nIf there was a recording, the created video entity will be returned. Otherwise the response will be empty. Please see conditions and restrictions for recording a stream in the description of method /`start_recording`.", "operationId": "put_streams_id_stop_recording", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Recording is stopped. Returns the created video entity if there was a recording, or empty response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/searchVideo"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}}}
  "/streaming/streams/{stream_id}/clip_recording":
    "put": {"tags": ["Streams"], "summary": "Create clip", "description": "Create an instant clip from on-going live stream.\nInstant clips are applicable in cases where there is no time to wait for the broadcast to be completed and recorded. For example, for quickly cutting highlights in sport events, or cutting an important moment in the news or live performance.\n  \nInstant clip becomes available for viewing in the following formats:\n- HLS .m3u8,\n- MP4,\n- VOD in video hosting with a permanent link to watch video.\n![HTML Overlays](https://demo-files.gvideo.io/apidocs/`clip_recording_mp4_hls`.gif)\n  \n**Clip lifetime:**\nInstant clips are a copy of the stream, created from a live stream. They are stored in memory for a limited time, after which the clip ceases to exist and you will receive a 404 on the link.\nLimits that you should keep in mind:\n- The clip's lifespan is controlled by ```expiration``` parameter.\n- The default expiration value is 1 hour. The value can be set from 1 minute to 4 hours.\n- If you want a video for longer or permanent viewing, then create a regular VOD based on the clip. This way you can use the clip's link for the first time, and immediately after the transcoded version is ready, you can change by yourself it to a permanent link of VOD.\n- The clip becomes available only after it is completely copied from the live stream. So the clip will be available after ```start + duration``` exact time. If you try to request it before this time, the response will be error code 425 \"Too Early\".\n  \n**Cutting a clip from a source:**\nIn order to use clips recording feature, DVR must be enabled for a stream: \"`dvr_enabled`: true\".\nThe DVR serves as a source for creating clips:\n- By default live stream DVR is set to 1 hour (3600 seconds). You can create an instant clip using any segment of this time period by specifying the desired start time and duration.\n- If you create a clip, but the DVR expires, the clip will still exist for the specified time as a copy of the stream.\n  \n**Getting permanent VOD:**\nTo get permanent VOD version of a live clip use this parameter when making a request to create a clip: ```vod_required: true```.\nLater, when the clip is ready, grab ```video_id``` value from the response and query the video by regular GET /video/{id} method.", "operationId": "put_streams_id_clip_recording", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/clipPut"}}}}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/clipId"}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}}}
    "get": {"tags": ["Streams"], "summary": "Get clips", "description": "Get list of non expired instant clips for a stream.\n  \nYou can now use both MP4 just-in-time packager and HLS for all clips. Get URLs from \"`hls_master`\" and \"`mp4_master`\".\n  \n**How to download renditions of clips:**\nURLs contain \"master\" alias by default, which means maximum available quality from ABR set (based on height metadata). There is also possibility to access individual bitrates from ABR ladder. That works for both HLS and MP4. You can replace manually \"master\" to a value from renditions list in order to get exact bitrate/quality from the set.\nExample:\n- HLS 720p: ```https://CID.domain.com/rec/`111_1000`/`rec_d7bsli54p8n4_qsid42_master`.m3u8```\n- HLS 720p: ```https://CID.domain.com/rec/`111_1000`/`rec_d7bsli54p8n4_qsid42_media_1_360`.m3u8```\n- MP4 360p: ```https://CID.domain.com/rec/`111_1000`/`rec_d7bsli54p8n4_qsid42_master`.mp4```\n- MP4 360p: ```https://CID.domain.com/rec/`111_1000`/`rec_d7bsli54p8n4_qsid42_media_1_360`.mp4```", "operationId": "get_streams_id_clip_recording", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/clipId"}}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}}}
  "/streaming/streams/{stream_id}/overlays":
    "get": {"tags": ["Overlays"], "summary": "Get all overlays", "description": "Returns a list of HTML overlay widgets which are attached to a stream", "operationId": "get_overlays", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/overlayId"}}, "example": [{"id": 1, "stream_id": 12345, "url": "http://domain.tld/myoverlay1.html", "width": 120, "height": 40, "x": 10, "y": 10, "stretch": false, "created_at": "2023-09-20T00:01:01.000Z", "updated_at": "2023-10-01T12:01:01.000Z"}, {"id": 2, "stream_id": 12345, "url": "http://domain.tld/myoverlay2.html", "width": null, "height": null, "x": null, "y": null, "stretch": true, "created_at": "2023-09-20T00:01:01.000Z", "updated_at": "2023-10-01T12:01:01.000Z"}]}}}}}
    "post": {"tags": ["Overlays"], "summary": "Create overlays", "description": "\"Overlay\" is a live HTML widget, which rendered and inserted over the live stream.\n  \nThere are can be more that 1 overlay over a stream, which are small or stretched over full frame. Overlays can have transparent areas. Frequency of update is 1 FPS. Automatic size scaling for Adaptative Bitrate qualities is applied.\n![HTML Overlays](https://demo-files.gvideo.io/apidocs/`coffee_run_overlays`.gif)\n  \nHow to activate and use in simple steps:\n- Activate feature on your account, ask the Support Team\n- Set “`html_overlay`” attribute to \"true\" for a stream\n- Set array of overlays\n- Start or restart your stream again\n- Enjoy :-)\nFor the first time an overlay should be enabled **before** start pushing of a live stream. If you are pushing the stream already (stream is alive and you are activating overlay for the first time), then overlay will become active after restart pushing.\nOnce you activate the overlay for the stream for the first time, you can add, change, move, delete widgets on the fly even during a live stream with no affection on a result stream.\n  \nTech limits:\n- Max original stream resolution = FullHD.\n- It is necessary that all widgets must fit into the original frame of the source stream (width x height). If one of the widgets does not fit into the original frame, for example, goes 1 pixel beyond the frame, then all widgets will be hidden.\n- Attributes of overlays:\n- url – should be valid http/https url\n- 0 < width <= 1920\n- 0 < height <= 1080\n- 0 <= x < 1920\n- 0 <= y < 1080\n- stretch – stretch to full frame. Cannot be used with positioning attributes.\n- HTML widget can be access by HTTP 80 or HTTPS 443 ports.\n- HTML page code at the \"url\" link is read once when starting the stream only. For dynamically updating widgets, you must use either dynamic code via JavaScript or cause a page refresh via HTML meta tag <meta http-equiv=\"refresh\" content=\"N\">.\n- Widgets can contain scripts, but they must be lightweight and using small amount memory, CPU, and bandwidth. It is prohibited to run heavy scripts, create a heavy load on the network, or run other heavy modules. Such widgets can be stopped automatically, and the ability to insert widgets itself is banned.\n- If feature is disabled, you will receive HTTP code: 422. Error text: Feature disabled. Contact support to enable.\nPlease, pay attention to the content of HTML widges you use. If you don't trust them, then you shouldn't use them, as their result will be displayed in live stream to all users.\n**Will there be a widget in the recording?**\nRight now overlay widgets are sent to the end viewer in the HLS/DASH streams, but are not recorded due to technical limitations. We are working to ensure that widgets remain in the recordings as well. Follow the news.", "operationId": "post_overlays", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/overlayBody"}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/overlayId"}}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}, "x-codegen-request-body-name": "body"}
    "patch": {"tags": ["Overlays"], "summary": "Change overlays", "description": "Updates settings for set of overlays", "operationId": "patch_overlay", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/overlayPatchId"}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/overlayId"}}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}, "x-codegen-request-body-name": "body"}
  "/streaming/streams/{stream_id}/overlays/{overlay_id}":
    "get": {"tags": ["Overlays"], "summary": "Get an overlay", "description": "Returns overlay details", "operationId": "get_overlays_id", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}, {"name": "overlay_id", "in": "path", "description": "Overlay ID", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/overlayId"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
    "patch": {"tags": ["Overlays"], "summary": "Change an overlay", "description": "Updates overlay's settings", "operationId": "patch_overlay_id", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}, {"name": "overlay_id", "in": "path", "description": "Overlay ID", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/overlayPatch"}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/overlayId"}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}, "x-codegen-request-body-name": "body"}
    "delete": {"tags": ["Overlays"], "summary": "Delete an overlay", "operationId": "delete_overlays_id", "parameters": [{"name": "stream_id", "in": "path", "description": "Stream ID", "required": true, "schema": {"type": "integer"}}, {"name": "overlay_id", "in": "path", "description": "Overlay ID", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Overlay has been deleted successfully", "content": {}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/broadcasts":
    "get": {"tags": ["Broadcasts"], "summary": "Get all broadcasts", "description": "Note: Feature \"Broadcast\" is outdated, soon it will be replaced by \"Multicamera\".\n  \nReturns a list of broadcasts. Please see description in POST method.", "operationId": "get_broadcasts", "parameters": [{"name": "page", "in": "query", "description": "Query parameter. Use it to list the paginated content", "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/broadcast"}}}}}}}
    "post": {"tags": ["Broadcasts"], "summary": "Create broadcast", "description": "Broadcast entity is for setting up HTML video player, which serves to combine:\n- many live streams,\n- advertising,\n- and design in one config.\nIf you use other players or you get streams by direct .m3u8/.mpd links, then you will not need this entity.\n  \nScheme of \"broadcast\" entity using:\n![Scheme of \"broadcast\" using](https://demo-files.gvideo.io/apidocs/broadcasts.png)", "operationId": "post_broadcasts", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"broadcast": {"$ref": "#/components/schemas/createBroadcast"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified   \n **{ \"errors\": { \"status\": [ \"can't be blank\" ] } }**   \n *Status* is a required parameter, so it must be specified", "content": {}}}, "x-codegen-request-body-name": "body", "parameters": []}
  "/streaming/broadcasts/{broadcast_id}":
    "get": {"tags": ["Broadcasts"], "summary": "Get broadcast", "description": "Returns broadcast details", "operationId": "get_broadcasts_id", "parameters": [{"name": "broadcast_id", "in": "path", "description": "Broadcast ID.   \nIDs of all created broadcasts can be received via Get All Broadcasts request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/broadcast"}}}}}}
    "delete": {"tags": ["Broadcasts"], "summary": "Delete broadcast", "operationId": "delete_broadcasts_id", "parameters": [{"name": "broadcast_id", "in": "path", "description": "Broadcast ID.   \nIDs of all created broadcasts can be received via Get All Broadcasts request", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Broadcast has been deleted successfully", "content": {}}}}
    "patch": {"tags": ["Broadcasts"], "summary": "Change broadcast", "description": "Updates broadcast settings", "operationId": "patch_broadcasts_id", "parameters": [{"name": "broadcast_id", "in": "path", "description": "Broadcast ID.   \nIDs of all created broadcasts can be received via Get All Broadcasts request", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"broadcast": {"$ref": "#/components/schemas/createBroadcast"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/broadcast"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it can't be blank   \n **{ \"errors\": { \"status\": [ \"can't be blank\" ] } }**   \n *Status* is a required parameter, so it can't be blank", "content": {}}}, "x-codegen-request-body-name": "body"}
  "/streaming/broadcasts/{broadcast_id}/spectators":
    "get": {"tags": ["Broadcasts"], "summary": "Get broadcast spectators count", "description": "Returns number of simultaneous broadcast viewers at the current moment", "operationId": "get_broadcasts_spectators", "parameters": [{"name": "broadcast_id", "in": "path", "description": "Broadcast ID.   \nIDs of all created broadcasts can be received via Get All Broadcasts request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/broadcastSpectators"}}}}}}
  "/streaming/restreams":
    "get": {"tags": ["Restreams"], "summary": "Get all restreams", "description": "Returns a list of created restreams", "operationId": "get_restreams", "parameters": [{"name": "page", "in": "query", "description": "Query parameter. Use it to list the paginated content", "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/restream"}}}}}}}
    "post": {"tags": ["Restreams"], "summary": "Create restream", "operationId": "post_restreams", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"restream": {"$ref": "#/components/schemas/createRestream"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"stream\": [ \"must exist\" ] } }**   \n A required parameter *`stream_id`* wasn't specified or a stream with such ID hasn't been created.   \n **{ \"errors\": { \"stream\": [ \"does not belong to the same client \" ] } }**   \n A stream with specified ID belongs to another client. **{ \"errors\": { \"uri\": [ \"can't be blank \", \"is invalid \" ] } }**   \n A required parameter *uri* wasn't specified or the input is incorrect", "content": {}}}, "x-codegen-request-body-name": "body", "parameters": []}
  "/streaming/restreams/{restream_id}":
    "get": {"tags": ["Restreams"], "summary": "Get restream", "description": "Returns restream details", "operationId": "get_restreams_id", "parameters": [{"name": "restream_id", "in": "path", "description": "Restream ID.   \nIDs of all created restreams can be received via Get All Restreams request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/restream"}}}}}}
    "delete": {"tags": ["Restreams"], "summary": "Delete restream", "operationId": "delete_restreams_id", "parameters": [{"name": "restream_id", "in": "path", "description": "Restream ID.   \nIDs of all created restreams can be received via Get All Restreams request", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Restream has been deleted successfully", "content": {}}}}
    "patch": {"tags": ["Restreams"], "summary": "Change restream", "description": "Updates restream settings", "operationId": "patch_restreams_id", "parameters": [{"name": "restream_id", "in": "path", "description": "Restream ID.   \nIDs of all created restreams can be received via Get All Restreams request", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"restream": {"$ref": "#/components/schemas/createRestream"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/restream"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"stream\": [ \"must exist\" ] } }**   \n A stream with such ID was deleted or hasn't been created yet.   \n **{ \"errors\": { \"stream\": [ \"does not belong to the same client \" ] } }**   \n A stream with specified ID belongs to another client. **{ \"errors\": { \"uri\": [ \"can't be blank \", \"is invalid \" ] } }**   \n A *uri* parameter input is incorrect", "content": {}}}, "x-codegen-request-body-name": "body"}
  "/streaming/videos":
    "get": {"tags": ["Videos"], "summary": "Get list of videos", "description": "Returns a set of videos by the given criteria.", "operationId": "get_api_videos", "parameters": [{"name": "id", "in": "query", "description": "IDs of the videos to find. You can specify one or more identifiers separated by commas. Example, ?id=1,101,1001", "schema": {"type": "string"}}, {"name": "search", "in": "query", "description": "Aggregated search condition. If set, the video list is filtered by one combined SQL criterion:\n- id={s} OR slug={s} OR name like {s}\ni.e. \"/videos?search=1000\" returns list of videos where id=1000 or slug=1000 or name contains \"1000\".", "schema": {"type": "string"}}, {"name": "status", "in": "query", "description": "Use it to get videos filtered by their status. Possible values:\n- empty\n- pending\n- viewable\n- ready\n- error", "schema": {"type": "string"}}, {"name": "client_user_id", "in": "query", "description": "Find videos where \"`client_user_id`\" meta field is equal to the search value", "schema": {"type": "integer"}}, {"name": "stream_id", "in": "query", "description": "Find videos recorded from a specific stream, so for which \"`stream_id`\" field is equal to the search value", "schema": {"type": "integer"}}, {"name": "fields", "in": "query", "description": "Restriction to return only the specified attributes, instead of the entire dataset. Specify, if you need to get short response. The following fields are available for specifying: id, name, duration, status, `created_at`, `updated_at`, `hls_url`, screenshots, `converted_videos`, priority, `stream_id`. Example, ?fields=id,name,`hls_url`", "schema": {"type": "string"}}, {"name": "page", "in": "query", "description": "Page number. Use it to list the paginated content", "schema": {"type": "integer"}}, {"name": "per_page", "in": "query", "description": "Items per page number. Use it to list the paginated content", "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/searchVideo"}}}}}}}
    "post": {"tags": ["Videos"], "summary": "Create video", "description": "Use this method to create a new video entity.\n  \n**Methods of creating**\nTo upload the original video file to the server, there are several possible scenarios:\n- **Copy from another server** – If your video is accessable via \"http://\", \"https://\", or \"sftp://\" public link, then you can use this method to copy a file from an external server. Set ```origin_url``` parameter with the link to the original video file (i.e. \"https://domain.com/video.mp4\"). After method execution file will be uploaded and will be sent to transcoding automatically, you don't have to do anything else. Use extra field ```origin_http_headers``` if authorization is required on the external server.\n- **Direct upload from a local device** – If you need to upload video directly from your local device or from a mobile app, then use this method. Keep ```origin_url``` empty and use TUS protocol ([tus.io](https://tus.io)) to upload file. More details are here [\"Get TUS' upload\"](/docs/api-reference/videos/get-tus-parameters-for-direct-upload)\nAfter getting the video, it is processed through the queue. There are 2 priority criteria: global and local. Global is determined automatically by the system as converters are ready to get next video, so your videos rarely queue longer than usual (when you don't have a dedicated region). Local priority works at the level of your account and you have full control over it, look at \"priority\" attribute.\n  \n**AI processing**\nWhen uploading a video, it is possible to automatically create subtitles based on AI.\nRead more:\n- What is [\"AI Transcribe\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-asr-task).\n- If the option is enabled via ```auto_transcribe_audio_language: auto|```, then immediately after successful transcoding, an AI task will be automatically created for transcription.\n- If you need to translate subtitles from original language to any other, then AI-task of subtitles translation can be applied. Use ```auto_translate_subtitles_language: default|``` parameter for that. Also you can point several languages to translate to, then a separate subtitle will be generated for each specified language.\n- How to [\"add AI-generated subtitles to an exist video\"](https://api.gcore.com/docs/streaming/docs/api-reference/subtitles/add-subtitle).\nThe created AI-task(s) will be automatically executed, and result will also be automatically attached to this video as subtitle(s).\nPlease note that transcription is done automatically for all videos uploaded to our video hosting. If necessary, you can disable automatic creation of subtitles. If AI is disabled in your account, no AI functionality is called.\n  \n**Advanced Features**\nFor details on the requirements for incoming original files, and output video parameters after transcoding, refer to the Knowledge Base documentation. By default video will be transcoded according to the original resolution, and a quality ladder suitable for your original video will be applied. There is no automatic upscaling; the maximum quality is taken from the original video.\nIf you want to upload specific files not explicitly listed in requirements or wish to modify the standard quality ladder (i.e. decrease quality or add new non-standard qualities), then such customization is possible. Please reach out to us for assistance.\n  \nAdditionally, check the Knowledge Base for any supplementary information you may need.", "operationId": "post_api_videos", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"video": {"$ref": "#/components/schemas/createVideo"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/searchVideo"}}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified", "content": {}}},
      "x-codegen-request-body-name": "body", "parameters": []}
  "/streaming/videos/batch":
    "post": {"tags": ["Videos"], "summary": "Create videos in batch", "description": "Mass upload of your videos. Method is used to set the task of creating videos in the form of 1 aggregated request instead of a large number of single requests.\n  \nAn additional advantage is the ability to specify subtitles in the same request. Whereas for a normal single upload, subtitles are uploaded in separate requests.\n  \nAll videos in the request will be processed in queue in order of priority. Use \"priority\" attribute and look at general description in POST /videos method.\nLimits:\n- Batch max size = 500 videos.\n- Max body size (payload) = 64MB.\n- API connection timeout = 30 sec.", "operationId": "post_videos_batch", "parameters": [{"name": "fields", "in": "query", "description": "Restriction to return only the specified attributes, instead of the entire dataset. Specify, if you need to get short response. The following fields are available for specifying: id, name, duration, status, `created_at`, `updated_at`, `hls_url`, screenshots, `converted_videos`, priority. Example, ?fields=id,name,`hls_url`", "schema": {"type": "string"}, "required": false}], "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"videos": {"type": "array", "items": {"$ref": "#/components/schemas/createVideoBatch"}}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/searchVideo"}}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified", "content": {}}}}
  "/streaming/videos/names":
    "get": {"tags": ["Videos"], "summary": "Get names of videos", "description": "Returns names for specified video IDs", "operationId": "get_api_videos_names", "parameters": [{"name": "ids", "in": "query", "description": "Comma-separated set of video IDs. Example, ?ids=7,17", "style": "form", "explode": false, "schema": {"type": "array", "items": {"type": "integer"}}}], "responses": {"200": {"description": "Successful"}}}
  "/streaming/videos/{video_id}":
    "get": {"tags": ["Videos"], "summary": "Get video", "description": "Information about a video entity.\nContains all the data about the video: meta-data, data for streaming and renditions, static media data, data about original video.\nYou can use different methods to play video:\n- `iframe_url` – a URL to a built-in HTML video player with automatically configured video playback.\n- `hls_url` – a URLs to HLS TS .m3u8 manifest, which can be played in video players.\n- `hls_cmaf_url` – a URL to HLS CMAF .m3u8 manifest with chunks in fMP4 format, which can be played in most modern video players.\n- `dash_url` – a URL to MPEG-DASH .mpd manifest, which can be played in most modern video players. Preferable for Android and Windows devices.\n- `converted_videos`/`mp4_url` – a URL to MP4 file of specific rendition.\n![Video player](https://demo-files.gvideo.io/apidocs/coffee-run-player.jpg)", "operationId": "get_api_videos_id", "parameters": [{"name": "video_id", "in": "path", "description": "Video ID", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/searchVideo"}}}}}}
    "patch": {"tags": ["Videos"], "summary": "Change video", "description": "Changes parameters of the video to new values.\nIt's allowed to update only those public parameters that are described in POST method to create a new “video” entity. So it's not possible to change calculated parameters like \"id\", \"duration\", \"`hls_url`\", etc.\nExamples of changing:\n- Name: ``` { \"name\": \"new name of the video\" } ```\n- Move the video to a new directory: ``` { \"`directory_id`\": 200 }```\nPlease note that some parameters are used on initial step (before transcoding) only, so after transcoding there is no use in changing their values. For example, \"`origin_url`\" parameter is used for downloading an original file from a source and never used after transcoding; or \"priority\" parameter is used to set priority of processing and never used after transcoding.", "operationId": "patch_api_videos_id", "parameters": [{"name": "video_id", "in": "path", "description": "ID of the video to get", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/createVideo"}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/searchVideo"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified", "content": {}}}, "x-codegen-request-body-name": "body"}
    "delete": {"tags": ["Videos"], "summary": "Delete video", "description": "Operation to delete video entity.\n  \nWhen you delete a video, all transcoded qualities and all associated files such as subtitles and screenshots, as well as other data, are deleted from cloud storage.\nThe video is deleted permanently and irreversibly. Therefore, it is impossible to restore files after this.\n  \nFor detailed information and information on calculating your maximum monthly storage usage, please refer to the Product Documentation.", "operationId": "delete_api_videos_id", "parameters": [{"name": "video_id", "in": "path", "description": "Video ID.   \nIDs of all created videos can be received via Get All Videos request", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Video has been deleted successfully", "content": {}}}}
  "/streaming/videos/{video_id}/upload":
    "get": {"tags": ["Videos"], "summary": "Get TUS' parameters for direct upload", "description": "Use this method to get TUS' session parameters: hostname of the server to upload, secure token.\nThe general sequence of actions for a direct upload of a video is as follows:\n- Create video entity via POST method [\"Create video\"](/docs/api-reference/videos/create-video)\n- Get TUS' session parameters (you are here now)\n- Upload file via TUS client, choose your implementation on [tus.io](https://tus.io/implementations)\nFinal endpoint for uploading is constructed using the following template: \"https://{hostname}/upload/\". Also you have to provide token, `client_id`, `video_id` as metadata too.\nA short javascript example is shown below, based on tus-js-client. Variable \"data\" below is the result of this API request. Please, note that we support 2.x version only of tus-js-client.\n```\nuploads[data.video.id] = new tus.Upload(file, {\nendpoint: `https://${data.servers[0].hostname}/upload/`,\nmetadata: {\nfilename: data.video.name,\ntoken: data.token,\n`video_id`: data.video.id,\n`client_id`: data.video.`client_id`\n},\nonSuccess: function() {\n...\n}\n}\nuploads[data.video.id].start();\n```", "operationId": "get_api_videos_id_upload", "parameters": [{"name": "video_id", "in": "path", "description": "Video ID.   \nIDs of all created videos can be received via Get All Videos request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/getUrlAndTokenToUploadVideo"}}}}}}
  "/streaming/videos/{video_id}/subtitles":
    "get": {"tags": ["Subtitles"], "operationId": "get_api_videos_video_id_subtitles", "summary": "Get all subtitles", "description": "Method returns a list of all subtitles that are already attached to a video.", "parameters": [{"name": "video_id", "in": "path", "description": "ID of the video", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/subtitle"}}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}}}
    "post": {"tags": ["Subtitles"], "operationId": "post_api_videos_video_id_subtitles", "summary": "Add subtitle", "description": "Add new subtitle/captions to a video entity.\n  \n**Add already exist subtitles**\nSubtitles must be in one of the following formats:\n- SRT – SubRip Text is described on [wikipedia.org](https://en.wikipedia.org/wiki/SubRip#`SubRip_file_format`). Must start from integer for sequence number. Use calidators to check the subtitles, like [srt-validator](https://taoning2014.github.io/srt-validator-website/index.html).\n- WebVTT – Web Video Text Tracks Format is described on\n[developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/API/`WebVTT_API`). Must start from \"WEBVTT\" header. Use validators to check the subtitles, like [W3C](https://w3c.github.io/webvtt.js/parser.html).\nLanguage is 3-letter language code according to ISO-639-2 (bibliographic code). Specify language you need, or just look at our list in the attribute \"`audio_language`\" of section [\"AI Transcribe\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-asr-task).\nYou can add multiple subtitles in the same language, language uniqueness is not required.\nSize must be up to 5Mb.\n  \nThe update time for added or changed subtitles is up to 30 seconds. Just like videos, subtitles are cached, so it takes time to update the data.\n  \n**AI subtitles and transcribing**\nIt is also possible to automatically create subtitles based on AI.\nRead more:\n- What is [\"AI Transcribe\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-asr-task).\n- If the option is enabled via ```auto_transcribe_audio_language: auto|```, then immediately after successful transcoding, an AI task will be automatically created for transcription.\n- If you need to translate subtitles from original language to any other, then AI-task of subtitles translation can be applied. Use ```auto_translate_subtitles_language: default|``` parameter for that. Also you can point several languages to translate to, then a separate subtitle will be generated for each specified language.\nThe created AI-task(s) will be automatically executed, and result will also be automatically attached to this video as subtitle(s).\nIf AI is disabled in your account, you will receive code 422 in response.\n  \n**Where and how subtitles are displayed?**\nSubtitles are became available in the API response and in playback manifests.\nAll added subtitles are automatically inserted into the output manifest .m3u8. This way, subtitles become available to any player: our player, OS built-in, or other specialized ones. You don't need to do anything else.\nRead more information in the Knowledge Base.\nExample:\n```\n#EXT-X-MEDIA:TYPE=SUBTITLES,GROUP-ID=\"subs0\",NAME=\"English\",LANGUAGE=\"en\",AUTOSELECT=YES,URI=\"subs-0.m3u8\"\n```\n![Auto generated subtitles example](https://demo-files.gvideo.io/apidocs/captions.gif)", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/subtitleCreate"}}}, "required": true}, "parameters": [{"name": "video_id", "in": "path", "description": "ID of a video", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/subtitle"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/subtitleerror422"}}}}}}
  "/streaming/videos/{video_id}/subtitles/{id}":
    "get": {"tags": ["Subtitles"], "operationId": "get_api_videos_video_id_subtitles_id", "summary": "Get subtitle", "description": "Returns information about a specific subtitle for a video.", "parameters": [{"name": "id", "in": "path", "description": "ID of the subtitle", "required": true, "schema": {"type": "integer"}}, {"name": "video_id", "in": "path", "description": "ID of the video", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/subtitle"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}}}
    "patch": {"tags": ["Subtitles"], "operationId": "patch_api_videos_video_id_subtitles_id", "summary": "Change subtitle", "description": "Method to update subtitle of a video.\nYou can update all or only some of fields you need.\nIf you want to replace the text of subtitles (i.e. found a typo in the text, or the timing in the video changed), then:\n- download it using GET method,\n- change it in an external editor,\n- and update it using this PATCH method.\nJust like videos, subtitles are cached, so it takes time to update the data. See POST method for details.", "parameters": [{"name": "id", "in": "path", "description": "ID of a subtitle", "required": true, "schema": {"type": "integer"}}, {"name": "video_id", "in": "path", "description": "ID of a video", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/subtitleBodyPatch"}}}, "required": true}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/subtitlePatched"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/subtitleerror422"}}}}}}
    "delete": {"tags": ["Subtitles"], "operationId": "delete_api_videos_video_id_subtitles_id", "summary": "Delete subtitle", "description": "Delete specified video subtitle", "parameters": [{"name": "id", "in": "path", "description": "ID of a subtitle", "required": true, "schema": {"type": "integer"}}, {"name": "video_id", "in": "path", "description": "ID of a video", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "\\\"No content\\\", subtitle deleted successfully"}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}}}
  "/streaming/directories/tree":
    "get": {"tags": ["Directories"], "summary": "Get list of directories", "description": "Tree structure of directories.\nThis endpoint returns hierarchical data about directories in video hosting.", "operationId": "get_api_directories_tree", "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/directories_tree"}}}}}}
  "/streaming/directories/{directory_id}":
    "get": {"tags": ["Directories"], "summary": "Get directory", "description": "Complete directory structure with contents. The structure contains both subfolders and videos in a continuous list.", "operationId": "get_directories_id", "parameters": [{"name": "directory_id", "in": "path", "description": "Directory ID", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/directory"}}}}}}
    "patch": {"tags": ["Directories"], "summary": "Update directory", "description": "Change a directory name or move to another \"`parent_id`\".", "operationId": "patch_directories_id", "parameters": [{"name": "directory_id", "in": "path", "description": "Directory ID", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/directory_patch"}}}, "required": true}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/directory_base"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified", "content": {}}}, "x-codegen-request-body-name": "body"}
    "delete": {"tags": ["Directories"], "summary": "Delete directory", "description": "Delete a directory **and all entities inside**.\n  \nAfter its execution, all contents of the directory will be deleted recursively:\n- Subdirectories\n- Videos\nThe directory and contents are deleted permanently and irreversibly. Therefore, it is impossible to restore files after this.\nFor details, see the Product Documentation.", "operationId": "delete_directories_id", "parameters": [{"name": "directory_id", "in": "path", "description": "Directory ID", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Directory has been deleted successfully", "content": {}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}}}
  "/streaming/directories":
    "post": {"tags": ["Directories"], "summary": "Create directory", "description": "Use this method to create a new directory entity.", "operationId": "post_directories", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/directory_post"}}}, "required": true}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/directory_base"}}}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified", "content": {}}}, "x-codegen-request-body-name": "body", "parameters": []}
  "/streaming/playlists":
    "get": {"tags": ["Playlists"], "summary": "Get all playlists", "description": "Returns a list of created playlists", "operationId": "get_playlists", "parameters": [{"name": "page", "in": "query", "description": "Query parameter. Use it to list the paginated content", "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/playlist"}}}}}}}
    "post": {"tags": ["Playlists"], "summary": "Create playlist", "description": "Playlist is a curated collection of video content organized in a sequential manner.\nThis method offers several advantages and features that are typical of live streaming but with more control over the content. Here's how it works:\n- Playlist always consists only of static VOD videos you previously uploaded to the system.\n- Playlist is always played as a \"Live stream\" for end-users, so without the ability to fast forward the stream to the “future”. Manifest will contain chunks as for live stream too.\n- Playlist can be looped endlessly. In this case, all the videos in the list will be constantly repeated through the list.\n- Playlist can be programmed to be played at a specific time in the future. In that case, before the start time there will be empty manifest.\nYou can add new videos to the list, remove unnecessary videos, or change the order of videos in the list.\nBut please pay attention to when the video list changes, it is updated instantly on the server. This means that after saving the changed list, the playlist will be reloaded for all users and it will start plays from the very first element.\nMaximum video limit = 128 videos in a row.\n  \nExamples of usage:\n- Looped video playback\n- Scheduled playback\n**Looped video playback**\nIt can be used to simulate TV channel pre-programmed behaviour.\n- Selection: Choose a series of videos, such as TV show episodes, movies, tutorials, or any other relevant content.\n- Order: Arrange the selected videos in the desired sequence, much like setting a broadcast schedule.\n- Looping: Optionally, the playlist can be set to loop, replaying the sequence once it finishes to maintain a continuous stream.\nExample:\n```\nactive: true\nloop: true\nname: \"Playlist: TV channel 'The world around us' (Programmed broadcast for 24 hours)\"\n```\n**Scheduled playback**\nIt can be used to simulate live events such as virtual concerts, webinars, or any special broadcasts without the logistical challenges of an actual live stream.\n- Timing: Set specific start time, creating the illusion of a live broadcast schedule.\n- Selection: Choose a video or series of videos to be played at the specified time.\n- No Pauses: Unlike on-demand streaming where users can pause and skip, this emulated live stream runs continuously, mirroring the constraints of traditional live broadcasts.\n```\nactive: true\nloop: false\nname: \"Playlist: Webinar 'Onboarding for new employees on working with the corporate portal'\"\n`start_time`: \"2024-07-01T11:00:00Z\"\n```", "operationId": "post_playlists", "requestBody": {"$ref": "#/components/requestBodies/playlist"}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/playlist_post"}}}}}, "x-codegen-request-body-name": "body", "parameters": []}
  "/streaming/playlists/{playlist_id}":
    "get": {"tags": ["Playlists"], "summary": "Get playlist", "description": "Returns a playlist details", "operationId": "get_playlists_id", "parameters": [{"name": "playlist_id", "in": "path", "description": "Playlist ID.   \nIDs of all created playlists can be received via Get All Playlists request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/playlist"}}}}}}
    "delete": {"tags": ["Playlists"], "summary": "Delete playlist", "operationId": "delete_playlists_id", "parameters": [{"name": "playlist_id", "in": "path", "description": "Playlist ID.   \nIDs of all created playlists can be received via Get All Playlists request", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Playlist has been deleted successfully", "content": {}}}}
    "patch": {"tags": ["Playlists"], "summary": "Change playlist", "operationId": "patch_playlists_id", "parameters": [{"name": "playlist_id", "in": "path", "description": "Playlist ID.   \nIDs of all created playlists can be received via Get All Playlists request", "required": true, "schema": {"type": "integer"}}], "requestBody": {"$ref": "#/components/requestBodies/playlist"}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/playlist"}}}}}, "x-codegen-request-body-name": "body"}
  "/streaming/playlists/{playlist_id}/videos":
    "get": {"tags": ["Playlists"], "summary": "Get playlist videos", "description": "Shows ordered array of playlist videos", "operationId": "get_playlists_id_videos", "parameters": [{"name": "playlist_id", "in": "path", "description": "Playlist ID.   \nIDs of all created playlists can be received via Get All Playlists request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/video"}}}}}}}
  "/streaming/quality_sets":
    "get": {"tags": ["QualitySets"], "operationId": "get_qualitysets", "summary": "Get all quality sets", "description": "Method returns a list of all custom quality sets.\n  \nTranscoding is designed to minimize video file size while maintaining maximum visual quality. This is done so that the video can be delivered and viewed on any device, on any Internet connection, anywhere in the world. It's always a compromise between video/audio quality and delivery+viewing quality (QoE).\n  \nOur experts have selected the optimal parameters for transcoding, to ensure maximum video/audio quality with the best compression. Default quality sets are described in the [documentation](https://gcore.com/docs/streaming-platform/live-streams-and-videos-protocols-and-codecs/output-parameters-after-transcoding-bitrate-frame-rate-and-codecs). These values are the default for everyone. There is no need to configure anything additional.\nRead more about qiality in our blog [How we lowered the bitrate for live and VOD streaming by 32.5% without sacrificing quality](https://gcore.com/blog/how-we-lowered-the-bitrate-for-live-and-vod-streaming-by-32-5-without-sacrificing-quality/).\n![Quality ladder](https://demo-files.gvideo.io/apidocs/`encoding_ladder`.png)\nOnly for those cases when, in addition to the main parameters, it is necessary to use your own, then it is necessary to use custom quality sets.\nHow to use:\n1) By default custom quality set is empty – ``` { \"live\":[],\"vod\":[] } ```\n2) Request the use of custom quality sets from your manager or the Support Team.\n3) Please forward your requirements to us, since the parameters are set not by you, but by our engineers. (We are working to ensure that later you can create qualities by yourself.)\n4) Use the created quality sets through the these specified API methods.\nHere are some common parameters of quality settings:\n- Resolution: Determines the size of the video frame. I.e. 720p, 1080p, 4K, etc.\n- Bitrate: Refers to the amount of data processed per unit of time.\n- Codec: Codec used for transcoding can significantly affect quality. Popular codecs include H.264 (AVC), H.265 (HEVC), and AV1.\n- Frame Rate: Determines how many frames per second are displayed. Common frame rates include 24fps, 30fps, and 60fps.\n- Color Depth and Chroma Subsampling: These settings determine the accuracy of color representation in the video.\n- Audio Bitrate and Codec: Don't forget about the audio :) Bitrate and codec used for audio can also affect the overall quality.\nNote: Custom quality set is a paid feature.", "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/qualitysets"}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}}}
  "/streaming/quality_sets/default":
    "put": {"tags": ["QualitySets"], "operationId": "put_qualityset_default", "summary": "Set defaults for quality sets", "description": "Method to set default quality set for VOD and Live transcoding.\nFor changing default quality set, specify the ID of the custom quality set from the method GET /`quality_sets`.\nDefault value can be reverted to the system defaults (cleared) by setting ``` \"id\": null ```.\n  \nLive transcoding management:\n- You can specify quality set explicitly in POST /streams method, look at attribute \"`quality_set_id`\".\n- Otherwise these default values will be used by the system by default.\nVOD transcoding management:\n- You can specify quality set explicitly in POST /videos method, look at attribute \"`quality_set_id`\".\n- Otherwise these default values will be used by the system by default.", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/qualitysetDefault"}}}, "required": true}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/qualitysets"}}}}, "400": {"description": "One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/badrequest"}}}}}}
  "/streaming/players":
    "get": {"tags": ["Players"], "summary": "Get all players", "description": "Returns a list of created players", "operationId": "get_players", "parameters": [{"name": "page", "in": "query", "description": "Query parameter. Use it to list the paginated content", "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/player"}}}}}}}
    "post": {"tags": ["Players"], "summary": "Create player", "operationId": "post_players", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"player": {"$ref": "#/components/schemas/player"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {}}, "422": {"description": "Possible error messages:   \n **{ \"errors\": { \"name\": [ \"can't be blank\" ] } }**   \n *Name* is a required parameter, so it must be specified", "content": {}}}, "x-codegen-request-body-name": "body", "parameters": []}
  "/streaming/players/{player_id}":
    "get": {"tags": ["Players"], "summary": "Get player", "description": "Returns player settings", "operationId": "get_players_id", "parameters": [{"name": "player_id", "in": "path", "description": "Player ID.   \nIDs of all created players can be received via Get All Players request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/player"}}}}}}
    "delete": {"tags": ["Players"], "summary": "Delete player", "operationId": "delete_players_id", "parameters": [{"name": "player_id", "in": "path", "description": "Player ID.   \nIDs of all created players can be received via Get All Players request", "required": true, "schema": {"type": "integer"}}], "responses": {"204": {"description": "Player has been deleted successfully", "content": {}}}}
    "patch": {"tags": ["Players"], "summary": "Change player", "description": "Updates player settings", "operationId": "patch_players_id", "parameters": [{"name": "player_id", "in": "path", "description": "Player ID.   \nIDs of all created players can be received via Get All Players request", "required": true, "schema": {"type": "integer"}}], "requestBody": {"content": {"application/json": {"schema": {"type": "object", "properties": {"player": {"$ref": "#/components/schemas/player"}}}}}, "required": false}, "responses": {"200": {"description": "Successful", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/player"}}}}}, "x-codegen-request-body-name": "body"}
  "/streaming/players/{player_id}/preview":
    "get": {"tags": ["Players"], "summary": "Preview player", "description": "Returns player configuration in HTML", "operationId": "get_players_id_preview", "parameters": [{"name": "player_id", "in": "path", "description": "Player ID.   \nIDs of all created players can be received via Get All Players request", "required": true, "schema": {"type": "integer"}}], "responses": {"200": {"description": "Successful", "content": {}}}}
  "/streaming/ai/tasks":
    "post": {"summary": "Create AI-task", "description": "Creating an AI task.\nThis method allows you to create an AI task for VOD video processing:\n- ASR: Transcribe video\n- ASR: Translate subtitles\n- CM: Sports detection\n- CM: Weapon detection\n- CM: Not Safe For Work (NSFW) content detection\n- CM: Soft nudity detection\n- CM: Hard nudity detection\n- CM: Child Sexual Abuse Material (CSAM) detection\n- CM: Objects recognition (soon)\n![Auto generated subtitles example](https://demo-files.gvideo.io/apidocs/captions.gif)\nHow to use:\n- Create an AI task, specify algoritm to use\n- Get `task_id`\n- Check a result using ```.../ai/tasks/{`task_id`}``` method\nFor more detailed information, see the description of each method separately.\n  \n**AI Automatic Speech Recognition (ASR)**\nAI is instrumental in automatic video processing for subtitles creation by using Automatic Speech Recognition (ASR) technology to transcribe spoken words into text, which can then be translated into multiple languages for broader accessibility.\nCategories:\n- ```transcription``` – to create subtitles/captions from audio in the original language.\n- ```translation``` – to transate subtitles/captions from the original language to 99+ other languages.\nAI subtitle transcription and translation tools are highly efficient, processing large volumes of audio-visual content quickly and providing accurate transcriptions and translations with minimal human intervention. Additionally, AI-driven solutions can significantly reduce costs and turnaround times compared to traditional methods, making them an invaluable resource for content creators and broadcasters aiming to reach global audiences.\nExample response with positive result:\n```\n{\n\"status\": \"SUCCESS\",\n\"result\": {\n\"subtitles\": [\n{\n\"`start_time`\": \"00:00:00.031\",\n\"`end_time`\": \"00:00:03.831\",\n\"text\": \"Come on team, ...\"\n}, ...\n]\n\"vttContent\": \"WEBVTT\\n\\n1\\n00:00:00.031 --> 00:00:03.831\\nCome on team, ...\",\n\"`concatenated_text`\": \"Come on team, ...\",\n\"languages\": [ \"eng\" ],\n\"`speech_detected`\": true\n}\n}, ...\n}\n```\n  \n**AI Content Moderation (CM)**\nThe AI Content Moderation API offers a powerful solution for analyzing video content to detect various categories of inappropriate material. Leveraging state-of-the-art AI models, this API ensures real-time analysis and flagging of sensitive or restricted content types, making it an essential tool for platforms requiring stringent content moderation.\nCategories:\n- ```nsfw```: Quick algorithm to detect pornographic material, ensuring content is \"not-safe-for-work\" or normal.\n- ```hard_nudity```: Detailed analisys of video which detects explicit nudity involving genitalia.\n- ```soft_nudity```: Detailed video analysis that reveals both explicit and partial nudity, including the presence of male and female faces and other uncovered body parts.\n- ```child_pornography```: Detects child sexual abuse materials (CASM).\n- ```sport```: Recognizes various sporting activities.\n- ```weapon```: Identifies the presence of weapons in the video content.\nThe AI Content Moderation API is an invaluable tool for managing and controlling the type of content being shared or streamed on your platform. By implementing this API, you can ensure compliance with community guidelines and legal requirements, as well as provide a safer environment for your users.\nImportant notes:\n- It's allowed to analyse still images too (where applicable). Format of image: JPEG, PNG. In that case one image is the same as video of 1 second duration.\n- Not all frames in the video are used for analysis, but only key frames (Iframe). For example, if a key frame in a video is set every ±2 seconds, then detection will only occur at these timestamps. If an object appears and disappears between these time stamps, it will not be detected. We are working on a version to analyze more frames, please contact your manager or our support team to enable this method.\nExample response with positive result:\n```\n{\n\"status\": \"SUCCESS\",\n\"result\"\
        : {\n\"`nsfw_detected`\": true,\n\"`detection_results`\": [ \"nsfw\" ],\n\"frames\": [\n{\n\"label\": \"nsfw\",\n\"confidence\": 1.0,\n\"`frame_number`\": 24\n},...\n]\n}\n}\n```\n  \n**Additional information**\nBilling takes into account the duration of the analyzed video. Or the duration until the stop tag(where applicable), if the condition was triggered during the analysis.\n  \nThe heart of content moderation is AI, with additional services. They run on our own infrastructure, so the files/data are not transferred anywhere to external services. After processing, original files are also deleted from local storage of AI.\n  \nRead more detailed information about our solution, and architecture, and benefits in the knowledge base and blog.", "operationId": "post_ai_tasks_create", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_task"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified\n- Queue limit reached (100), try later\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}, "429": {"description": "Too many requests, try later", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}}}
    "get": {"summary": "Get list of AI tasks", "description": "Returns a list of previously created and processed AI tasks.\nThe list contains brief information about the task and its execution status. Data is displayed page by page.", "parameters": [{"name": "task_id", "in": "query", "description": "The task unique identifier to fiund", "required": false, "schema": {"type": "string", "format": "uuid"}}, {"name": "task_name", "in": "query", "description": "Type of the AI task. Reflects the original API method that was used to create the AI task.", "required": false, "schema": {"type": "string", "enum": ["transcription", "content-moderation"]}}, {"name": "status", "in": "query", "description": "Task status", "required": false, "schema": {"type": "string", "enum": ["FAILURE", "PENDING", "RECEIVED", "RETRY", "REVOKED", "STARTED", "SUCCESS"]}}, {"name": "date_created", "in": "query", "description": "Time when task was created. Datetime in ISO 8601 format.", "required": false, "schema": {"type": "string"}}, {"name": "ordering", "in": "query", "description": "Which field to use when ordering the results: `task_id`, status, and `task_name`.\nSorting is done in ascending (ASC) order.\nIf parameter is omitted then \"`started_at` DESC\" is used for ordering by default.", "required": false, "schema": {"type": "string", "enum": ["task_id", "status", "task_name", "started_at"]}}, {"name": "search", "in": "query", "description": "This is an field for combined text search in the following fields: `task_id`, `task_name`, status, and `task_data`.\nBoth full and partial searches are possible inside specified above fields. For example, you can filter tasks of a certain category, or tasks by a specific original file.\nExample:\n- To filter tasks of Content Moderation NSFW method: ```GET /streaming/ai/tasks?search=nsfw```\n- To filter tasks of processing video from a specific origin: ```GET /streaming/ai/tasks?search=s3.eu-west-1.amazonaws.com```", "required": false, "schema": {"type": "string"}}, {"name": "page", "in": "query", "required": false, "schema": {"type": "integer", "default": 1}, "description": "Page to view from task list, starting from 1"}, {"name": "limit", "in": "query", "description": "Number of results to return per page.", "required": false, "schema": {"type": "integer", "default": 10}}], "operationId": "get_ai_tasks_list", "tags": ["AI"], "responses": {"200": {"description": "List of AI tasks", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_tasks_list"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks#transcribe":
    "post": {"summary": "Create AI ASR task", "description": "Transcribing is the process of writing down the words you hear in an audio.\nOur solution allows you to transcribe audio from your video and get subtitles automatically. To do this, we use modern AI models.\nThe result:\n- Transcription – subtitles in the original language. I.e. audio is in English – subtitles are in English too, audio is in German – subtitles are in German too.\n- Translation – subtitles is translated from the original language to any other language.\n**How to use?**\n- Explicit call to this AI method. Applicapbe for any file stored with us or located on the Internet.\n- Standard video upload but with automatic subtitle generation. Look at [\"VOD uploading\"](https://api.gcore.com/docs/streaming/docs/api-reference/videos/create-video).\n**What language will the subtitles be in?**\nYou can specify the language explicitly, then it will be used to create subtitles: the source language in the audio, the resulting subtitle language.\nIf this is not set, the system will run auto language identification and the subtitles will be in the detected language. The method also works based on AI analysis.\nAdditionally, when this is not set, we also support recognition of alternate languages in the video (code-switching). For example, when in a video different speakers speak several languages, or when they switch from their native language to English and back. Thus when you have multiple languages in the video it is better to not specify an \"`audio_language`\" otherwise AI may force the system to recognize gibberish.\n  \n**What can be transcribed?**\nService uses additional methods to detect presence of speech in audio track, thus improving the detection of any human conversations:\n- Speech of one speaker,\n- Speech of several speakers,\n- Speech in different languages,\n- etc\nRestriction on music, lyrics most likely will not be created.\n  \n**What about translation?**\nIt is also possible to automatically translate from the original language to another you need.\nTo create a translation, specify the desired language explicitly in \"`subtitles_language`\" parameter. Otherwise, the subtitles will be in the original language. Translation into different languages should be done by creating separate tasks.\n![Auto generated subtitles example](https://demo-files.gvideo.io/apidocs/captions.gif)\nUse MP4 videos to process. This method is not tied to videos that are stored only in our video hosting (look at how get a link to MP4 rendition), so you can use links to any other external file with HTTP/HTTPS access.\n  \nFor now, only the first audio track can be processed; later this functionality will be improved to allow to use any.\nAlso, not all language pairs are currently supported. If a language pair is not supported for automatic translation, the task status will be FAILURE with description of the reason.\nExample: ```eng => uzb```.\nYou can request to add the language pair you need for automatic translation. Contact our support.\n  \nExample of modes to transcibe and/or translate:\n- Auto language detection: `{ \"url\":\"...\" }`\n- From German language explicitly : `{ \"url\":\"...\", \"`audio_language`\":\"ger\" }`\n- From any auto-detected to English language explicitly: `{ \"url\":\"...\", \"`subtitles_language`\":\"eng\" }`\n- From German language to English language explicitly: `{ \"url\":\"...\", \"`audio_language`\":\"ger\", \"`subtitles_language`\":\"eng\" }`\nExample of setting a task to process MP4 file (animated gif from above):\n```\ncurl -L 'https://api.gcore.com/streaming/ai/transcribe' \\\n-H 'Content-Type: application/json' \\\n-H 'Authorization: APIKey 1234$abcd...' \\\n-d '{\n\"url\": \"https://demo-files.gvideo.io/apidocs/spritefright-blender-cut30sec.mp4\"\n}'\n```\nAs described above, transcription is done automatically using AI. Therefore, the quality may differ from a manual transcription by a professional person. If this happens to you, then you can download subtitles and change them in an external editor.\n  \nTranscription and translation
        are 2 different AI tasks:\n- Transcription is set only for transcription.\n- Translation, if non-original languages are set for translation.\nBilling takes into account the duration of the analyzed original video.\n  \nThe heart for transcribing is the AI model Whisper from OpenAI, with additional optimisations and services. The AI models run on our own infrastructure, so the files/data are not transferred anywhere to external services. After processing, origianl files are also deleted from local storage of AI.\nRead more detailed information about our solution, and architecture, and benefits in the knowledge base and blog.", "operationId": "post_ai_transcribe", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_transcribe"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks#cm_nsfw":
    "post": {"summary": "Create AI CM:nsfw task", "description": "This algorithm allows to quickly detect inappropriate content, determining that the content is NSFW (\"Not Safe For Work\") or normal. Generic info about all capabilities and limits see in the generic [\"Content Moderation\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-task) method.\n**What is \"Not Safe For Work\"?**\nThe algorithm has recognized inappropriate content in a video and it might not be suitable to view in public places. The solution provides its confidence level (in percentage) of how sure it is that the content is NSFW, or it most likely does not contain any sexual or similar content.\nDifferent to soft-nudity-detection and hard-nudity-detection, this model will only check for sensitive material that can be considered not-safe-for-work.\n![AI Content Moderation: NSFW detection visual example](https://demo-files.gvideo.io/apidocs/nsfw-detection.gif)\n**How to use?**\nFrames within the specified video are analyzed.\nResponse will contain only frames for which the class nsfw is detected with a confidence of more than 50%.\nExample of detected NSFW:\n```\n{\n\"`nsfw_detected`\": true,\n\"`detection_results`\": [ \"nsfw\" ],\n\"frames\": [\n{\n\"label\": \"nsfw\",\n\"confidence\": 0.93,\n\"`frame_number`\": 1\n},..\n]\n}\n```\nExample of a response without detecting inappropriate content:\n```\n{\n\"`nsfw_detected`\": false,\n\"`detection_results`\": [],\n\"frames\": []\n}\n```\n  \nPlease note that the API only provides a set of data (json) about the objects found, so no video is generated. The demo video video (above ^) was specially created based on json from the API for visual demonstration and better perception of the possibilities.", "operationId": "post_ai_contentmoderation_nsfw", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_contentmoderation_nsfw"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks#cm_hard_nudity":
    "post": {"summary": "Create AI CM:hard_nudity task", "description": "This algorithm allows to detect explicit nudity of the human body (involving genitals) in a video. Generic info about all capabilities and limits see in the generic [\"Content Moderation\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-task) method.\n**What is Hard nudity detection?**\nThis method is often used to analyze UGC to determine whether videos can be published to all users, or to prohibit publication due to offensive and inappropriate content.\nObjects that can be detected:\n- `ANUS_EXPOSED`\n- `BUTTOCKS_EXPOSED`\n- `FEMALE_BREAST_EXPOSED`\n- `FEMALE_GENITALIA_EXPOSED`\n- `MALE_BREAST_EXPOSED`\n- `MALE_GENITALIA_EXPOSED`\nPlease note that the number of objects is less than in the soft-nudity-detection. This method works faster and better if only exposed body parts detection is required.\n![AI Content Moderation: hard nudity detection visual example](https://demo-files.gvideo.io/apidocs/`nudity_detection`.gif)\n**How to use?**\nThe information is returned with the video frame number where it was found and probability of the detected object.\nNudity detection is done using AI, so for each object a probability percentage is applied; objects with a probability of at least 30% are included in the response.\nVideo processing speed is approximately 1:5.\nExample of detected nudity or body parts:\n```\n{\n\"`nudity_detected`\": true,\n\"`detection_results`\": [ \"`MALE_GENITALIA_EXPOSED`\" ]\n\"frames\": [\n{\n\"confidence\": 0.75,\n\"`frame_number`\": 35,\n\"label\": \"`MALE_GENITALIA_EXPOSED`\"\n},...\n]\n}\n```\nExample response when nudity or body parts were not found:\n```\n{\n\"`nudity_detected`\": false,\n\"`detection_results`\": []\n\"frames\": []\n}\n```\nThere is no universal recipe under which a video can be considered unacceptable, since different services host different types of videos for different audiences: adult content, children's content, educational content, etc. You can determine the probability threshold at which you consider a video inappropriate. The easiest option is to run several of your videos and analyze the resulting probability coefficient.\n  \nSometimes a detected object at the beginning of the video immediately makes it clear that there is no need to further analyze the video. For such cases, you can use stop tags. Use parameter \"`stop_objects`\" to specify comma separated stop tags. It is also possible to specify % probability threshold value, above which the stop tag will be triggered.\n```\n{\n\"url\": \"...\",\n\"`stop_objects`\": \"`MALE_GENITALIA_EXPOSED`:0.8,`FEMALE_GENITALIA_EXPOSED`\"\n}\n```\n  \nPlease note that the API only provides a set of data (json) about the objects found, so no video is generated. The demo video video (above ^) was specially created based on json from the API for visual demonstration and better perception of the possibilities.", "operationId": "post_ai_contentmoderation_hardnudity", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_contentmoderation_hardnudity"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks#cm_soft_nudity":
    "post": {"summary": "Create AI CM:soft_nudity task", "description": "This algorithm allows to identify explicit nudity and partial nudity too (including the presence of male and female faces and other uncovered body parts) in a video. Generic info about all capabilities and limits see in the generic [\"Content Moderation\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-task) method.\n**What is Soft nudity detection?**\nThis method is often used to analyze UGC to determine whether videos can be published to all users, or to prohibit publication due to offensive and inappropriate content.\nObjects that can be detected:\n- `ANUS_COVERED`\n- `ANUS_EXPOSED`\n- `ARMPITS_COVERED`\n- `ARMPITS_EXPOSED`\n- `BELLY_COVERED`\n- `BELLY_EXPOSED`\n- `BUTTOCKS_COVERED`\n- `BUTTOCKS_EXPOSED`\n- `FACE_FEMALE`\n- `FACE_MALE`\n- `FEET_COVERED`\n- `FEET_EXPOSED`\n- `FEMALE_BREAST_COVERED`\n- `FEMALE_BREAST_EXPOSED`\n- `FEMALE_GENITALIA_COVERED`\n- `FEMALE_GENITALIA_EXPOSED`\n- `MALE_BREAST_EXPOSED`\n- `MALE_GENITALIA_EXPOSED`\nThis method allows you to identify faces and other body parts. Used to find complex combinations of what is happening in a video. Please note that the number of objects is more than in the hard-nudity-detection. The method is slower.\n![AI Content Moderation: hard nudity detection visual example](https://demo-files.gvideo.io/apidocs/`soft_nudity_detection`.gif)\n**How to use?**\nThe information is returned with the video frame number where it was found and probability of the detected object.\nNudity detection is done using AI, so for each object a probability percentage is applied; objects with a probability of at least 30% are included in the response.\nVideo processing speed is approximately 1:5.\nExample of detected nudity or body parts:\n```\n{\n\"`nudity_detected`\": true,\n\"`detection_results`\": [ \"`FACE_FEMALE`\", \"`BELLY_COVERED`\" ]\n\"frames\": [\n{\n\"confidence\": 0.82,\n\"`frame_number`\": 1,\n\"label\": \"`BELLY_COVERED`\"\n},...\n]\n}\n```\nExample response when nudity or body parts were not found:\n```\n{\n\"`nudity_detected`\": false,\n\"`detection_results`\": []\n\"frames\": []\n}\n```\nThere is no universal recipe under which a video can be considered unacceptable, since different services host different types of videos for different audiences: adult content, children's content, educational content, etc. You can determine the probability threshold at which you consider a video inappropriate. The easiest option is to run several of your videos and analyze the resulting probability coefficient.\n  \nSometimes a detected object at the beginning of the video immediately makes it clear that there is no need to further analyze the video. For such cases, you can use stop tags. Use parameter \"`stop_objects`\" to specify comma separated stop tags. It is also possible to specify % probability threshold value, above which the stop tag will be triggered.\n```\n{\n\"url\": \"...\",\n\"`stop_objects`\": \"`BELLY_COVERED`:0.9,`FEMALE_GENITALIA_COVERED`\"\n}\n```\n  \nPlease note that the API only provides a set of data (json) about the objects found, so no video is generated. The demo video video (above ^) was specially created based on json from the API for visual demonstration and better perception of the possibilities.", "operationId": "post_ai_contentmoderation_softnudity", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_contentmoderation_softnudity"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is
            advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks#cm_casm":
    "post": {"summary": "Create AI CM:CASM task", "description": "This algorithm allows to detect Child Sexual Abuse Materials (CASM). Generic info about all capabilities and limits see in the generic [\"Content Moderation\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-task) method.\n**What is Child Sexual Abuse Materials detection?**\nThis method is intended to prevent this type of content from being distributed over the Internet.\nFor child pornography detection we first run a \"`soft_nudity`\" and a \"`hard_nudity`\" tasks. If both methods indicate the presence of obscene content with the presence of children (child's face) in a frame, then such a video is marked as obscene. Frames are designated by the age category of identified children.\n**How to use?**\nThe information is returned with the number of the video frame in which the child's face was found and age.\nNudity detection is done using AI, so for each object a probability percentage is applied; objects with a probability of at least 30% are included in the response.\nVideo processing speed is approximately 1:10.\nExample of detected nudity:\n```\n{\n\"`child_pornography_detected`\": true,\n\"`detection_results`\": [ \"3-9\" ],\n\"frames\": [\n{\n\"`frame_number`\": 407,\n\"label\": \"`FACE_FEMALE`\",\n\"confidence\": 0.78,\n\"age\": \"3-9\",\n\"`age_confidence`\": 0.65\n}...\n]\n}\n```\nExample response without nudity found is empty array:\n```\n{\n\"`child_pornography_detected`\": false,\n\"`detection_results`\": [],\n\"frames\": []\n}\n```", "operationId": "post_ai_contentmoderation_casm", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_contentmoderation_casm"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks#cm_sport":
    "post": {"summary": "Create AI CM:sport task", "description": "This algorithm allows to identify various sporting activities in a video. Generic info about all capabilities and limits see in the generic [\"Content Moderation\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-task) method.\n**What is Sports activity detection?**\nSports activity detection by AI involves using machine learning and computer vision technologies to automatically identify, analyze, and interpret various activities within sports and generic videos. This can include detecting specific types, actions, events, and moments.\nThis model operates on a video sequence (and not on images as most of the used computer vision models). Make sure your video is at least 10-15 seconds long.\nSports activities can be detected:\n- archery\n- arm wrestling\n- playing badminton\n- playing baseball\n- basketball dunk\n- bowling\n- boxing punch\n- boxing speed bag\n- catching or throwing baseball\n- catching or throwing softball\n- cricket\n- curling\n- disc golfing\n- dodgeball\n- fencing\n- football\n- golf chipping\n- golf driving\n- golf putting\n- hitting baseball\n- hockey stop\n- ice skating\n- javelin throw\n- juggling soccer ball\n- kayaking\n- kicking field goal\n- kicking soccer ball\n- playing cricket\n- playing field hockey\n- playing ice hockey\n- playing kickball\n- playing lacrosse\n- playing ping pong\n- playing polo\n- playing squash or racquetball\n- playing tennis\n- playing volleyball\n- pole vault\n- riding a bike\n- riding or walking with horse\n- roller skating\n- rowing\n- sailing\n- shooting goal (soccer)\n- skateboarding\n- skiing\nUse cases:\n- Sports leagues and content creators can use AI to monitor UGC for unauthorized publications of their content. This can include detecting specific sporting events or activities that are part of copyrighted content.\n- Sports fans often miss live games and rely on highlight reels. AI can automatically detect key moments like goals, touchdowns, or game-winning shots in uploaded UGC videos and compile them into personalized highlight reels.\n![AI Content Moderation: sports activity detection visual example](https://demo-files.gvideo.io/apidocs/`sports_football_detection`.gif)\n**How to use?**\nThe information is returned with the video frame number where it was found and probability of the detected activty.\nIdentification is done using AI, so for each activity a probability percentage is applied; activities with a probability of at least 30% are included in the response.\nVideo processing speed is approximately 1:5.\nExample of detected sports activity:\n```\n{\n\"`sport_detected`\": true,\n\"`detection_results`\": [ \"shooting goal (soccer)\" ],\n\"frames\": [\n{\n\"label\": \"shooting goal (soccer)\",\n\"`frame_number`\": 98,\n\"confidence\": 0.99\n},...\n]\n}\n```\nExample response when sports activities were not found:\n```\n{\n\"`sport_detected`\": false,\n\"`detection_results`\": []\n\"frames\": []\n}\n```\n  \nPlease note that the API only provides a set of data (json) about the objects found, so no video is generated. The demo video video (above ^) was specially created based on json from the API for visual demonstration and better perception of the possibilities.", "operationId": "post_ai_contentmoderation_sport", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_contentmoderation_sport"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager
            or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks#cm_weapon":
    "post": {"summary": "Create AI CM:weapon task", "description": "This algorithm identifies the presence of weapons in a video. Generic info about all capabilities and limits see in the generic [\"Content Moderation\"](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-task) method.\n**What is Weapon detection?**\nAI-powered weapon detection in videos opens up numerous possibilities for enhancing security, content moderation, and user safety. Commonly used for scanning UGC for inappropriate content.\nUses cases:\n- Content Moderation: Implement weapon detection in social media or video sharing platforms to automatically flag and review harmful content.\n- Event Security: Use in surveillance systems at public events to enhance security measures through real-time threat detection.\n- Personal Safety Apps: Develop apps that allow users to scan their environment for potential threats using their mobile devices.\nWeapon types can be detected:\n- gun\n- heavy weapon\n- knife\n![AI Content Moderation: weapon detection visual example](https://demo-files.gvideo.io/apidocs/weapon-detection.gif)\n**How to use?**\nUsing our API you can integrate AI services that handle weapon detection into you business logic of website or mobile app. The information is returned with the video frame number where it was found and probability of the detected object.\nIdentification is done using AI, so for each object a probability percentage is applied; objects with a probability of at least 30% are included in the response.\nVideo processing speed is approximately 1:5.\nExample of a detected weapon:\n```\n{\n\"`weapon_detected`\": true,\n\"`detection_results`\": [ \"heavy-weapon\" ],\n\"frames\": [\n{\n\"label\": \"heavy-weapon\",\n\"`frame_number`\": 1,\n\"confidence\": 0.58\n},...\n]\n}\n```\nExample response when weapons were not found:\n```\n{\n\"`weapon_detected`\": false,\n\"`detection_results`\": []\n\"frames\": []\n}\n```\n  \nPlease note that the API only provides a set of data (json) about the objects found, so no video is generated. The demo video video (above ^) was specially created based on json from the API for visual demonstration and better perception of the possibilities.", "operationId": "post_ai_contentmoderation_weapon", "tags": ["AI"], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_contentmoderation_weapon"}}}}, "parameters": [], "responses": {"201": {"description": "Response returns ID of the created AI task. Using this AI task ID, you can check the status and get the video processing result. Look at GET /ai/results method.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response"}}}}, "400": {"description": "Bad request:\n- \"url\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks/{task_id}":
    "get": {"summary": "Get AI task result", "description": "This is the single method to check the execution status of an AI task, and obtain the result of any type of AI task.\nBased on the results of processing, the “result” field will contain an answer corresponding to the type of the initially created task:\n- ASR: Transcribe video\n- ASR: Translate subtitles\n- CM: Sports detection\n- CM: Weapon detection\n- CM: Not Safe For Work (NSFW) content detection\n- CM: Soft nudity detection\n- CM: Hard nudity detection\n- CM: Child Sexual Abuse Material (CSAM) detection\n- CM: Objects recognition (soon)\n- etc... (see other methods from /ai/ domain)\n  \nA queue is used to process videos. The waiting time depends on the total number of requests in the system, so sometimes you will have to wait.\nStatuses:\n- PENDING – the task is received and it is pending for available resources\n- STARTED – processing has started\n- SUCCESS – processing has completed successfully\n- FAILURE – processing failed\n- REVOKED – processing was cancelled by the user (or the system)\n- RETRY – the task execution failed due to internal reasons, the task is queued for re-execution (up to 3 times)\nEach task is processed in sub-stages, for example, original language is first determined in a video, and then transcription is performed. In such cases, the video processing status may change from \"STARTED\" to \"PENDING\", and back. This is due to waiting for resources for a specific processing sub-stage. In this case, the overall percentage \"progress\" of video processing will reflect the full picture.\n  \nThe result data is stored for 1 month, after which it is deleted.\n  \nFor billing conditions see the corresponding methods in /ai/ domain. The task is billed only after successful completion of the task and transition to \"SUCCESS\" status.", "parameters": [{"name": "task_id", "in": "path", "required": true, "schema": {"type": "string"}, "description": "ID of the task to get status of execution or result. This value is taken from the response of the initial AI task creation method."}], "operationId": "get_ai_task", "tags": ["AI"], "responses": {"200": {"description": "Result of AI task execution", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_results"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/notfound"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/tasks/{task_id}/cancel":
    "post": {"summary": "Cancel AI task", "description": "Stopping a previously launched AI-task without waiting for it to be fully completed.\nThe task will be moved to \"REVOKED\" status.", "parameters": [{"name": "task_id", "in": "path", "required": true, "schema": {"type": "string"}, "description": "ID of the task to be cancelled"}], "operationId": "post_ai_tasks_cancel", "tags": ["AI"], "responses": {"202": {"description": "Accepted. AI-task has been cancelled successfully", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response_result"}}}}, "400": {"description": "Bad request:\n- \"`task_id`\" is not specified,\n- Queue limit reached (100), try later,\n- etc", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streaming_error"}}}}, "404": {"description": "Not found", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response_error404"}}}}, "412": {"description": "Precondition Failed. AI-task can't be cancelled, because it is already cancelled or completed.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_post_response_error"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/ai/info":
    "get": {"summary": "Get AI Parameters", "description": "The method for revealing basic information and advanced underlying settings that are used when performing AI-tasks.\n  \nParameter sections:\n- \"`language_support`\" – AI Translation: check if a language pair is supported or not for AI translation.\n- this list will expand as new AI methods are added.\n  \n**`language_support`**\nThere are many languages available for transcription. But not all languages can be automatically translated to and from with good quality. In order to determine the availability of translation from the audio language to the desired subtitle language, you can use this type of \"`language_support`\".\nAI models are constantly improving, so this method can be used for dynamic determination.\nExample:\n```\ncurl -L 'https://api.gcore.com/streaming/ai/info?type=`language_support`&`audio_language`=eng&`subtitles_language`=fre'\n{ \"supported\": true }\n```\nToday we provide the following capabilities as below.\nThese are the 100 languages for which we support only transcription and translation to English.\nThe iso639-2b codes for these are: ```afr, sqi, amh, ara, hye, asm, aze, bak, eus, bel, ben, bos, bre, bul, mya, cat, zho, hrv, ces, dan, nld, eng, est, fao, fin, fra, glg, kat, deu, guj, hat, hau, haw, heb, hin, hun, isl, ind, ita, jpn, jav, kan, kaz, khm, kor, lao, lat, lav, lin, lit, ltz, mkd, mlg, msa, mal, mlt, mri, mar, ell, mon, nep, nor, nno, oci, pan, fas, pol, por, pus, ron, rus, san, srp, sna, snd, sin, slk, slv, som, spa, sun, swa, swe, tgl, tgk, tam, tat, tel, tha, bod, tur, tuk, ukr, urd, uzb, vie, cym, yid, yor```.\nThese are the 77 languages for which we support translation to other languages and translation to: ```afr, amh, ara, hye, asm, aze, eus, bel, ben, bos, bul, mya, cat, zho, hrv, ces, dan, nld, eng, est, fin, fra, glg, kat, deu, guj, heb, hin, hun, isl, ind, ita, jpn, jav, kan, kaz, khm, kor, lao, lav, lit, mkd, mal, mlt, mar, ell, mon, nep, nno, pan, fas, pol, por, pus, ron, rus, srp, sna, snd, slk, slv, som, spa, swa, swe, tgl, tgk, tam, tel, tha, tur, ukr, urd, vie, cym, yor```.", "parameters": [{"name": "type", "in": "query", "required": true, "schema": {"type": "string", "enum": ["language_support"]}, "description": "The parameters section for which parameters are requested"}, {"name": "audio_language", "in": "query", "required": false, "schema": {"type": "string"}, "description": "The source language from which the audio will be transcribed. Required when ```type=language_support```. Value is 3-letter language code according to ISO-639-2 (bibliographic code), (e.g., fre for French)."}, {"name": "subtitles_language", "in": "query", "required": false, "schema": {"type": "string"}, "description": "The target language the text will be translated into. If omitted, the API will return whether the `audio_language` is supported for transcription only, instead of translation. Value is 3-letter language code according to ISO-639-2 (bibliographic code), (e.g., fre for French)."}], "operationId": "get_ai_info", "tags": ["AI"], "responses": {"200": {"description": "Result of AI task execution", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_response_info_language"}}}}, "400": {"description": "Bad Request. One or more parameters were specified incorrectly, check the request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ai_badrequest"}}}}, "422": {"description": "This is advanced functionality; to enable it, contact your manager or the Support Team.", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/upgraderequired"}}}}}}
  "/streaming/statistics/cdn/uniqs":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getCDNUniqs", "summary": "Get unique viewers via CDN", "description": "Сounts the number of unique viewers of a video entity over CDN. It doesn't matter what player you used.\nAll unique viewers for the specified period of time are counted.\n**How does it work?**\nCalculating the number of unique viewers for a Live stream or VOD over CDN involves aggregating and analyzing various metrics to ensure each individual viewer is counted only once, regardless of how many times they connect or disconnect during the stream.\nThis method provides statistics for any video viewing by unique users, regardless of viewing method and a player you used. Thus, this is the most important difference from viewing through the built-in player:\n- In method /statistics/uniqs viewers of the built-in player are tracked only.\n- But this method tracks all viewers from everywhere.\nThis method is a combination of two other Live and VOD detailed methods. If you need detailed information, then see the methods: ```/statistics/stream/viewers``` and ```/statistics/vod/viewers```.\n**Data Processing and Deduplication**\nWe us IP Address & User-Agent combination. Each unique combination of IP address and User-Agent string might be considered a unique viewer.\nThis approach allows to accurately estimate the number of unique viewers. However, this is not foolproof due to NAT (Network Address Translation) and shared networks. Thus if your users fall under such restrictions, then the number of unique viewers may be higher than calculated.\n**Why is there no \"Unique Views\" method?**\nBased on CDN data, we can calculate the number of unique viewers only. Thus only your player will be able to count the number of unique views (clicks on the Play button) within the player session (i.e. how many times 1 unique viewer clicked the Play button within a unique player's session).", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Format is date time in ISO 8601.", "example": "2024-07-01T00:00:00Z", "schema": {"type": "string"}}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Format is date time in ISO 8601.", "example": "2024-07-31T23:59:59Z", "schema": {"type": "string"}}, {"name": "type", "in": "query", "required": false, "description": "Filter by entity's type", "example": "live", "schema": {"type": "string", "enum": ["live", "vod", "playlist"]}}, {"name": "id", "in": "query", "required": false, "description": "Filter by entity's id. Put ID of a Live stream, VOD or a playlist to be calculated.\nIf the value is omitted, then the calculation is done for all videos/streams of the specified type.\nWhen using this \"id\" parameter, be sure to specify the \"type\" parameter too. If you do not specify a type, the \"id\" will be ignored.", "schema": {"type": "string"}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/cdn_uniqs"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/views":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getViews", "summary": "Get views in built-in player", "description": "Get the number of views in the built-in player.\nAllows flexible grouping and filtering. The fields in the response depend on the selected grouping.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "type", "in": "query", "description": "filter by entity's type", "schema": {"type": "string", "enum": ["live", "vod", "playlist"]}}, {"name": "id", "in": "query", "description": "filter by entity's id", "schema": {"type": "string"}}, {"name": "event", "in": "query", "description": "filter by event's name", "schema": {"type": "string", "enum": ["init", "start", "watch"]}}, {"name": "host", "in": "query", "description": "filter by host", "schema": {"type": "string"}}, {"name": "country", "in": "query", "description": "filter by country", "schema": {"type": "string"}}, {"name": "group", "in": "query", "schema": {"description": "group=1,2,4 OR group=1&group=2&group=3", "type": "array", "items": {"type": "string", "enum": ["host", "os", "browser", "platform", "ip", "country", "event", "id"]}}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/views"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/uniqs":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getUniqs", "summary": "Get unique viewers in built-in player", "description": "Get the number of unique viewers in the built-in player.\nCounts the number of unique IPs.\nAllows flexible grouping and filtering. The fields in the response depend on the selected grouping.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "type", "in": "query", "description": "filter by entity's type", "schema": {"type": "string", "enum": ["live", "vod", "playlist"]}}, {"name": "id", "in": "query", "description": "filter by entity's id", "schema": {"type": "string"}}, {"name": "event", "in": "query", "description": "filter by event's name", "schema": {"type": "string", "enum": ["init", "start", "watch"]}}, {"name": "host", "in": "query", "description": "filter by host", "schema": {"type": "string"}}, {"name": "country", "in": "query", "description": "filter by country", "schema": {"type": "string"}}, {"name": "group", "in": "query", "schema": {"description": "group=1,2,4 OR group=1&group=2&group=3", "type": "array", "items": {"type": "string", "enum": ["date", "host", "os", "browser", "platform", "ip", "country", "event", "id"]}}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/uniqs"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/countries":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getCountries", "summary": "Get views by countries in built-in player", "description": "Aggregates the number of views grouping them by country in the built-in player.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/countries"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/regions":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getRegions", "summary": "Get views by regions in built-in player", "description": "Aggregates the number of views grouping them by regions of countries in the built-in player.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/regions"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/popular":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getPopular", "summary": "Get popular videos in built-in player", "description": "Aggregates the number of views for all client videos, grouping them by id and sort from most popular to less in the built-in player.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/popular"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/browsers":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getBrowsers", "summary": "Get browsers in built-in player", "description": "Aggregates the number of views for all client videos, grouping them by browsers in the built-in player.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/browsers"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/systems":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getSystems", "summary": "Get OSs in built-in player", "description": "Aggregates the number of views for all client videos, grouping them by device OSs in the built-in player.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/systems"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/embeds":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getEmbeds", "summary": "Get referer in built-in player", "description": "Aggregates the number of views, grouping them by \"referer\" URL of pages the built-in player was embeded to.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/embeds"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/hosts":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getHosts", "summary": "Get hosts in built-in player", "description": "Aggregates the number of views, grouping them by \"host\" domain name the built-in player was embeded to.\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/hosts"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/heatmap":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getHeatmap", "summary": "Get heatmap in built-in player", "description": "Shows information about what part of the video your viewers watched in the built-in player.\nThis way you can find out how many viewers started watching the video, and where they stopped watching instead of watching the entire video to the end.\nHas different format of response depends on query param \"type\".\nNote. This method operates only on data collected by the built-in HTML player. It will not show statistics if you are using another player or viewing in native OS players through direct .m3u8/.mpd/.mp4 links. For such cases, use calculations through CDN (look at method /statistics/cdn/uniqs) or statistics of the players you have chosen.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "type", "in": "query", "required": true, "description": "entity's type", "schema": {"type": "string", "enum": ["live", "vod", "playlist"]}}, {"name": "stream_id", "in": "query", "required": true, "description": "video streaming ID", "schema": {"type": "string"}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/heatmap"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/ffprobe":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getFfprobe", "description": "Aggregates data for the specified video stream in the specified time\ninterval. \"interval\" and \"units\" params working together to point\naggregation interval.\nYou can use this method to watch when stream was alive in time, and when it was off.", "parameters": [{"name": "date_from", "in": "query", "required": true, "description": "Start of time frame. Format is ISO 8601.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "date_to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "stream_id", "in": "query", "required": true, "description": "Stream ID", "schema": {"type": "string"}, "example": 12345}, {"name": "interval", "in": "query", "schema": {"type": "integer", "default": 10}, "example": 6000}, {"name": "units", "in": "query", "schema": {"type": "string", "enum": ["second", "minute", "hour", "day", "week", "month"], "default": "second"}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ffprobe"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/stream":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getStreamChart", "description": "Calculates time series of the transcoding minutes of all streams. The data is updated near realtime.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "granularity", "in": "query", "description": "specifies the time interval for grouping data", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streamstat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/max_stream":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getMaxStreamChart", "description": "Calculates time series of the amount of simultaneous streams. The data is updated near realtime.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "granularity", "in": "query", "description": "specifies the time interval for grouping data", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/max_stream"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/storage":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getStorageChart", "description": "Calculates time series of the size of disk space in bytes for all processed and undeleted client videos. The data is updated every 8 hours, it does not make sense to set the granulation less than 1 day.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "granularity", "in": "query", "description": "specifies the time interval for grouping data", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/storage"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/reseller/stream":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getResellerStreamChart", "description": "Calculates the time series of transcoding minutes of all streams of all subclients. The data is updated near realtime.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "granularity", "in": "query", "description": "specifies the time interval for grouping data", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d"]}}, {"name": "by_streams", "in": "query", "schema": {"type": "boolean", "default": false, "description": "indicates the format of the answer should be grouped by stream, else by client"}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streamstat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/meet":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getMeetChart", "description": "Calculates time series of the transcoding minutes of all streams. The data is updated near realtime.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "granularity", "in": "query", "description": "specifies the time interval for grouping data", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/meet"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/vod/storage_duration":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getVodStorageChart", "summary": "Get VOD storage volume", "description": "Calculates time series of the duration in minutes for all processed and undeleted client videos.\nThe data is updated every 8 hours, it does not make sense to set the granulation less than 1 day.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/vod_stat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/vod/transcoding_duration":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getVodTranscodingChart", "summary": "Get VOD transcoding duration", "description": "Calculates time series of the transcoding time in minutes for all processed client videos.\nThe data is updated every 8 hours, it does not make sense to set the granulation less than 1 day.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Datetime in ISO 8601 format.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/vod_stat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/vod/viewers":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getVodViewersChart", "summary": "Get VOD unique viewers via CDN", "description": "Calculates time series of unique viewers of VOD via CDN.\nThe statistics are taken from the data of CDN and work regardless of which player the views were made with.\nWorks similar to the method ```/statistics/cdn/uniqs```. But this allows you to break down data with the specified granularity: minutes, hours, days.\nBased on this method, a graph of unique views in the Customer Portal is built.\n![Unique viewers via CDN in Customer Portal](https://demo-files.gvideo.io/apidocs/`cdn_unique_viewers`.png)", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Format is date time in ISO 8601", "schema": {"type": "string"}, "example": "2024-07-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Format is date time in ISO 8601", "schema": {"type": "string"}, "example": "2024-07-31T23:59:59Z"}, {"name": "slug", "in": "query", "required": false, "description": "Filter by video \"slug\"", "schema": {"type": "string"}, "example": "F0000000MxmUA"}, {"name": "client_user_id", "in": "query", "required": false, "description": "Filter by user \"id\"", "schema": {"type": "integer"}, "example": 2400001}, {"name": "granularity", "in": "query", "description": "Specifies the time interval for grouping data", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/vod_stat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/vod/watching_duration":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getVodWatchingDurationChart", "summary": "Get VOD watching duration via CDN", "description": "Calculates a time series of video watching duration in minutes. Views of only those videos that meet the specified filters are summed up.\nThe statistics are taken from the data of CDN and work regardless of which player the views were made with.\nPlease note that the result for each time interval is in minutes, it is rounded to the nearest upper integer. You cannot use the sum of all intervals as the total watch time value; instead, use the /total method.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of the time period for counting minutes of watching. Format is date time in ISO 8601.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": false, "description": "End of time frame. Datetime in ISO 8601 format. If omitted, then the current time is taken.", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "slug", "in": "query", "required": false, "description": "Filter by video's slug", "schema": {"type": "string"}}, {"name": "client_user_id", "in": "query", "required": false, "description": "Filter by field \"`client_user_id`\"", "schema": {"type": "integer"}}, {"name": "granularity", "in": "query", "description": "Data is grouped by the specified time interval", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d", "1mo"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/vod_stat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/vod/watching_duration/total":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getVodWatchingDurationTotal", "summary": "Get VOD watching duration total via CDN", "description": "Calculates the total duration of video watching in minutes. Views of only those videos that meet the specified filters are summed up.\nThe statistics are taken from the data of CDN and work regardless of which player the views were made with.", "parameters": [{"name": "from", "in": "query", "required": false, "description": "Start of the time period for counting minutes of watching. Format is date time in ISO 8601. If omitted, the earliest start time for viewing is taken", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": false, "description": "End of time frame. Datetime in ISO 8601 format. If omitted, then the current time is taken", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "slug", "in": "query", "required": false, "description": "Filter by video's slug", "schema": {"type": "string"}}, {"name": "client_user_id", "in": "query", "required": false, "description": "Filter by field \"`client_user_id`\"", "schema": {"type": "integer"}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/vod_watching_total"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/stream/viewers":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getStreamViewersChart", "summary": "Get Live unique viewers via CDN", "description": "Calculates time series of unique viewers of Live streams via CDN.\nThe statistics are taken from the data of CDN and work regardless of which player the views were made with.\nWorks similar to the method ```/statistics/cdn/uniqs```. But this allows you to break down data with the specified granularity: minutes, hours, days.\nBased on this method, a graph of unique views in the Customer Portal is built.\n![Unique viewers via CDN in Customer Portal](https://demo-files.gvideo.io/apidocs/`cdn_unique_viewers`.png)", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of time frame. Format is date time in ISO 8601", "schema": {"type": "string"}, "example": "2024-07-01T00:00:00Z"}, {"name": "to", "in": "query", "required": true, "description": "End of time frame. Format is date time in ISO 8601", "schema": {"type": "string"}, "example": "2024-07-31T23:59:59Z"}, {"name": "stream_id", "in": "query", "required": false, "description": "Filter by \"`stream_id`\"", "schema": {"type": "integer"}}, {"name": "client_user_id", "in": "query", "required": false, "description": "Filter by \"`client_user_id`\"", "schema": {"type": "integer"}}, {"name": "granularity", "in": "query", "description": "Specifies the time interval for grouping data", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/stream_stat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/stream/watching_duration":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getStreamWatchingDurationChart", "summary": "Get Live watching duration via CDN", "description": "Calculates a time series of live streams watching duration in minutes. Views of only those streams that meet the specified filters are summed up.\nThe statistics are taken from the data of CDN and work regardless of which player the views were made with.\nPlease note that the result for each time interval is in minutes, it is rounded to the nearest upper integer. You cannot use the sum of all intervals as the total watch time value; instead, use the /total method.", "parameters": [{"name": "from", "in": "query", "required": true, "description": "Start of the time period for counting minutes of watching. Format is date time in ISO 8601.", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": false, "description": "End of time frame. Datetime in ISO 8601 format. If omitted, then the current time is taken", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "stream_id", "in": "query", "required": false, "description": "Filter by `stream_id`", "schema": {"type": "integer"}}, {"name": "client_user_id", "in": "query", "required": false, "description": "Filter by field \"`client_user_id`\"", "schema": {"type": "integer"}}, {"name": "granularity", "in": "query", "description": "Data is grouped by the specified time interval", "schema": {"type": "string", "default": "1h", "enum": ["1m", "5m", "15m", "1h", "1d", "1mo"]}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/streamstat"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
  "/streaming/statistics/stream/watching_duration/total":
    "get": {"tags": ["Streaming Statistics"], "operationId": "getStreamWatchingDurationTotal", "summary": "Get Live watching duration total via CDN", "description": "Calculates the total duration of live streams watching in minutes. Views of only those streams that meet the specified filters are summed up.\nThe statistics are taken from the data of CDN and work regardless of which player the views were made with.", "parameters": [{"name": "from", "in": "query", "required": false, "description": "Start of the time period for counting minutes of watching. Format is date time in ISO 8601. If omitted, the earliest start time for viewing is taken", "schema": {"type": "string"}, "example": "2024-05-01T00:00:00Z"}, {"name": "to", "in": "query", "required": false, "description": "End of time frame. Datetime in ISO 8601 format. If missed, then the current time is taken", "schema": {"type": "string"}, "example": "2024-05-31T23:59:59Z"}, {"name": "stream_id", "in": "query", "required": false, "description": "Filter by `stream_id`", "schema": {"type": "integer"}}, {"name": "client_user_id", "in": "query", "required": false, "description": "Filter by field \"`client_user_id`\"", "schema": {"type": "integer"}}], "responses": {"200": {"description": "OK", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/stream_watching_total"}}}}, "400": {"$ref": "#/components/responses/error_bad_request"}, "500": {"$ref": "#/components/responses/error_internal_server"}}}
tags:
- {"name": "AI", "x-displayName": "AI"}
- {"name": "Broadcasts", "x-displayName": "Broadcasts"}
- {"name": "Directories", "x-displayName": "Directories"}
- {"name": "Overlays", "x-displayName": "Overlays"}
- {"name": "Players", "x-displayName": "Players"}
- {"name": "Playlists", "x-displayName": "Playlists"}
- {"name": "QualitySets", "x-displayName": "QualitySets"}
- {"name": "Restreams", "x-displayName": "Restreams"}
- {"name": "Streaming Statistics", "x-displayName": "Statistics"}
- {"name": "Streams", "x-displayName": "Streams"}
- {"name": "Subtitles", "x-displayName": "Subtitles"}
- {"name": "Videos", "x-displayName": "Videos"}
x-tagGroups:
- {"name": "Streaming API", "tags": ["AI", "Broadcasts", "Directories", "Overlays", "Players", "Playlists", "QualitySets", "Restreams", "Streaming Statistics", "Streams", "Subtitles", "Videos"]}
security: ["APIKey": []]
components:
  schemas:
    stream: {"allOf": ["$ref": "#/components/schemas/createStream", {"properties": {"id": {"type": "integer", "description": "Stream ID"}, "live": {"type": "boolean", "description": "State of receiving and transcoding master stream from source by main server"}, "backup_live": {"type": "boolean", "description": "State of receiving and transcoding master stream from source by backup server if you pushing stream to \"`backup_push_url`\" or \"`backup_push_url_srt`\".\nDisplays the backup server status of PUSH method only. For PULL a \"live\" field is always used, even when origin servers are switched using round robin scheduling (look \"uri\" field for details)."}, "push_url": {"type": "string", "description": "URL to PUSH master stream to our main server using RTMP and RTMPS protocols.\nTo use RTMPS just manually change the protocol name from \"rtmp://\" to \"rtmps://\".\nIf you see an error like \"invalid SSL certificate\" try the following:\n- Make sure the push URL is correct, and it contains \"rtmps://\".\n- If the URL looks correct but you still get an SSL error, try specifying the port 443 in the URL. Here’s an example: rtmps://vp-push.domain.com:443/in/stream?key.\n- If you're still having trouble, then your encoder may not support RTMPS. Double-check the documentation for your encoder.\nFor advanced customers only: For your complexly distributed broadcast systems, it is also possible to additionally output an array of multi-regional ingestion points for manual selection from them. To activate this mode, contact your manager or the Support Team to activate the \"`multi_region_push_urls`\" attibute.\nBut if you clearly don’t understand why you need this, then it’s best to use the default single URL in the \"`push_url`\" attribute."}, "backup_push_url": {"type": "string", "description": "URL to PUSH master stream to our backup server using RTMP/S protocols. Servers for the main and backup streams are distributed geographically.\nMainly sending one stream to main server is enough. But if you need a backup stream, then this is the field to PUSH it.\nTo use RTMPS just manually change the protocol name from \"rtmp://\" to \"rtmps://\".\nThe backup logs are as follows: In PUSH mode, you initiate sending a stream from your machine. If your stream stops or breaks for some reason and it stops coming to the main server, then after 3-10 seconds of waiting the stream will turn off or the backup one will be automatically turned on, if you are pushing it too."}, "push_url_srt": {"type": "string", "description": "URL to PUSH master stream to our main server using SRT protocol.\nUse only 1 protocol of sending a master stream: either only SRT (`push_url_srt`), or only RTMP (`push_url`)."}, "backup_push_url_srt": {"type": "string", "description": "URL to PUSH master stream to our backup server using SRT protocol with the same logic of backup-streams"}, "push_url_whip": {"type": "string", "description": "URL to PUSH WebRTC stream to our server using WHIP protocol.\n  \n**WebRTC WHIP to LL-HLS and DASH**\nVideo Streaming supports WebRTC HTTP Ingest Protocol (WHIP), and WebRTC to HLS/DASH converter. As a result you can stream from web broswers natively.\n**WebRTC WHIP server**\nWe have dedicated WebRTC WHIP servers in our infrastructure. WebRTC WHIP server organizes both signaling and receives video data.\nSignaling is a term to describe communication between WebRTC endpoints, needed to initiate and maintain a session. WHIP is an open specification for a simple signaling protocol for starting WebRTC sessions in an outgoing direction, (i.e., streaming from your device).\n**WebRTC stream encoding parameters**\nAt least one video and audio track both must be present in the stream:\n- Video must be encoded with H.264.\n- Audio must be encoded with OPUS.\nNote. Specifically for WebRTC mode a method of constant transcoding with an initial given resolution is used. This means that if WebRTC in the end-user's browser decides to reduce the quality or resolution of the master stream (to let say 360p) due to restrictions on the end-user's device (network
                conditions, CPU consumption, etc.), the transcoder will still continue to transcode the reduced stream to the initial resolution (let say 1080p ABR). When the restrictions on the end-user's device are removed, quiality will improve again.\n**WebRTC WHIP Client**\nWe provide a convenient WebRTC WHIP library for working in browsers. You can use our library, or any other you prefer.\nSimple example of usage is here: https://stackblitz.com/edit/stackblitz-starters-j2r9ar?file=index.html\nAlso try to use the feature in UI of the Customer Portal. In the Streaming section inside the settings of a specific live stream, a new section \"Quick start in browser\" has been added.\nMore information in the Product Documentation on the website."}, "created_at": {"type": "string", "description": "Datetime of creation in ISO 8601"}, "started_at_primary": {"type": "string", "default": null, "description": "Time of the last session when main server started receiving the stream. Datetime in ISO 8601.\nThis means that if the stream was started 1 time, then here will be the time it was started. If the stream was started several times, or restarted on your side, then only the time of the last session is displayed here."}, "started_at_backup": {"type": "string", "default": null, "description": "Time of the last session when backup server started receiving the stream. Datetime in ISO 8601"}, "finished_at_primary": {"type": "string", "default": null, "description": "Time when the stream ended for the last time. Datetime in ISO 8601.\nAfter restarting the stream, this value is not reset to \"null\", and the time of the last/previous end is always displayed here. That is, when the start time is greater than the end time, it means the current session is still ongoing and the stream has not ended yet.\nIf you want to see all information about acitivity of the stream, you can get it from another method /streaming/statistics/ffprobe. This method shows aggregated activity parameters during a time, when stream was alive and transcoded. Also you can create graphs to see the activity. For example /streaming/statistics/ffprobe?interval=6000&`date_from`=2023-10-01&`date_to`=2023-10-11&`stream_id`=12345"}, "iframe_url": {"type": "string", "description": "A URL to a built-in HTML web player with the stream inside. It can be inserted into an iframe on your website and the video will automatically play in all browsers.\nPlease, remember that transcoded streams from \"`hls_cmaf_url`\" with .m3u8 at the end, and from \"`dash_url`\" with .mpd at the end are to be played inside video players only. For example: AVplayer on iOS, Exoplayer on Android, HTML web player in browser, etc. General bowsers like Chrome, Firefox, etc cannot play transcoded streams with .m3u8 and .mpd at the end. The only exception is Safari, which can only play Apple's HLS .m3u8 format with limits.\nThat's why you may need to use this HTML web player. Please, look Knowledge Base for details.\nExample of usage on a web page:\n<iframe width=\"560\" height=\"315\" src=\"https://player.gvideo.co/streams/`2675_201693`\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"}, "dash_url": {"type": "string", "description": "MPEG-DASH output. URL for transcoded result stream in MPEG-DASH format, with .mpd link.\nLow Latency support: YES.\nThis is CMAF-based MPEG-DASH stream. Encoder and packager dynamically assemble the video stream with fMP4 fragments. Chunks have ±2-4 seconds duration depending on the settings. All chunks for DASH are transferred through CDN using chunk transfer technology, which allows to use all the advantages of low latency delivery of DASH.\n- by default low latency is ±4 sec, because it's stable for almost all last-mile use cases.\n- and its possible to enable ±2 sec for DASH, just ask our Support Team.\n  \nRead more information in the article \"How Low Latency streaming works\" in the Knowledge Base."}, "hls_cmaf_url": {"type": "string", "description": "HLS output. URL for transcoded result of stream in HLS CMAF format, with .m3u8 link.\n
                Recommended for use for all HLS streams.\nLow Latency support: YES.\nThis is CMAF-based HLS stream. Encoder and packager dynamically assemble the video stream with fMP4 fragments. Chunks have ±2-4 seconds duration depending on the settings. All chunks for LL-HLS are transferred through CDN via dividing into parts (small segments ```#EXT-X-PART``` of 0.5-1.0 sec duration), which allows to use all the advantages of low latency delivery of LL-HLS.\n- by default low latency is ±5 sec, because it's stable for almost all last-mile use cases.\n- and its possible to enable ±3 sec for LL-HLS, just ask our Support Team.\n  \nIt is also possible to use modifier-attributes, which are described in the \"`hls_mpegts_url`\" field above.\nIf you need to get MPEGTS (.ts) chunks, look at the attribute \"`hls_mpegts_url`\".\n  \nRead more information in the article \"How Low Latency streaming works\" in the Knowledge Base."}, "hls_mpegts_url": {"type": "string", "description": "HLS output for legacy devices. URL for transcoded result of stream in HLS MPEGTS (.ts) format, with .m3u8 link.\nLow Latency support: NO.\nSome legacy devices or software may require MPEGTS (.ts) segments as a format for streaming, so we provide this options keeping backward compatibility with any of your existing workflows. For other cases it's better to use \"`hls_cmaf_url`\" instead.\nYou can use this legacy HLSv6 format based on MPEGTS segmenter in parallel with main HLS CMAF. Both formats are sharing same segments size, manifest length (DVR), etc.\n  \nIt is also possible to use additional modifier-attributes:\n- ?`get_duration_sec`=true – Adds the real segment duration in seconds to chunk requests. A chunk duration will be automatically added to a chunk request string with the \"`duration_sec`\" attribute. The value is an integer for a length multiple of whole seconds, or a fractional number separated by a dot for chunks that are not multiples of seconds. This attribute allows you to determine duration in seconds at the level of analyzing the logs of CDN requests and compare it with file size (so to use it in your analytics).\nSuch modifier attributes are applied manually and added to the link obtained from this field. I.e. ```?`get_duration_sec`=true```\nExample:\n`https://demo.gvideo.io/mpegts/`2675_19146`/`master_mpegts`.m3u8?`get_duration_sec`=true`\n```\n#EXTM3U\n#EXT-X-VERSION:6\n#EXT-X-TARGETDURATION:2\n...\n#EXTINF:2.000000,\n#EXT-X-PROGRAM-DATE-TIME:2025-08-14T08:15:00\nseg1.ts?`duration_sec`=2\n...\n```"}, "screenshot": {"type": "string", "description": "An instant screenshot taken from a live stream, and available as a static JPEG image. Resolution 1080 pixels wide, or less if the original stream has a lower resolution.\nScreenshot is taken every 10 seconds while the stream is live. This field contains a link to the last screenshot created by the system. Screenshot history is not stored, so if you need a series of screenshots over time, then download them."}, "transcoded_qualities": {"type": "array", "default": null, "items": {"type": "string"}, "description": "Array of qualities to which live stream is transcoded"}, "recording_duration": {"type": "number", "default": null, "description": "Duration of current recording in seconds if recording is enabled for the stream"}, "transcoding_speed": {"type": "number", "format": "decimal", "default": null, "description": "Speed of transcoding the stream.\nMainly it must be 1.0 for real-time processing. May be less than 1.0 if your stream has problems in delivery due to your local internet provider's conditions, or the stream does not meet stream inbound requirements. See Knowledge Base for details."}, "frame_rate": {"type": "number", "format": "decimal", "default": null, "description": "Current FPS of the original stream, if stream is transcoding"}, "video_height": {"type": "number", "default": null, "description": "Current height of frame of the original stream, if stream is transcoding"}, "video_width": {"type": "number", "default": null, "description": "Current width of frame of the original
                stream, if stream is transcoding"}, "html_overlays": {"type": "array", "default": [], "description": "Array of HTML overlay widgets", "items": {"allOf": ["$ref": "#/components/schemas/overlayId"]}}}, "example": {"id": 1080200, "pull": false, "uri": null, "live": true, "backup_live": false, "push_url": "rtmp://vp-push-anx2.domain.com/in/123?08cd54f0", "backup_push_url": "rtmp://vp-push-ed1.domain.com/in/123b?08cd54f0", "push_url_srt": "srt://vp-push-anx2-srt.domain.com:5001?streamid=123#08cd54f0", "backup_push_url_srt": "srt://vp-push-anx1-srt.domain.com:5001?streamid=123b#08cd54f0", "push_url_whip": "https://whip.gvideo.co/123_561041/whip", "created_at": "2023-10-01T00:01:01.000Z", "started_at_primary": "2023-10-03T00:01:01.000Z", "started_at_backup": null, "finished_at_primary": "2023-10-01T23:59:59.000Z", "dvr_duration": 3600, "iframe_url": "https://demo-public.gvideo.io/streams/2675_19146", "dash_url": "https://demo-public.gvideo.io/cmaf/2675_19146/index.mpd", "hls_cmaf_url": "https://demo-public.gvideo.io/cmaf/2675_19146/master.m3u8", "hls_mpegts_url": "https://demo-public.gvideo.io/mpegts/2675_19146/master_mpegts.m3u8", "screenshot": "https://static.gvideo.co/videoplatform/streams/2675/19146/screenshots/last.jpg", "recording_duration": 1500, "transcoded_qualities": ["audioa", "360pa", "480pa", "720pa", "1080pa"], "transcoding_speed": 1.01, "frame_rate": 29.97, "video_height": 1080, "video_width": 1920}}]}
    createStream: {"required": ["name"], "type": "object", "properties": {"name": {"type": "string", "description": "Stream name.\nOften used as a human-readable name for the stream, but can contain any text you wish. The values are not unique and may be repeated.\nExamples:\n- Conference in July\n- Stream #10003\n- Open-Air Camera #31 Backstage\n- 480fd499-2de2-4988-bc1a-a4eebe9818ee"}, "active": {"type": "boolean", "default": false, "description": "Stream switch between on and off. This is not an indicator of the status \"stream is receiving and it is LIVE\", but rather an on/off switch.\nWhen stream is switched off, there is no way to process it: PULL is deactivated and PUSH will return an error.\n- true – stream can be processed\n- false – stream is off, and cannot be processed"}, "pull": {"type": "boolean", "default": false, "description": "Indicates if stream is pulled from external server or not. Has two possible\nvalues:\n- true – stream is received by PULL method. Use this when need to get stream from external server by srt, rtmp\\s, hls, dash, etc protocols.\n- false – stream is received by PUSH method. Use this when need to send stream from end-device to our Streaming Platform, i.e. from mobile app or OBS Studio."}, "uri": {"type": "string", "default": null, "description": "When using PULL method, this is the URL to pull a stream from.\nYou can specify multiple addresses separated by a space (\" \"), so you can organize a backup plan. In this case, the specified addresses will be selected one by one using round robin scheduling. If the first address does not respond, then the next one in the list will be automatically requested, returning to the first and so on in a circle.\nAlso, if the sucessfully working stream stops sending data, then the next one will be selected according to the same scheme.\nAfter 24 hours of inactivity of your streams we will stop PULL-ing, and will switch \"active\" field to \"false\".\nPlease, note that this field is for PULL only, so is not suitable for PUSH. Look at fields \"`push_url`\" and \"`push_url_srt`\" from GET method."}, "low_latency_enabled": {"type": "boolean", "default": true, "description": "Deprecated, always returns \"true\".\nThe only exception is that the attribute can only be used by clients that have previously used the old stream format.\nThis method is outdated since we've made it easier to manage streams.\nFor your convenience, you no longer need to set this parameter at the stage of creating a stream. Now all streams are prepared in 2 formats simultaniously: Low Latency and Legacy. You can get the desired output format in the attributes \"`dash_url`\", \"`hls_cmaf_url`\", \"`hls_mpegts_url`\". Or use them all at once.\n---\nNote: Links /streams/{id}/playlist.m3u8 are depricated too. Use value of the \"`hls_mpegts_url`\" attribute instead."}, "auto_record": {"type": "boolean", "default": false, "description": "Enables autotomatic recording of the stream when it started. So you don't need to call recording manually.\nResult of recording is automatically added to video hosting. For details see the /streams/`start_recording` method and in knowledge base\nValues:\n- true – auto recording is enabled\n- false – auto recording is disabled"}, "dvr_enabled": {"type": "boolean", "default": false, "description": "Enables DVR for the stream:\n- true – DVR is enabled\n- false – DVR is disabled"}, "record_type": {"type": "string", "default": "origin", "enum": ["origin", "transcoded"], "description": "Method of recording a stream. Specifies the source from which the stream will be recorded: original or transcoded.\nTypes:\n- \"origin\" – To record RMTP/SRT/etc original clean media source.\n- \"transcoded\" – To record the output transcoded version of the stream, including overlays, texts, logos, etc. additional media layers."}, "hls_mpegts_endlist_tag": {"type": "boolean", "default": true, "description": "Add ```#EXT-X-ENDLIST``` tag within .m3u8 playlist after the last segment of a live stream when broadcast is ended."}, "dvr_duration": {"type": "integer", "default": 3600, "description": "DVR
            duration in seconds if DVR feature is enabled for the stream. So this is duration of how far the user can rewind the live stream.\n`dvr_duration` range is [30...14400].\nMaximum value is 4 hours = 14400 seconds. If you need more, ask the Support Team please."}, "cdn_id": {"type": "integer", "default": null, "description": "ID of custom CDN resource from which the content will be delivered (only if you know what you do)"}, "client_user_id": {"type": "integer", "default": null, "description": "Custom meta field for storing the Identifier in your system. We do not use this field in any way when processing the stream. Example: ```client_user_id = 1001```"}, "client_entity_data": {"type": "string", "maxLength": 4096, "default": null, "description": "Custom meta field designed to store your own extra information about a video entity: video source, video id, parameters, etc. We do not use this field in any way when processing the stream. You can store any data in any format (string, json, etc), saved as a text string. Example: ```client_entity_data = '{ \"`seq_id`\": \"1234567890\", \"name\": \"John Doe\", \"iat\": 1516239022 }'```"}, "html_overlay": {"type": "boolean", "default": false, "description": "Switch on mode to insert and display real-time HTML overlay widgets on top of live streams"}, "quality_set_id": {"type": "integer", "description": "Custom quality set ID for transcoding, if transcoding is required according to your conditions. Look at GET /`quality_sets` method", "default": null}, "broadcast_ids": {"type": "array", "default": [], "description": "IDs of broadcasts which will include this stream", "items": {"type": "integer"}}, "projection": {"type": "string", "default": "regular", "enum": ["regular", "vr360", "vr180", "vr360tb"], "description": "Visualization mode for 360° streams, how the stream is rendered in our web player ONLY. If you would like to show video 360° in an external video player, then use parameters of that video player.\nModes:\n- regular – regular “flat” stream\n- vr360 – display stream in 360° mode\n- vr180 – display stream in 180° mode\n- vr360tb – display stream in 3D 360° mode Top-Bottom"}}, "example": {"name": "Live stream by user e4d0f942-f35d", "pull": true, "active": true, "auto_record": false, "client_user_id": 1001, "uri": "srt://domain.com:5000/?streamid=12345", "html_overlay": false}}
    overlayId: {"allOf": ["$ref": "#/components/schemas/overlayBase", {"required": ["id", "url", "stream_id", "created_at", "updated_at"], "properties": {"id": {"type": "integer", "description": "ID of the overlay"}, "stream_id": {"type": "integer", "description": "ID of a stream to which it is attached"}, "created_at": {"type": "string", "description": "Datetime of creation in ISO 8601"}, "updated_at": {"type": "string", "description": "Datetime of last update in ISO 8601"}}, "example": {"id": 1, "stream_id": 12345, "url": "http://domain.com/myoverlay1.html", "width": 120, "height": 40, "x": 30, "y": 30, "stretch": false, "created_at": "2023-09-20T00:01:01.000Z", "updated_at": "2023-10-01T12:01:01.000Z"}}]}
    overlayBase: {"type": "object", "properties": {"url": {"type": "string", "description": "Valid http/https URL to an HTML page/widget"}, "width": {"type": "integer", "default": null, "description": "Width of the widget"}, "height": {"type": "integer", "default": null, "description": "Height of the widget"}, "x": {"type": "integer", "default": null, "description": "Coordinate of left upper corner"}, "y": {"type": "integer", "default": null, "description": "Coordinate of left upper corner"}, "stretch": {"type": "boolean", "default": false, "description": "Switch of auto scaling the widget. Must not be used as \"true\" simultaneously with the coordinate installation method (w, h, x, y)."}}}
    startRecordingStream: {"type": "object", "properties": {"id": {"type": "integer", "description": "Stream ID", "example": 123}, "client": {"type": "object", "properties": {"id": {"type": "integer", "description": "Client ID", "example": 777}, "storage_usage_mb": {"type": "number", "description": "Current storage usage for client by megabytes", "example": 2048}, "storage_limit_mb": {"type": "integer", "description": "Current storage limit for client by megabytes", "example": 10240}}}}}
    clientStorageAlmostExceededWarning: {"type": "object", "properties": {"key": {"type": "string", "description": "current warning key", "enum": ["client_storage_almost_exceeded"], "example": "client_storage_almost_exceeded"}, "source_object": {"type": "object", "description": "Warning source object", "properties": {"id": {"type": "integer", "description": "Client ID", "example": 918}, "type": {"type": "string", "description": "Object type (class)", "enum": ["client"], "example": "client"}}}, "meta": {"type": "object", "description": "storage usage state for client", "properties": {"storage_usage_mb": {"type": "number", "description": "Current storage usage for client by megabytes", "example": 1200}, "storage_limit_mb": {"type": "integer", "description": "Current storage limit for client by megabytes", "example": 2048}}}}}
    notfound: {"allOf": ["$ref": "#/components/schemas/badrequest", "example": {"status": 404, "error": "Not Found. Entity you are looking for was not found, please check the initial parameters"}]}
    badrequest: {"type": "object", "properties": {"status": {"type": "integer", "description": "Error number"}, "error": {"type": "string", "description": "Error message"}}, "example": {"status": 400, "error": "Bad Request response status code indicates that the server cannot or will not process the request due to something that is perceived to be a client error (for example, malformed request syntax, invalid request message framing, or deceptive request routing)."}}
    searchVideo: {"type": "object", "properties": {"id": {"type": "integer", "description": "Video ID"}, "name": {"type": "string", "description": "Title of the video.\nOften used as a human-readable name of the video, but can contain any text you wish. The values are not unique and may be repeated.\nExamples:\n- Educational training 2024-03-29\n- Series X S3E14, The empire strikes back\n- 480fd499-2de2-4988-bc1a-a4eebe9818ee"}, "description": {"type": "string", "description": "Additional text field for video description"}, "client_id": {"type": "integer", "description": "Client ID"}, "origin_size": {"type": "integer", "description": "Size of original file"}, "origin_video_duration": {"type": "integer", "description": "Original video duration in milliseconds"}, "origin_url": {"type": "string", "description": "URL to an original file from which the information for transcoding was taken.\nMay contain a link for scenarios:\n- If the video was downloaded from another origin\n- If the video is a recording of a live stream\n- Otherwise it is \"null\"\n**Copy from another server**\nURL to an original file that was downloaded. Look at method \"Copy from another server\" in POST /videos.\n**Recording of an original live stream**\nURL to the original non-transcoded stream recording with original quality, saved in MP4 format. File is created immediately after the completion of the stream recording. The stream from which the recording was made is reflected in \"`stream_id`\" field.\nCan be used for internal operations when a recording needs to be received faster than the transcoded versions are ready. But this version is not intended for public distribution. Views and downloads occur in the usual way, like viewing an MP4 rendition.\nThe MP4 file becomes available for downloading when the video entity \"status\" changes from \"new\" to \"pending\". The file is stored for 7 days, after which it will be automatically deleted.\nFormat of URL is ```/videos/_/`origin__`.mp4```\nWhere:\n- `````` – Encoding bitrate in Kbps.\n- `````` – Video height.\nThis is a premium feature, available only upon request through your manager or support team.", "default": null}, "duration": {"type": "integer", "description": "Video duration in milliseconds. May differ from \"`origin_video_duration`\" value if the video was uploaded with clipping through the parameters \"`clip_start_seconds`\" and \"`clip_duration_seconds`\""}, "slug": {"type": "string", "description": "A unique alphanumeric identifier used in public URLs to retrieve and view the video. It is unique for each video, generated randomly and set automatically by the system.\nFormat of usage in URL is \\*.../videos/{`client_id`}_{slug}/...\\*\nExample:\n- Player: /videos/`12345_neAq1bYZ2`\n- Manifest: /videos/`12345_neAq1bYZ2`/master.m3u8\n- Rendition: /videos/`12345_neAq1bYZ2`/`qid90v1_720`.mp4"}, "stream_id": {"type": "integer", "description": "If the video was saved from a stream, then ID of that stream is saved here"}, "recording_started_at": {"type": "string", "description": "If the video was saved from a stream, then start time of the stream recording is saved here. Format is date time in ISO 8601"}, "share_url": {"type": "string", "description": "Custom URL or iframe displayed in the link field when a user clicks on a sharing button in player. If empty, the link field and social network sharing is disabled"}, "poster": {"type": "string", "default": null, "description": "Poster is your own static image which can be displayed before the video begins playing. This is often a frame of the video or a custom title screen.\nField contains a link to your own uploaded image.\nAlso look at \"screenshot\" attribute."}, "poster_thumb": {"type": "string", "default": null, "description": "Field contains a link to minimized poster image. Original \"poster\" image is proportionally scaled to a size of 200 pixels in height."}, "screenshot": {"type": "string", "description": "A URL to the default screenshot is here. The image is selected from an array of all screenshots based on the “`screenshot_id`” attribute.
            If you use your own \"poster\", the link to it will be here too.\nOur video player uses this field to display the static image before the video starts playing. As soon as the user hits \"play\" the image will go away.\nIf you use your own external video player, then you can use the value of this field to set the poster/thumbnail in your player.\nExample:\n- `video_js`.poster: ```api.screenshot```\n- clappr.poster: ```api.screenshot```"}, "screenshots": {"type": "array", "items": {"type": "string"}, "description": "Array of auto generated screenshots from the video. By default 5 static screenshots are taken from different places in the video. If the video is short, there may be fewer screenshots.\nScreenshots are created automatically, so they may contain not very good frames from the video. To use your own image look at \"poster\" attribute."}, "screenshot_id": {"type": "integer", "description": "ID of auto generated screenshots to be used for default screenshot.\nCounting from 0. A value of -1 sets the \"screenshot\" attribute to the URL of your own image from the \"poster\" attribute.", "default": null}, "sprite": {"type": "string", "description": "Link to picture with video storyboard. Image in JPG format. The picture is a set of rectangles with frames from the video. Typically storyboard is used to show preview images when hovering the video's timeline.", "default": null}, "sprite_vtt": {"type": "string", "description": "Storyboard in VTT format. This format implies an explicit indication of the timing and frame area from a large sprite image.", "default": null}, "ad_id": {"type": "integer", "description": "ID of ad that should be shown. If empty the default ad is show. If there is no default ad, no ad is shownю"}, "hls_url": {"type": "string", "description": "A URL to a master playlist HLS (master.m3u8).\nChunk type will be selected automatically:\n- TS if your video was encoded to H264 only.\n- CMAF if your video was encoded additionally to H265 and/or AV1 codecs (as Apple does not support these codecs over MPEG TS, and they are not standardized in TS-container).\n  \nYou can also manually specify suffix-options that will allow you to change the manifest to your request:\n```/videos/{`client_id`}_{`video_slug`}/master[-cmaf][-min-N][-max-N][-img][-(h264|hevc|av1)].m3u8```\nList of suffix-options:\n- [-cmaf] – getting HLS CMAF version of the manifest. Look at the ```hls_cmaf_url``` field.\n- [-min-N] – ABR soft limitation of qualities from below.\n- [-max-N] – ABR soft limitation of qualities from above.\n- [-img] – Roku trick play: to add tiles directly into .m3u8 manifest. Read the Product Documentation for details.\n- [-(h264|hevc|av1) – Video codec soft limitation. Applicable if the video was transcoded into multiple codecs H264, H265 and AV1 at once, but you want to return just 1 video codec in a manifest. Read the Product Documentation for details.\nABR soft-limiting: Soft limitation of the list of qualities allows you to return not the entire list of transcoded qualities for a video, but only those you need. For more details look at the Product Documentation.\nFor example, the video is available in 7 qualities from 360p to 4K, but you want to return not more than 480p only due to the conditions of distribution of content to a specific end-user (i.e. free account):\n- To a generic ```.../master.m3u8``` manifest\n- Add a suffix-option to limit quality ```.../master-max-480.m3u8```\n- Add a suffix-option to limit quality and codec ```.../master-min-320-max-320-h264.m3u8```\n  \nCaution. Solely master.m3u8 (and master[-options].m3u8) is officially documented and intended for your use. Any additional internal manifests, sub-manifests, parameters, chunk names, file extensions, and related components are internal infrastructure entities. These may undergo modifications without prior notice, in any manner or form. It is strongly advised not to store them in your database or cache them on your end."}, "hls_cmaf_url": {"type": "string", "description": "A URL to a master playlist HLS (master-cmaf.m3u8) with CMAF-based
            chunks. Chunks are in fMP4 container. It's a code-agnostic container, which allows to use any like H264, H265, AV1, etc.\n  \nIt is possible to use the same suffix-options as described in the \"`hls_url`\" attribute.\n  \nCaution. Solely master.m3u8 (and master[-options].m3u8) is officially documented and intended for your use. Any additional internal manifests, sub-manifests, parameters, chunk names, file extensions, and related components are internal infrastructure entities. These may undergo modifications without prior notice, in any manner or form. It is strongly advised not to store them in your database or cache them on your end."}, "dash_url": {"type": "string", "description": "A URL to a master playlist MPEG-DASH (master.mpd) with CMAF or WebM based chunks.\nChunk type will be selected automatically for each quality:\n- CMAF for H264 and H265 codecs.\n- WebM for AV1 codec.\n  \nThis URL is a link to the main manifest. But you can also manually specify suffix-options that will allow you to change the manifest to your request:\n```/videos/{`client_id`}_{slug}/master[-min-N][-max-N][-(h264|hevc|av1)].mpd```\nList of suffix-options:\n- [-min-N] – ABR soft limitation of qualities from below.\n- [-max-N] – ABR soft limitation of qualities from above.\n- [-(h264|hevc|av1) – Video codec soft limitation. Applicable if the video was transcoded into multiple codecs H264, H265 and AV1 at once, but you want to return just 1 video codec in a manifest. Read the Product Documentation for details.\nRead more what is ABR soft-limiting in the \"`hls_url`\" field above.\n  \nCaution. Solely master.mpd is officially documented and intended for your use. Any additional internal manifests, sub-manifests, parameters, chunk names, file extensions, and related components are internal infrastructure entities. These may undergo modifications without prior notice, in any manner or form. It is strongly advised not to store them in your database or cache them on your end."}, "iframe_url": {"type": "string", "description": "A URL to a built-in HTML video player with the video inside. It can be inserted into an iframe on your website and the video will automatically play in all browsers.\nThe player can be opened or shared via this direct link. Also the video player can be integrated into your web pages using the Iframe tag.\nExample of usage on a web page:\n<iframe width=\"100%\" height=\"100%\" src=\"https://player.gvideo.co/videos/`2675_FnlHXwA16ZMxmUr`\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n  \nThere are some link modificators you can specify and add manually:\n- ?`no_low_latency` – player is forced to use non-low-latency streams HLS MPEG TS, instead of MPEG-DASH CMAF or HLS/LL-HLS CMAF.\n- ?t=(integer) – time to start playback from specified point in the video. Applicable for VOD only.\n- ?`sub_lang`=(language) – force subtitles to specific language (2 letters ISO 639 code of a language).\n- Read more in the Product Documentation."}, "custom_iframe_url": {"type": "string", "description": "Custom URL of Iframe for video player to be used in share panel in player. Auto generated Iframe URL provided by default."}, "views": {"type": "integer", "description": "Number of video views through the built-in HTML video player of the Streaming Platform only. This attribute does not count views from other external players and native OS players, so here may be less number of views than in \"`cdn_views`\"."}, "cdn_views": {"type": "integer", "description": "Total number of video views. It is calculated based on the analysis of all views, no matter in which player."}, "client_user_id": {"type": "integer", "default": null, "description": "Custom meta field for storing the Identifier in your system. We do not use this field in any way when processing the stream. Example: ```client_user_id = 1001```"}, "status": {"type": "string", "description": "Video processing status:\n- empty – initial status, when video-entity is created, but video-file has not yet been fully uploaded (TUS uploading, or downloading from
            an origin is not finished yet)\n- pending – video is in queue to be processed\n- viewable – video has at least 1 quality and can already be viewed via a link, but not all qualities are ready yet\n- ready – video is completely ready, available for viewing with all qualities\n- error – error while processing a video, look at \"error\" field", "enum": ["empty", "pending", "viewable", "ready", "error"]}, "error": {"type": "string", "description": "Video processing error text will be saved here if \"status: error\""}, "projection": {"type": "string", "description": "Regulates the video format:\n\n* **regular** — plays the video as usual\n* **vr360** — plays the video in 360 degree mode\n* **vr180** — plays the video in 180 degree mode\n* **vr360tb** — plays the video in 3D 360 degree mode Top-Bottom.\n\n  \n Default is regular"}, "converted_videos": {"type": "array", "description": "Array of data about each transcoded quality", "items": {"type": "object", "properties": {"id": {"type": "integer", "description": "ID of the converted file of the specific quality"}, "name": {"type": "string", "description": "Specific quality name"}, "width": {"type": "integer", "description": "Width in pixels of the converted video file of the specified quality. Can be ```null``` for audio files.", "default": null}, "height": {"type": "integer", "description": "Height in pixels of the converted video file of the specific quality. Can be ```null``` for audio-only files.", "default": null}, "size": {"type": "integer", "description": "Size in bytes of the converted file of the specific quality. Can be ```null``` until transcoding is fully completed.", "default": null}, "progress": {"type": "integer", "description": "Status of transcoding into the specific quality, from 0 to 100"}, "status": {"type": "string", "description": "Status of transcoding:\n- processing – video is being transcoded to this quality,\n- complete – quality is fully processed,\n- error – quality processing error, see parameter \"error\".", "enum": ["processing", "complete", "error"]}, "error": {"type": "string", "description": "Video processing error text in this quality", "default": null}, "mp4_url": {"type": "string", "description": "A URL to a rendition file of the specified quality in MP4 format for downloading.\n  \n**Download methods**\nFor each converted video, additional download endpoints are available under `converted_videos`/`mp4_urls`.\nAn MP4 download enpoints:\n- /videos/{`client_id`}_{slug}/{filename}.mp4\n- /videos/{`client_id`}_{slug}/{filename}.mp4/download\n- /videos/{`client_id`}_{slug}/{filename}.mp4/download={`custom_filename`}\nThe first option returns the file as is.\nThe following options respond with the header that directly tells browsers to download the file instead of playing it in the browser.\n```\nContent-Disposition: attachment\n```\nThe third option allows you to set a custom name for the file being downloaded. You can optionally specify a custom filename (just name excluding the .mp4 extension) using the download= query.\nFilename Constraints\n- Length: 1-255 characters\n- Must NOT include the .mp4 extension (it is added automatically)\n- Allowed characters: a-z, A-Z, 0-9, _(underscore), -(dash), .(dot)\n- First character cannot be .(dot)\nExample valid filenames: ```holiday2025```, ```_backup.final```, ```clip-v1.2```\n  \n**Default MP4 file name structure**\nLink to the file {filename} contains information about the encoding method using format:\n```___.mp4```\n- `````` – Internal quality identifier and file version. Please do not use it, can be changed at any time without any notice.\n- `````` – Codec name that was used to encode the video, or audio codec if it is an audio-only file.\n- `````` – Encoding bitrate in Kbps.\n- `````` – Video height, or word \"audio\" if it is an audio-only file.\nNote that this link format has been applied since 14.08.2024. If the video entity was uploaded earlier, links may have old simplified format.\nExample: ``` /videos/{`client_id`}_{slug}/`qid3567v1_h264_4050_1080`.mp4 ```\n  \n**Dynamic speed limiting**\n
                  This mode sets different limits for different users or for different types of content. The speed is adjusted based on requests with the “speed” and “buffer” arguments.\nExample: ``` ?speed=50k&buffer=500k ```\nRead more in Product Documentation in CDN section \"Network limits\".\n  \n**Secure token authentication (updated)**\nAccess to MP4 download links can be protected using secure tokens passed as query parameters. The token generation logic has been updated to allow fine-grained protection per file and bitrate.\nToken generation uses the entire MP4 path, which ensures the token only grants access to a specific quality/version of the video. This prevents unintended access to other bitrate versions of an ABR stream.\nToken Query Parameters:\n- token: The generated hash\n- expires: Expiration timestamp\n- speed: (optional) Speed limit in bytes/sec, or empty string\n- buffer: (optional) Buffer size in bytes, or empty string\nOptional (for IP-bound tokens):\n- ip: The user’s IP address\nExample: ``` ?md5=QX39c77lbQKvYgMMAvpyMQ&expires=1743167062 ```\nRead more in Product Documentation in Streaming section \"Protected temporarily link\".\n  \n**Examples**\n- Audio-only: ```https://demo-public.gvideo.io/videos/`2675_JNnccG5l97XPxsov`/`qid3585v1_aac_128_audio`.mp4```\n- Video: ```https://demo-public.gvideo.io/videos/`2675_3MlggU4xDb1Ssa5Y`/`qid3567v1_h264_4050_1080`.mp4/download```\n- Video with custom download filename: ```https://demo-public.gvideo.io/videos/`2675_XtMKxzJM6Xt7SBUV`/1080.mp4/download=`highlights_v1`.`1_2025`-05-30```"}}}}}, "example": {"id": 70575, "name": "Coffee Run - Blender Open Movie 720p", "description": "Fueled by caffeine, a young woman runs through the bittersweet memories of her past relationship. Coffee Run was directed by Hjalti Hjalmarsson and produced by the team at Blender Studio.", "client_id": 1, "duration": 184669, "slug": "xMbWbUSuvJ8NX2", "status": "ready", "origin_size": 29260881, "origin_video_duration": 184669, "origin_audio_channels": 2, "origin_height": 804, "origin_width": 1920, "created_at": "2024-06-13T12:15:25.000Z", "updated_at": "2024-07-26T15:30:50.000Z", "clip_start_seconds": null, "clip_duration_seconds": null, "hls_url": "https://demo-public.gvideo.io/videos/2675_FnlHXwA16ZMxmUr/master.m3u8", "hls_cmaf_url": "https://demo-public.gvideo.io/videos/2675_FnlHXwA16ZMxmUr/master-cmaf.m3u8", "dash_url": "https://demo-public.gvideo.io/videos/2675_FnlHXwA16ZMxmUr/master.mpd", "iframe_url": "https://player.gvideo.co/videos/2675_FnlHXwA16ZMxmUr", "poster": "https://static.gvideo.co/videoplatform/posters/video/2474723/f9767f071a8b7da51c64907f6a830cbb.webp", "poster_thumb": "https://static.gvideo.co/videoplatform/posters/video/2474723/thumb_f9767f071a8b7da51c64907f6a830cbb.webp", "screenshot": "https://static.gvideo.co/videoplatform/posters/video/2474723/f9767f071a8b7da51c64907f6a830cbb.webp", "screenshots": ["https://static.gvideo.co/videoplatform/thumbnails/2675/2474723_FnlHXwA16ZMxmUr.mp4_1_1080.jpg", "https://static.gvideo.co/videoplatform/thumbnails/2675/2474723_FnlHXwA16ZMxmUr.mp4_2_1080.jpg"], "screenshot_id": -1, "views": 2000001, "cdn_views": 30000003, "projection": "regular", "sprite": "https://static.gvideo.co/videoplatform/sprites/2675/2474723_FnlHXwA16ZMxmUr.mp4_sprite.jpg", "sprite_vtt": "1\n00:00:00,000 --> 00:00:05,000\nxMbWbUSuvJ8NX2_sprite.jpg#xywh=0,0,100,42\n\n2\n00:00:05,000 --> 00:00:10,000\nxMbWbUSuvJ8NX2_sprite.jpg#xywh=100,0,100,42\n\n3\n00:00:10,000 --> 00:00:15,000\nxMbWbUSuvJ8NX2_sprite.jpg#xywh=200,0,100,42\n", "converted_videos": [{"id": 25889825, "name": "vod720p", "width": 1719, "height": 720, "size": 29929272, "progress": 100, "status": "complete", "mp4_url": "https://demo-public.gvideo.io/videos/2675_p0jh5kwH6F0ff2H6/qid3570v1_h264_1267_720.mp4"}, {"id": 25889828, "name": "vod480p", "width": 1146, "height": 480, "size": 20827007, "progress": 100, "status": "complete", "mp4_url": "https://demo-public.gvideo.io/videos/2675_p0jh5kwH6F0ff2H6/qid3573v1_h264_800_480.mp4"}]}}
    clipPut: {"allOf": ["properties": {"vod_required": {"type": "boolean", "description": "Indicates if video needs to be stored also as permanent VOD", "default": true}}, "$ref": "#/components/schemas/clipBase"]}
    clipBase: {"type": "object", "required": ["duration"], "properties": {"start": {"type": "integer", "description": "Starting point of the segment to cut.\nUnix timestamp in seconds, absolute value.\nExample: ```24.05.2024 14:00:00 (GMT) is Unix timestamp = 1716559200```\nIf a value from the past is specified, it is used as the starting point for the segment to cut. If the value is omitted, then clip will start from now.", "default": null}, "duration": {"type": "integer", "description": "Requested segment duration in seconds to be cut.\nPlease, note that cutting is based on the idea of instantly creating a clip, instead of precise timing. So final segment may be:\n- Less than the specified value if there is less data in the DVR than the requested segment.\n- Greater than the specified value, because segment is aligned to the first and last key frames of already stored fragment in DVR, this way -1 and +1 chunks can be added to left and right.\nDuration of cutted segment cannot be greater than DVR duration for this stream. Therefore, to change the maximum, use \"`dvr_duration`\" parameter of this stream."}, "expiration": {"type": "integer", "description": "Expire time of the clip via a public link.\nUnix timestamp in seconds, absolute value.\nThis is the time how long the instant clip will be stored in the server memory and can be accessed via public HLS/MP4 links. Download and/or use the instant clip before this time expires.\nAfter the time has expired, the clip is deleted from memory and is no longer available via the link. You need to create a new segment, or use ```vod_required: true``` attribute.\nIf value is omitted, then expiration is counted as +3600 seconds (1 hour) to the end of the clip (i.e. ```unix timestamp =  +  + 3600```).\nAllowed range: 1m <= expiration <= 4h.\nExample: ```24.05.2024 14:00:00 (GMT) + 60 seconds of duration + 3600 seconds of expiration = 24.05.2024 15:01:00 (GMT) is Unix timestamp = 1716562860```", "default": null}}, "example": {"start": 1716559200, "duration": 60, "expiration": 1716562860}}
    clipId: {"allOf": [{"required": ["id"], "properties": {"id": {"type": "string", "description": "ID of the clip"}, "created_at": {"type": "string", "description": "Creation date and time. Format is date time in ISO 8601"}, "vod_required": {"type": "boolean", "description": "Indicates if video needs to be stored as VOD", "default": true}, "video_id": {"type": "integer", "description": "ID of the created video if `vod_required`=true", "default": null}, "renditions": {"type": "array", "items": {"type": "string"}, "description": "List of available rendition heights"}, "hls_master": {"type": "string", "description": "Link to HLS .m3u8 with immediate clip. The link retains same adaptive bitrate as in the stream for end viewers. For additional restrictions, see the description of parameter \"`mp4_master`\"."}, "mp4_master": {"type": "string", "description": "Link to MP4 with immediate clip. The link points to max rendition quality.\nRequest of the URL can return:\n- 200 OK – if the clip exists.\n- 404 Not found – if the clip did not exist or has already ceased to exist.\n- 425 Too early – if recording is on-going now. The file is incomplete and will be accessible after start+duration time will come."}}, "example": {"id": "d7bsli54p8n4", "created_at": "2024-01-05T20:15:00.000Z", "vod_required": true, "video_id": 459857, "renditions": ["media_1_360", "media_2_468", "media_3_720", "media_4_1080"], "hls_master": "https://CID.domain.com/rec/12345_330031/rec_d7bsli54p8n4_qsid42_master.m3u8", "mp4_master": "https://CID.domain.com/rec/12345_330031/rec_d7bsli54p8n4_qsid42_master.mp4"}}, "$ref": "#/components/schemas/clipBase"]}
    overlayBody: {"allOf": ["$ref": "#/components/schemas/overlayBase", {"required": ["url"], "example": {"url": "http://domain.com/myoverlay1.html", "width": 120, "height": 40, "x": 30, "y": 30, "stretch": false}}]}
    upgraderequired: {"type": "object", "properties": {"error": {"type": "string", "description": "This is advanced functionality; to enable it, contact your manager or support service."}}, "example": {"error": "Feature is disabled. Contact support to enable."}}
    overlayPatchId: {"allOf": [{"required": ["id"], "properties": {"id": {"type": "integer", "description": "ID of the overlay"}}, "example": {"id": 1, "url": "http://domain.com/myoverlay_new_3.html", "width": null, "height": null, "x": null, "y": null, "stretch": true}}, "$ref": "#/components/schemas/overlayBase"]}
    overlayPatch: {"allOf": ["example": {"url": "http://domain.com/myoverlay_new_3.html", "width": null, "height": null, "x": null, "y": null, "stretch": true}, "$ref": "#/components/schemas/overlayBase"]}
    broadcast: {"allOf": ["$ref": "#/components/schemas/createBroadcast"]}
    createBroadcast: {"required": ["name"], "type": "object", "properties": {"name": {"type": "string", "description": "Broadcast name"}, "status": {"type": "string", "description": "Broadcast statuses:  \n **Pending** — default “Broadcast isn’t started yet” or custom message (see `pending_message` parameter) is shown, users don't see the live stream  \n **Live** — broadcast is live, and viewers can see it  \n **Paused** — “Broadcast is paused” message is shown, users don't see the live stream  \n **Finished** — “Broadcast is finished” message is shown, users don't see the live stream  \n The users' browsers start displaying the message/stream immediately after you change the broadcast status"}, "share_url": {"type": "string", "description": "Custom URL or iframe displayed in the link field when a user clicks on a sharing button in player. If empty, the link field and social network sharing is disabled"}, "custom_iframe_url": {"type": "string", "description": "Custom URL of iframe for video player to be shared via sharing button in player. Auto generated iframe URL is provided by default"}, "show_dvr_after_finish": {"type": "boolean", "description": "Regulates if a DVR record is shown once a broadcast is finished. Has two possible values:\n\n* **true** — record is shown\n* **false** — record isn't shown\n\n  \nDefault is false"}, "pending_message": {"type": "string", "description": "A custom message that is shown if broadcast status is set to pending. If empty, a default message is shown"}, "ad_id": {"type": "integer", "description": "ID of ad to be displayed in a live stream. If empty the default ad is show. If there is no default ad, no ad is shown"}, "player_id": {"type": "integer", "description": "ID of player to be used with a broadcast. If empty the default player is used"}, "stream_ids": {"type": "array", "description": "IDs of streams used in a broadcast", "items": {"type": "integer"}}, "poster": {"type": "string", "description": "Uploaded poster file"}}, "example": {"name": "Broadcast", "status": "live", "share_url": "", "custom_iframe_url": "", "show_dvr_after_finish": true, "ad_id": 1, "player_id": 14, "stream_ids": [10]}}
    broadcastSpectators: {"type": "object", "properties": {"spectators_count": {"type": "integer", "description": "Number of spectators at the moment"}}, "example": {"spectators_count": 100}}
    restream: {"allOf": ["$ref": "#/components/schemas/createRestream"]}
    createRestream: {"type": "object", "properties": {"name": {"type": "string", "description": "Restream name"}, "live": {"type": "boolean", "description": "Indicates that the stream is being published. Has two possible values:\n\n* **true** — stream is being published\n* **false** — stream isn't published"}, "active": {"type": "boolean", "description": "Enables/Disables restream. Has two possible values:\n\n* **true** — restream is enabled and can be started\n* **false** — restream is disabled.\n\n  \nDefault is true"}, "uri": {"type": "string", "description": "A URL to push the stream to"}, "stream_id": {"type": "integer", "description": "ID of the stream to restream"}, "client_user_id": {"type": "integer", "description": "Custom field where you can specify user ID in your system"}}, "example": {"name": "first restream", "active": true, "uri": "rtmp://a.rtmp.youtube.com/live/k17a-13s8", "stream_id": 20, "client_user_id": 10}}
    createVideo: {"required": ["name"], "type": "object", "properties": {"name": {"type": "string", "description": "Video name"}, "description": {"type": "string", "description": "Video details; not visible to the end-users", "default": null}, "origin_url": {"type": "string", "description": "URL to an original file which you want to copy from external storage.\nIf specified, system will download the file and will use it as video source for transcoding.", "default": null}, "origin_http_headers": {"type": "string", "description": "Authorization HTTP request header. Will be used as credentials to authenticate a request to download a file (specified in \"`origin_url`\" parameter) on an external server.\nSyntax: ```Authorization:  ```\nExamples:\n- \"`origin_http_headers`\": \"Authorization: Basic ...\"\n- \"`origin_http_headers`\": \"Authorization: Bearer ...\"\n- \"`origin_http_headers`\": \"Authorization: APIKey ...\"\nExample of usage when downloading a file from Google Drive:\n```\nPOST https://api.gcore.com/streaming/videos\n\"video\": {\n\"name\": \"IBC 2024 intro.mp4\",\n\"`origin_url`\": \"https://www.googleapis.com/drive/v3/files/...?alt=media\",\n\"`origin_http_headers`\": \"Authorization: Bearer ABC\"\n}\n```", "default": null}, "priority": {"type": "integer", "default": 0, "description": "Priority allows you to adjust the urgency of processing some videos before others in your account, if your algorithm requires it. For example, when there are very urgent video and some regular ones that can wait in the queue.\nValue range, integer [-10..10]. -10 is the lowest down-priority, 10 is the highest up-priority. Default priority is 0."}, "quality_set_id": {"type": "integer", "description": "Custom quality set ID for transcoding, if transcoding is required according to your conditions. Look at GET /`quality_sets` method", "default": null}, "clip_start_seconds": {"type": "integer", "default": null, "description": "If you want to transcode only a trimmed segment of a video instead of entire length if the video, then you can provide timecodes of starting point and duration of a segment to process. Start encoding from is a number in seconds."}, "clip_duration_seconds": {"type": "integer", "default": null, "description": "The length of the trimmed segment to transcode, instead of the entire length of the video. Is only used in conjunction with specifying the start of a segment. Transcoding duration is a number in seconds."}, "source_bitrate_limit": {"type": "boolean", "default": true, "description": "The option allows you to set the video transcoding rule so that the output bitrate in ABR ladder is not exceeding the bitrate of the original video.\n  \nThis option is for advanced users only.\n  \nBy default ```source_bitrate_limit: true``` this option allows you to have the output bitrate not more than in the original video, thus to transcode video faster and to deliver it to end-viewers faster as well. At the same time, the quality will be similar to the original.\nIf for some reason you need more byte-space in the output quality when encoding, you can set this option to ```source_bitrate_limit: false```. Then, when transcoding, the quality ceiling will be raised from the bitrate of the original video to the maximum possible limit specified in our the Product Documentation.\nFor example, this may be needed when:\n- to improve the visual quality parameters using PSNR, SSIM, VMAF metrics,\n- to improve the picture quality on dynamic scenes,\n- etc.\nThe option is applied only at the video creation stage and cannot be changed later. If you want to re-transcode the video using new value, then you need to create and upload a new video only."}, "directory_id": {"type": "integer", "description": "ID of the directory where the video should be uploaded. (beta)"}, "poster": {"type": "string", "default": null, "description": "Poster is your own static image which can be displayed before the video starts.\nAfter uploading the video, the system will automatically create several screenshots (they will be stored in \"screenshots\" attribute)
            from which you can select an default screenshot.\nThis \"poster\" field is for uploading your own image. Also use attribute \"`screenshot_id`\" to select poster as a default screnshot.\nAttribute accepts single image as base64-encoded string [(RFC 2397 – The \"data\" URL scheme)](https://www.rfc-editor.org/rfc/rfc2397). In format: ```data:[];base64,```\nMIME-types are image/jpeg, image/webp, and image/png and file sizes up to 1Mb.\nExamples:\n- ```data:image/jpeg;base64,/9j/4AA...qf/2Q==```\n- ```data:image/png;base64,iVBORw0KGg...ggg==```\n- ```data:image/webp;base64,UklGRt.../DgAAAAA```"}, "remote_poster_url": {"type": "string", "default": null, "description": "Poster URL to download from external resource, instead of uploading via \"poster\" attribute.\nIt has the same restrictions as \"poster\" attribute."}, "remove_poster": {"type": "boolean", "default": false, "description": "Set it to true to remove poster"}, "screenshot_id": {"type": "integer", "default": 0, "description": "Default screenshot index.\nSpecify an ID from the \"screenshots\" array, so that the URL of the required screenshot appears in the \"screenshot\" attribute as the default screenshot. By default 5 static screenshots will be taken from different places in the video after transcoding. If the video is short, there may be fewer screenshots.\nCounting from 0. A value of -1 sets the default screenshot to the URL of your own image from the \"poster\" attribute.\nLook at \"screenshot\" attribute in GET /videos/{`video_id`} for details."}, "client_user_id": {"type": "integer", "description": "Custom field where you can specify user ID in your system"}, "auto_transcribe_audio_language": {"type": "string", "description": "Automatic creation of subtitles by transcribing the audio track.\nValues:\n- disable – Do not transcribe.\n- auto – Automatically detects the activation of the option based on the settings in your account. If generation is activated, then automatic language detection while transcribing.\n- \\ – Transcribe from specific language. Can be used to specify the exact language spoken in the audio track, or when auto language detection fails. Language is set by 3-letter language code according to ISO-639-2 (bibliographic code). List of languages is available in ```audio_language``` attribute of API POST /streaming/ai/transcribe .\nExample:\n```\n`auto_transcribe_audio_language`: \"auto\"\n`auto_transcribe_audio_language`: \"ger\"\n```\nMore details:\n- List of AI tasks – API [GET /streaming/ai/tasks](https://api.gcore.com/docs/streaming/docs/api-reference/ai/get-ai-task-result)\n- Add subtitles to an exist video – API [POST /streaming/videos/{`video_id`}/subtitles](https://api.gcore.com/docs/streaming/docs/api-reference/subtitles/add-subtitle).", "enum": ["disable", "auto", "<language_code>"], "default": "auto"}, "auto_translate_subtitles_language": {"type": "string", "description": "Automatic translation of auto-transcribed subtitles to the specified language(s). Can be used both together with ```auto_transcribe_audio_language``` option only.\nUse it when you want to make automatic subtitles in languages other than the original language in audio.\nValues:\n- disable – Do not translate.\n- default – There are 3 default languages: eng,fre,ger\n- \\ – Explicit language to translate to, or list of languages separated by a comma. Look at list of available languages in description of AI ASR task creation.\nIf several languages are specified for translation, a separate subtitle will be generated for each language.\nExample:\n```\n`auto_translate_subtitles_language`: default\n`auto_translate_subtitles_language`: eng,fre,ger\n```\n  \nPlease note that subtitle translation is done separately and after transcription. Thus separate AI-tasks are created for translation.", "enum": ["disable", "default", "<language_codes,>"], "default": "disable"}, "projection": {"type": "string", "description": "Deprecated.\nRegulates the video format:\n\n* **regular**\n  — plays the video as usual\n* **vr360**\n  — plays the video in 360 degree mode\n* **vr180** —
            plays the video in 180 degree\n  mode\n* **vr360tb** — plays the video in 3D\n  360 degree mode Top-Bottom.\n\n  \n Default is regular"}, "share_url": {"type": "string", "description": "Deprecated.\nCustom URL or iframe displayed in the link field when a user clicks\non a sharing button in player. If empty, the link field and social\nnetwork sharing is disabled"}, "custom_iframe_url": {"type": "string", "description": "Deprecated.\nCustom URL of IFrame for video player to be used in share panel in\nplayer. Auto generated IFrame URL provided by default"}}, "example": {"name": "IBC 2025 - International Broadcasting Convention", "description": "We look forward to welcoming you at IBC2025, which will take place 12-15 September 2025.", "origin_url": "https://www.googleapis.com/drive/v3/files/...?alt=media", "origin_http_headers": "Authorization: Bearer ...", "priority": 0, "clip_start_seconds": 137, "clip_duration_seconds": 60, "directory_id": 800, "projection": "regular", "client_user_id": 10, "stream_id": 1, "poster": "data:image/jpeg;base64,/9j/4AA...qf/2Q==", "screenshot_id": -1, "auto_transcribe_audio_language": "auto"}}
    createVideoBatch: {"allOf": ["$ref": "#/components/schemas/createVideo", {"properties": {"subtitles": {"type": "array", "items": {"$ref": "#/components/schemas/subtitleBody"}}}, "example": {"subtitles": [{"name": "English (AI-generated)", "language": "eng", "vtt": "WEBVTT\n\n1\n00:00:07.154 --> 00:00:12.736\nWe have 100 million registered users or active users who play at least once a week.\n\n2\n00:00:13.236 --> 00:00:20.198\nWe might have 80 or 100,000 playing on a given cluster."}, {"name": "German (AI-translated)", "language": "ger", "vtt": "WEBVTT\n\n1\n00:00:07.154 --> 00:00:12.736\nWir haben 100 Millionen registrierte Benutzer oder aktive Benutzer, die mindestens einmal pro Woche spielen.\n\n2\n00:00:13.236 --> 00:00:20.198\nWir haben vielleicht 80 oder 100.000, die auf einem bestimmten Cluster spielen."}]}}]}
    subtitleBody: {"allOf": ["$ref": "#/components/schemas/subtitleBase", {"required": ["language", "vtt"], "example": {"name": "German (AI-generated)", "language": "ger", "vtt": "WEBVTT\n\n1\n00:00:07.154 --> 00:00:12.736\nWir haben 100 Millionen registrierte Benutzer oder aktive Benutzer, die mindestens einmal pro Woche spielen.\n\n2\n00:00:13.236 --> 00:00:20.198\nWir haben vielleicht 80 oder 100.000, die auf einem bestimmten Cluster spielen."}}]}
    subtitleBase: {"type": "object", "properties": {"name": {"type": "string", "description": "Name of subtitle file"}, "language": {"type": "string", "description": "3-letter language code according to ISO-639-2 (bibliographic code)"}, "vtt": {"type": "string", "description": "Full text of subtitles/captions, with escaped \"\\n\" (\"\\r\") symbol of new line"}}, "example": null}
    getUrlAndTokenToUploadVideo: {"type": "object", "properties": {"servers": {"type": "array", "description": "An array which contains information about servers you can upload a video to.   \n **Server;** type — object.   \n \n\n---\n\n Server has the following fields:   \n\n* **id;** type — integer  \n   Server ID\n  \n* **hostname;** type — string  \n   Server hostname", "items": {"type": "object", "properties": {}}}, "token": {"type": "string", "description": "Token"}, "video": {"type": "object", "properties": {}, "description": "Contains information about the created video. See the full description in the Get video request"}}, "example": {"servers": [{"id": 15, "hostname": "example.com"}], "token": "X2lkIjoxMDE1fSwi", "video": {"id": 17, "name": "Video", "description": "Conference July", "client_id": 100, "duration": 4120, "slug": "zInSg1FL80", "origin_size": 2974741, "origin_host": "origin.host.org", "origin_resource": "", "origin_height": 1080, "screenshots": ["https://screenshot1.example.com/494.jpg"], "screenshot_id": 0, "ad_id": 2, "projection": "regular", "client_user_id": 10, "hls_url": "https://example.com/master.m3u8"}}}
    subtitle: {"allOf": ["$ref": "#/components/schemas/subtitleBase", {"properties": {"id": {"type": "integer", "description": "ID of subtitle file"}}, "example": {"id": 1000, "name": "German (AI-generated)", "language": "ger", "vtt": "WEBVTT\n\n1\n00:00:07.154 --> 00:00:12.736\nWir haben 100 Millionen registrierte Benutzer oder aktive Benutzer, die mindestens einmal pro Woche spielen.\n\n2\n00:00:13.236 --> 00:00:20.198\nWir haben vielleicht 80 oder 100.000, die auf einem bestimmten Cluster spielen."}}]}
    subtitleCreate: {"allOf": ["$ref": "#/components/schemas/subtitleBase", "required": ["language"], {"properties": {"auto_transcribe_audio_language": {"type": "string", "description": "Automatic creation of subtitles by transcribing the audio track.\nWhen using this option, you do not need to attach subtitle text in ```vtt``` field. The audio track will be transcribed and the subtitle will be created automatically.\nValues:\n- auto – AI will determine language automatically.\n- \\ – Explicit indication of the language spoken in the audio. Option is used for clarification ifAI cannot determine the language automatically. Look at list of available languages in description of AI ASR task creation.\nExample: ```auto_transcribe_audio_language: ger```", "enum": ["auto", "<language_code>"], "default": null}, "auto_translate_subtitles_language": {"type": "string", "description": "Automatic translation of auto-transcribed subtitles to the specified language(s). Can be used both together with ```auto_transcribe_audio_language``` option only.\nUse it when you want to make automatic subtitles in languages other than the original language in audio.\nValues:\n- default – There are 3 default languages: eng,fre,ger\n- \\ – Explicit language to translate to, or list of languages separated by a comma. Look at list of available languages in description of AI ASR task creation.\nIf several languages are specified for translation, a separate subtitle will be generated for each language.\nExample: ```auto_translate_subtitles_language: eng,fre,ger```\n  \nPlease note that subtitle translation is done separately and after transcription. Thus separate AI-tasks are created for translation.", "enum": ["default", "<language_code,>"], "default": null}, "name": {"description": "Name of the subtitle.\nIf AI is used for creating subtitles and name field is not set, then name will be taken by pattern: \"{language} (AI-generated)\"."}, "vtt": {"description": "Full text of subtitles/captions, with escaped \"\\n\" (\"\\r\") symbol of new line.\nIf AI is used for creating subtitles, then this field must not be set."}}, "example": {"name": "German (AI-generated)", "language": "ger", "vtt": "WEBVTT\n\n1\n00:00:07.154 --> 00:00:12.736\nWir haben 100 Millionen registrierte Benutzer oder aktive Benutzer, die mindestens einmal pro Woche spielen.\n\n2\n00:00:13.236 --> 00:00:20.198\nWir haben vielleicht 80 oder 100.000, die auf einem bestimmten Cluster spielen."}}]}
    subtitleerror422: {"allOf": ["$ref": "#/components/schemas/badrequest", "example": {"status": 422, "error": "Unprocessable Entity. Language code is not recognized."}]}
    subtitleBodyPatch: {"allOf": ["$ref": "#/components/schemas/subtitleBase", "example": {"language": "ltz"}]}
    subtitlePatched: {"allOf": ["$ref": "#/components/schemas/subtitleBase", "example": {"name": "German (AI-generated)", "language": "ltz", "vtt": "WEBVTT\n\n1\n00:00:07.154 --> 00:00:12.736\nWir haben 100 Millionen registrierte Benutzer oder aktive Benutzer, die mindestens einmal pro Woche spielen.\n\n2\n00:00:13.236 --> 00:00:20.198\nWir haben vielleicht 80 oder 100.000, die auf einem bestimmten Cluster spielen."}]}
    directories_tree: {"type": "object", "properties": {"tree": {"type": "array", "items": {"allOf": ["$ref": "#/components/schemas/directory_base"], "properties": {"descendants": {"type": "array", "items": {"$ref": "#/components/schemas/directories_tree"}, "description": "Array of subdirectories, if any.", "default": null}}}}}, "example": {"tree": [{"id": 100, "name": "New series", "parent_id": null, "items_count": 2, "created_at": "2024-07-01T18:00:00Z", "updated_at": "2024-07-01T18:00:00Z", "descendants": [{"id": 101, "name": "New series, Season 1", "parent_id": 100, "items_count": 12, "created_at": "2024-07-01T18:10:00Z", "updated_at": "2024-07-01T18:10:00Z", "descendants": []}]}]}}
    directory_base: {"type": "object", "properties": {"id": {"type": "integer", "description": "ID of the directory"}, "name": {"type": "string", "description": "Title of the directory"}, "parent_id": {"type": "integer", "description": "ID of a parent directory. \"null\" if it's in the root.", "default": null}, "items_count": {"type": "integer", "description": "Number of objects in this directory. Counting files and folders. The quantity is calculated only at one level (not recursively in all subfolders)."}, "created_at": {"type": "string", "description": "Time of creation. Datetime in ISO 8601 format."}, "updated_at": {"type": "string", "description": "Time of last update of the directory entity. Datetime in ISO 8601 format."}}, "example": {"id": 100, "name": "New series", "parent_id": null, "items_count": 2, "created_at": "2024-07-01T18:00:00Z", "updated_at": "2024-07-01T18:00:00Z"}}
    directory: {"type": "object", "properties": {"directory": {"allOf": ["$ref": "#/components/schemas/directory_base"], "properties": {"items": {"type": "array", "items": {"anyOf": ["$ref": "#/components/schemas/directory_video", "$ref": "#/components/schemas/directory_item"]}, "description": "Array of subdirectories, if any.", "default": null}}}}, "example": {"directory": {"id": 100, "name": "New series", "parent_id": null, "items_count": 2, "created_at": "2024-07-01T18:00:00Z", "updated_at": "2024-07-01T18:00:00Z", "items": [{"id": 101, "item_type": "Directory", "name": "New series, Season 1", "parent_id": 100, "items_count": 12, "created_at": "2024-07-01T18:10:00Z", "updated_at": "2024-07-01T18:10:00Z"}, {"id": 4734454, "name": "Season 1, Official Trailer 2024", "item_type": "Video", "slug": "2Y20240219074738"}]}}}
    directory_video: {"type": "object", "properties": {"item_type": {"type": "string", "description": "Type of the entity: directory, or video", "enum": ["Video"]}}, "allOf": ["$ref": "#/components/schemas/searchVideo"], "example": {"item_type": "Video"}}
    directory_item: {"type": "object", "properties": {"item_type": {"type": "string", "description": "Type of the entity: directory, or video", "enum": ["Directory"]}}, "allOf": ["$ref": "#/components/schemas/directory_base"], "example": {"id": 100, "item_type": "Directory", "name": "New series", "parent_id": null, "items_count": 2, "created_at": "2024-07-01T18:00:00Z", "updated_at": "2024-07-01T18:00:00Z"}}
    directory_patch: {"type": "object", "properties": {"name": {"type": "string", "description": "Title of the directory. Omit this if you don't want to change."}, "parent_id": {"type": "integer", "description": "ID of a parent directory. \"null\" if it's in the root. Omit this if you don't want to change."}}, "example": {"name": "New series. Season 2"}}
    directory_post: {"type": "object", "properties": {"name": {"type": "string", "description": "Title of the directory."}, "parent_id": {"type": "integer", "description": "ID of a parent directory. \"null\" if it's in the root.", "default": null}}, "required": ["name"], "example": {"name": "New series. Season 1", "parent_id": 100}}
    playlist: {"type": "object", "properties": {"name": {"type": "string", "description": "Playlist name"}, "client_id": {"type": "integer", "description": "Current playlist client ID"}, "active": {"type": "boolean", "default": true, "description": "Enables/Disables playlist. Has two possible values:\n- true – Playlist can be played.\n- false – Playlist is disabled. No broadcast while it's desabled."}, "start_time": {"type": "string", "default": null, "description": "Playlist start time. Playlist won't be available before the specified time. Datetime in ISO 8601 format."}, "loop": {"type": "boolean", "default": false, "description": "Enables/Disables playlist loop"}, "video_ids": {"type": "array", "description": "A list of VOD IDs included in the playlist. Order of videos in a\nplaylist reflects the order of IDs in the array.\nMaximum video limit = 128.", "items": {"type": "integer"}}, "client_user_id": {"type": "integer", "description": "Custom field where you can specify user ID in your system"}, "ad_id": {"type": "integer", "description": "The advertisement ID that will be inserted into the video"}, "player_id": {"type": "integer", "description": "The player ID with which the video will be played"}, "countdown": {"type": "boolean", "description": "Enables countdown before playlist start with ```playlist_type: live```"}, "playlist_type": {"type": "string", "enum": ["live", "vod"], "description": "Determines whether the playlist:\n- `live` - playlist for live-streaming\n- `vod` - playlist is for video on demand access"}, "hls_url": {"type": "string", "description": "A URL to a master playlist HLS (master.m3u8) with MPEG TS container.\n  \nThis URL is a link to the main manifest. But you can also manually specify suffix-options that will allow you to change the manifest to your request:\n```/playlists/{`client_id`}_{`playlist_id`}/master[-cmaf][-min-N][-max-N][-img][-(h264|hevc|av1)].m3u8```\nPlease see the details in ```hls_url``` attribute of /videos/{id} method.\n  \nCaution. Solely master.m3u8 (and master[-options].m3u8) is officially documented and intended for your use. Any additional internal manifests, sub-manifests, parameters, chunk names, file extensions, and related components are internal infrastructure entities. These may undergo modifications without prior notice, in any manner or form. It is strongly advised not to store them in your database or cache them on your end."}, "hls_cmaf_url": {"type": "string", "description": "A URL to a master playlist HLS (master-cmaf.m3u8) with CMAF-based chunks. Chunks are in fMP4 container.\n  \nIt is possible to use the same suffix-options as described in the \"`hls_url`\" attribute.\n  \nCaution. Solely master.m3u8 (and master[-options].m3u8) is officially documented and intended for your use. Any additional internal manifests, sub-manifests, parameters, chunk names, file extensions, and related components are internal infrastructure entities. These may undergo modifications without prior notice, in any manner or form. It is strongly advised not to store them in your database or cache them on your end."}, "iframe_url": {"type": "string", "description": "A URL to a built-in HTML video player with the video inside. It can be inserted into an iframe on your website and the video will automatically play in all browsers.\nThe player can be opened or shared via this direct link. Also the video player can be integrated into your web pages using the Iframe tag.\n  \nPlease see the details in ```iframe_url``` attribute of /videos/{id} method."}}, "example": {"name": "Playlist: Webinar 'Onboarding for new employees on working with the corporate portal'", "active": true, "start_time": "2024-07-01T11:00:00Z", "loop": false, "video_ids": [17800, 17801], "client_user_id": 2876, "countdown": true, "playlist_type": "live"}}
    playlist_post: {"allOf": ["$ref": "#/components/schemas/playlist"], "properties": {"id": {"type": "integer", "description": "Playlist ID"}}, "example": {"id": 6018}}
    video: {"allOf": ["$ref": "#/components/schemas/createVideo"]}
    qualitysets: {"type": "object", "properties": {"live": {"type": "array", "items": {"$ref": "#/components/schemas/qualityset1"}}, "vod": {"type": "array", "items": {"$ref": "#/components/schemas/qualityset1"}}}, "example": {"live": [{"id": 77, "name": "Live 4K UHD 60fps AV1 (custom)", "default": true, "qualities": [{"id": 1, "name": "vod2160n"}, {"id": 2, "name": "vod1440n"}]}], "vod": []}}
    qualityset1: {"type": "object", "properties": {"id": {"type": "integer", "description": "ID of the custom quality set"}, "name": {"type": "string", "description": "Human readable name of the quality set"}, "default": {"type": "boolean", "description": "States if this preset is default for a client profile"}, "qualities": {"type": "array", "description": "Array of associated qualities", "items": {"type": "object", "properties": {"id": {"type": "integer", "description": "ID of the quality"}, "name": {"type": "string", "description": "Name of the quality"}}}}}}
    qualitysetDefault: {"type": "object", "properties": {"live": {"type": "object", "properties": {"id": {"type": "integer", "default": null, "description": "ID of the custom quality set, or \"null\" for the system default"}}}, "vod": {"type": "object", "properties": {"id": {"type": "integer", "default": null, "description": "ID of the custom quality set, or \"null\" for the system default"}}}}, "example": {"live": {"id": 77}, "vod": {"id": null}}}
    player: {"required": ["name"], "type": "object", "properties": {"id": {"type": "integer", "description": "Player ID"}, "name": {"type": "string", "description": "Player name"}, "client_id": {"type": "integer", "description": "Client ID"}, "framework": {"type": "string", "description": "Player framework type"}, "design": {"type": "string", "description": "String to be rendered as JS parameters to player"}, "custom_css": {"type": "string", "description": "Custom CSS to be added to player iframe"}, "js_url": {"type": "string", "description": "Player main JS file URL. Leave empty to use JS URL from the default player"}, "skin_is_url": {"type": "string", "description": "URL to custom skin JS file"}, "bg_color": {"type": "string", "description": "Color of skin background in format #AAAAAA"}, "fg_color": {"type": "string", "description": "Color of skin foreground (elements) in format #AAAAAA"}, "text_color": {"type": "string", "description": "Color of skin text elements in format #AAAAAA"}, "hover_color": {"type": "string", "description": "Color of foreground elements when mouse is over in format #AAAAAA"}, "autoplay": {"type": "boolean", "description": "Enables video playback right after player load:\n\n* **true** — video starts playing right after player loads\n* **false** — video isn’t played automatically. A user must click play to start\n\nDefault is false"}, "mute": {"type": "boolean", "description": "Regulates the sound volume:\n\n* **true** — video starts with volume off\n* **false** — video starts with volume on\n\nDefault is false"}, "disable_skin": {"type": "boolean", "description": "Enables/Disables player skin:\n\n* **true** — player skin is disabled\n* **false** — player skin is enabled\n\nDefault is false"}, "save_options_to_cookies": {"type": "boolean", "description": "Enables/Disables saving volume and other options in cookies:\n\n* **true** — user settings will be saved\n* **false** — user settings will not be saved\n\nDefault is true"}, "show_sharing": {"type": "boolean", "description": "Enables/Disables sharing button display:\n\n* **true** — sharing button is displayed\n* **false** — no sharing button is displayed\n\nDefault is true"}, "logo_position": {"type": "string", "description": "Logotype position.   \n Has four possible values:\n\n* **tl** — top left\n* **tr** — top right\n* **bl** — bottom left\n* **br** — bottom right\n\nDefault is null"}, "speed_control": {"type": "boolean", "description": "Enables/Disables speed control button display:\n\n* **true** — sharing button is displayed\n* **false** — no sharing button is displayed\n\nDefault is false"}, "logo": {"type": "string", "description": "URL to logo image"}}, "description": "Set of properties for displaying videos. All parameters may be blank to inherit their values from default Streaming player.", "example": [{"id": 33, "name": "Player", "client_id": 100, "design": "", "custom_css": "", "js_url": "", "skin_js_url": "", "bg_color": "#3313df", "fg_color": "#FFFFFF", "text_color": "#FFFFFF", "hover_color": "#ef9047", "autoplay": true, "mute": false, "disable_skin": false, "save_options_to_cookies": false, "show_sharing": true, "speed_control": false}]}
    ai_task: {"type": "object", "properties": {"task_name": {"type": "string", "description": "Name of the task to be performed", "enum": ["transcription", "content-moderation"]}}, "required": ["task_name", "url"], "example": {"task_name": "transcription|content-moderation", "url": "https://demo-files.gvideo.io/ai_demo_subtitles_nudity_detection.mp4", "audio_language": "ger", "category": "nsfw"}, "allOf": ["$ref": "#/components/schemas/ai_transcribe", "$ref": "#/components/schemas/ai_contentmoderation_general"]}
    ai_transcribe: {"type": "object", "required": ["url", "task_name"], "properties": {"task_name": {"type": "string", "description": "Name of the task to be performed", "enum": ["transcription"]}, "url": {"type": "string", "description": "URL to the MP4 file to analyse. File must be publicly accessible via HTTP/HTTPS."}, "audio_language": {"type": "string", "description": "Language in original audio (transcription only). This value is used to determine the language from which to transcribe.\nIf this is not set, the system will run auto language identification and the subtitles will be in the detected language. The method also works based on AI analysis. It's fairly accurate, but if it's wrong, then set the language explicitly.\nAdditionally, when this is not set, we also support recognition of alternate languages in the video (language code-switching).\nLanguage is set by 3-letter language code according to ISO-639-2 (bibliographic code).\nWe can process languages:\n- 'afr': Afrikaans\n- 'alb': Albanian\n- 'amh': Amharic\n- 'ara': Arabic\n- 'arm': Armenian\n- 'asm': Assamese\n- 'aze': Azerbaijani\n- 'bak': Bashkir\n- 'baq': Basque\n- 'bel': Belarusian\n- 'ben': Bengali\n- 'bos': Bosnian\n- 'bre': Breton\n- 'bul': Bulgarian\n- 'bur': Myanmar\n- 'cat': Catalan\n- 'chi': Chinese\n- 'cze': Czech\n- 'dan': Danish\n- 'dut': Nynorsk\n- 'eng': English\n- 'est': Estonian\n- 'fao': Faroese\n- 'fin': Finnish\n- 'fre': French\n- 'geo': Georgian\n- 'ger': German\n- 'glg': Galician\n- 'gre': Greek\n- 'guj': Gujarati\n- 'hat': Haitian creole\n- 'hau': Hausa\n- 'haw': Hawaiian\n- 'heb': Hebrew\n- 'hin': Hindi\n- 'hrv': Croatian\n- 'hun': Hungarian\n- 'ice': Icelandic\n- 'ind': Indonesian\n- 'ita': Italian\n- 'jav': Javanese\n- 'jpn': Japanese\n- 'kan': Kannada\n- 'kaz': Kazakh\n- 'khm': Khmer\n- 'kor': Korean\n- 'lao': Lao\n- 'lat': Latin\n- 'lav': Latvian\n- 'lin': Lingala\n- 'lit': Lithuanian\n- 'ltz': Luxembourgish\n- 'mac': Macedonian\n- 'mal': Malayalam\n- 'mao': Maori\n- 'mar': Marathi\n- 'may': Malay\n- 'mlg': Malagasy\n- 'mlt': Maltese\n- 'mon': Mongolian\n- 'nep': Nepali\n- 'dut': Dutch\n- 'nor': Norwegian\n- 'oci': Occitan\n- 'pan': Punjabi\n- 'per': Persian\n- 'pol': Polish\n- 'por': Portuguese\n- 'pus': Pashto\n- 'rum': Romanian\n- 'rus': Russian\n- 'san': Sanskrit\n- 'sin': Sinhala\n- 'slo': Slovak\n- 'slv': Slovenian\n- 'sna': Shona\n- 'snd': Sindhi\n- 'som': Somali\n- 'spa': Spanish\n- 'srp': Serbian\n- 'sun': Sundanese\n- 'swa': Swahili\n- 'swe': Swedish\n- 'tam': Tamil\n- 'tat': Tatar\n- 'tel': Telugu\n- 'tgk': Tajik\n- 'tgl': Tagalog\n- 'tha': Thai\n- 'tib': Tibetan\n- 'tuk': Turkmen\n- 'tur': Turkish\n- 'ukr': Ukrainian\n- 'urd': Urdu\n- 'uzb': Uzbek\n- 'vie': Vietnamese\n- 'wel': Welsh\n- 'yid': Yiddish\n- 'yor': Yoruba", "default": null}, "subtitles_language": {"type": "string", "description": "Indicates which language it is clearly necessary to translate into.\nIf this is not set, the original language will be used from attribute \"`audio_language`\".\nPlease note that:\n- transcription into the original language is a free procedure,\n- and translation from the original language into any other languages is a \"translation\" procedure and is paid. More details in [POST /ai/tasks#transcribe](https://api.gcore.com/docs/streaming/docs/api-reference/ai/create-ai-asr-task).\nLanguage is set by 3-letter language code according to ISO-639-2 (bibliographic code).", "default": null}, "client_user_id": {"type": "string", "maxLength": 256, "default": null, "description": "Meta parameter, designed to store your own identifier. Can be used by you to tag requests from different end-users. It is not used in any way in video processing."}, "client_entity_data": {"type": "string", "maxLength": 4096, "default": null, "description": "Meta parameter, designed to store your own extra information about a video entity: video source, video id, etc. It is not used in any way in video processing.\nFor example, if an AI-task was created automatically when you uploaded a video with the AI auto-processing option (transcribing, translationing), then
            the ID of the associated video for which the task was performed will be explicitly indicated here."}}, "example": {"url": "https://demo-files.gvideo.io/apidocs/spritefright-blender-cut30sec.mp4", "task_name": "transcription", "audio_language": "ger"}}
    ai_contentmoderation_general: {"type": "object", "required": ["url", "task_name"], "properties": {"task_name": {"type": "string", "description": "Name of the task to be performed", "enum": ["content-moderation"]}, "url": {"type": "string", "description": "URL to the MP4 file to analyse. File must be publicly accessible via HTTP/HTTPS."}, "category": {"type": "string", "description": "Model for analysis (content-moderation only). Determines what exactly needs to be found in the video.", "enum": ["sport", "weapon", "nsfw", "hard_nudity", "soft_nudity", "child_pornography"]}, "client_user_id": {"type": "string", "maxLength": 256, "default": null, "description": "Meta parameter, designed to store your own identifier. Can be used by you to tag requests from different end-users. It is not used in any way in video processing."}, "client_entity_data": {"type": "string", "maxLength": 4096, "default": null, "description": "Meta parameter, designed to store your own extra information about a video entity: video source, video id, etc. It is not used in any way in video processing.\nFor example, if an AI-task was created automatically when you uploaded a video with the AI auto-processing option (nudity detection, etc), then the ID of the associated video for which the task was performed will be explicitly indicated here."}}, "example": {"url": "https://demo-files.gvideo.io/ai_demo_subtitles_nudity_detection.mp4", "task_name": "content-moderation", "category": "nsfw"}}
    ai_post_response: {"type": "object", "required": ["task_id"], "properties": {"task_id": {"type": "string", "format": "uuid", "description": "ID of the created AI task, from which you can get the execution result"}}, "example": {"task_id": "aafe70c6-0000-0000-0000-327b65f7670f"}}
    streaming_error: {"type": "object", "properties": {"error": {"type": "string", "description": "Text message with description of error."}}, "example": {"error": "Queue limit reached (100), try later."}}
    ai_tasks_list: {"properties": {"count": {"type": "integer", "description": "Total number of tasks", "default": 0}, "next": {"type": "string", "description": "Pointer to next page, is part of query string of the request", "default": null}, "previous": {"type": "string", "description": "Pointer to the previous page, is part of query string of the request", "default": null}, "results": {"type": "array", "items": {"$ref": "#/components/schemas/ai_task_base"}}}, "example": {"count": 127, "next": "page=2", "previous": null, "results": [{"task_id": "aafe70c6-0000-0000-0000-327b65f7670f", "task_name": "content-moderation", "task_data": {}, "progress": 100, "status": "SUCCESS"}, {"task_id": "aafe70c6-0000-0000-0000-d3bcebebf37c", "task_name": "transcription", "task_data": {}, "progress": 50, "status": "STARTED"}]}}
    ai_task_base: {"type": "object", "properties": {"task_id": {"type": "string", "format": "uuid", "description": "ID of the AI task"}, "status": {"type": "string", "description": "Status of processing the AI task. See GET /ai/results method for description.", "enum": ["PENDING", "STARTED", "SUCCESS", "FAILURE", "REVOKED", "RETRY"]}, "progress": {"type": "integer", "default": null, "description": "Percentage of task completed. A value greater than 0 means that it has been taken into operation and is being processed."}, "task_name": {"type": "string", "description": "Type of AI task", "enum": ["content-moderation", "transcription"]}, "task_data": {"description": "The object will correspond to the task type that was specified in the original request. There will be one object for transcription, another for searching for nudity, and so on.", "anyOf": ["$ref": "#/components/schemas/ai_transcribe", "$ref": "#/components/schemas/ai_contentmoderation_nsfw", "$ref": "#/components/schemas/ai_contentmoderation_hardnudity", "$ref": "#/components/schemas/ai_contentmoderation_softnudity", "$ref": "#/components/schemas/ai_contentmoderation_casm", "$ref": "#/components/schemas/ai_contentmoderation_sport", "$ref": "#/components/schemas/ai_contentmoderation_weapon"]}}}
    ai_contentmoderation_nsfw: {"allOf": ["$ref": "#/components/schemas/ai_contentmoderation_general"], "required": ["category"], "properties": {"category": {"type": "string", "enum": ["nsfw"], "description": "AI content moderation with NSFW detection algorithm"}}, "example": {"url": "https://demo-files.gvideo.io/ai_demo_subtitles_nudity_detection.mp4", "task_name": "content-moderation", "category": "nsfw"}}
    ai_contentmoderation_hardnudity: {"allOf": ["$ref": "#/components/schemas/ai_contentmoderation_general"], "required": ["category"], "properties": {"category": {"type": "string", "enum": ["hard_nudity"], "description": "AI content moderation with \"`hard_nudity`\" algorithm"}, "stop_objects": {"type": "string", "enum": ["ANUS_EXPOSED", "BUTTOCKS_EXPOSED", "FEMALE_BREAST_EXPOSED", "FEMALE_GENITALIA_EXPOSED", "MALE_BREAST_EXPOSED", "MALE_GENITALIA_EXPOSED"], "description": "Comma separated objects, and probabilities, that will cause the processing to stop immediatelly after finding."}}, "example": {"url": "https://demo-files.gvideo.io/ai_demo_subtitles_nudity_detection.mp4", "task_name": "content-moderation", "category": "hard_nudity", "stop_objects": "FEMALE_GENITALIA_EXPOSED,FEMALE_BREAST_EXPOSED:0.50,BUTTOCKS_EXPOSED:0.90"}}
    ai_contentmoderation_softnudity: {"allOf": ["$ref": "#/components/schemas/ai_contentmoderation_general"], "required": ["category"], "properties": {"category": {"type": "string", "enum": ["soft_nudity"], "description": "AI content moderation with \"`soft_nudity`\" algorithm"}, "stop_objects": {"type": "string", "enum": ["ANUS_COVERED", "ANUS_EXPOSED", "ARMPITS_COVERED", "ARMPITS_EXPOSED", "BELLY_COVERED", "BELLY_EXPOSED", "BUTTOCKS_COVERED", "BUTTOCKS_EXPOSED", "FACE_FEMALE", "FACE_MALE", "FEET_COVERED", "FEET_EXPOSED", "FEMALE_BREAST_COVERED", "FEMALE_BREAST_EXPOSED", "FEMALE_GENITALIA_COVERED", "FEMALE_GENITALIA_EXPOSED", "MALE_BREAST_EXPOSED", "MALE_GENITALIA_EXPOSED"], "description": "Comma separated objects, and probabilities, that will cause the processing to stop immediatelly after finding."}}, "example": {"url": "https://demo-files.gvideo.io/ai_demo_subtitles_nudity_detection.mp4", "task_name": "content-moderation", "category": "soft_nudity", "stop_objects": "BELLY_COVERED:0.9,FEMALE_GENITALIA_COVERED"}}
    ai_contentmoderation_casm: {"allOf": ["$ref": "#/components/schemas/ai_contentmoderation_general"], "required": ["category"], "properties": {"category": {"type": "string", "enum": ["child_pornography"], "description": "AI content moderation with child pornography detection algorithm"}}, "example": {"url": "https://demo-files.gvideo.io/ai_demo_subtitles_nudity_detection.mp4", "task_name": "content-moderation", "category": "child_pornography"}}
    ai_contentmoderation_sport: {"allOf": ["$ref": "#/components/schemas/ai_contentmoderation_general"], "required": ["category"], "properties": {"category": {"type": "string", "enum": ["sport"], "description": "AI content moderation with types of sports activity detection"}}, "example": {"url": "https://demo-files.gvideo.io/ai_demo_soccer_players_passing_the_ball.mp4", "task_name": "content-moderation", "category": "sport"}}
    ai_contentmoderation_weapon: {"allOf": ["$ref": "#/components/schemas/ai_contentmoderation_general"], "required": ["category"], "properties": {"category": {"type": "string", "enum": ["weapon"], "description": "AI content moderation with weapon detection algorithm"}}, "example": {"url": "https://demo-files.gvideo.io/ai_demo_weapon_detection.mp4", "task_name": "content-moderation", "category": "weapon"}}
    ai_results: {"allOf": ["$ref": "#/components/schemas/ai_task_base"], "properties": {"processing_time": {"type": "object", "properties": {"started_at": {"type": "string", "description": "Video processing start time. Format is date time in ISO 8601"}, "completed_at": {"type": "string", "description": "Video processing end time. Format is date time in ISO 8601", "default": null}, "total_time_sec": {"type": "number", "format": "decimal", "description": "Duration of video processing in seconds", "default": null}}}, "result": {"default": null, "anyOf": ["$ref": "#/components/schemas/ai_results_transcribe", "$ref": "#/components/schemas/ai_results_contentmoderation_sport", "$ref": "#/components/schemas/ai_results_contentmoderation_weapon", "$ref": "#/components/schemas/ai_results_contentmoderation_nsfw", "$ref": "#/components/schemas/ai_results_contentmoderation_hardnudity", "$ref": "#/components/schemas/ai_results_contentmoderation_softnudity", "$ref": "#/components/schemas/ai_results_contentmoderation_casm", "$ref": "#/components/schemas/ai_results_failure"]}}, "example": {"task_id": "aafe70c6-0000-0000-0000-327b65f7670f", "task_data": {}, "progress": 100, "status": "SUCCESS", "processing_time": {"started_at": "2024-07-13T12:30:00.000Z", "completed_at": "2024-07-13T12:31:02.900Z", "total_time_sec": 62.901}, "result": {}}}
    ai_results_transcribe: {"type": "object", "properties": {"speech_detected": {"type": "boolean", "description": "Determines whether speech was detected or not.\nPlease note: If the task is in \"SUCCESS\" status and speech was not found in the entire file, then \"false\" will be indicated here and the ```subtitles``` field will be empty."}, "concatenated_text": {"type": "string", "description": "Full text of the analyzed video. The value is unstructured, unformatted text."}, "subtitles": {"type": "array", "items": {"type": "object", "properties": {"start_time": {"type": "string", "description": "Start time of the phrase when it is heard in the video. Format is \"HH:mm:ss.fff\"."}, "end_time": {"type": "string", "description": "End time of the phrase, when it ends in the video. Format is \"HH:mm:ss.fff\"."}, "text": {"type": "string", "description": "A complete phrase that sounds during a specified period of time."}}}, "description": "An array of phrases divided into time intervals, in the format \"json\". Suitable when you need to display the result in chronometric form, or transfer the text for further processing."}, "vttContent": {"type": "string", "description": "Auto generated subtitles in WebVTT format."}, "languages": {"type": "array", "items": {"type": "string"}, "description": "An array of language codes that were discovered and/or used in transcription. If the audio or subtitle language was explicitly specified in the initial parameters, it will be copied here. For automatic detection the identified languages will be displayed here. Also please note that for multilingual audio, the first 5 languages are displayed in order of frequency of use."}}, "example": {"concatenated_text": "Come on team, we mustn't dilly dally when there's so much nature to see!  I was thinking, we should call our class project, Fungi in a Forest!", "subtitles": [{"start_time": "00:00:00.009", "end_time": "00:00:03.689", "text": "Come on team, we mustn't dilly dally when there's so much nature to see!"}, {"start_time": "00:00:04.129", "end_time": "00:00:08.169", "text": "I was thinking, we should call our class project, Fungi in a Forest!"}], "vttContent": "WEBVTT\n\n1\n00:00:00.009 --> 00:00:03.689\nCome on team, we mustn't dilly dally when there's so much nature to see!\n\n2\n00:00:04.129 --> 00:00:08.169\nI was thinking, we should call our class project, Fungi in a Forest!\n\n", "languages": ["eng"]}}
    ai_results_contentmoderation_sport: {"type": "object", "properties": {"sport_detected": {"type": "boolean", "description": "A boolean value whether any sports were detected"}, "detection_results": {"type": "array", "items": {"type": "string", "description": "Array of detected sports", "enum": ["archery", "arm wrestling", "playing badminton", "playing baseball", "basketball dunk", "bowling", "boxing punch", "boxing speed bag", "catching or throwing baseball", "catching or throwing softball", "cricket", "curling", "disc golfing", "dodgeball", "fencing", "football", "golf chipping", "golf driving", "golf putting", "hitting baseball", "hockey stop", "ice skating", "javelin throw", "juggling soccer ball", "kayaking", "kicking field goal", "kicking soccer ball", "playing cricket", "playing field hockey", "playing ice hockey", "playing kickball", "playing lacrosse", "playing ping pong", "playing polo", "playing squash or racquetball", "playing tennis", "playing volleyball", "pole vault", "riding a bike", "riding or walking with horse", "roller skating", "rowing", "sailing", "shooting goal (soccer)", "skateboarding", "skiing"]}}, "frames": {"type": "array", "items": {"type": "object", "properties": {"frame-number": {"type": "integer", "description": "Video frame number where activity was found"}, "label": {"type": "string", "description": "Type of detected activity"}, "confidence": {"type": "number", "format": "decimal", "description": "Percentage of probability of identifying the activity"}}}}}, "example": {"sport_detected": true, "detection_results": ["football", "playing tennis"], "frames": [{"frame-number": 4, "label": "football", "score": 0.95}, {"frame-number": 100, "label": "playing tennis", "score": 0.5}]}}
    ai_results_contentmoderation_weapon: {"type": "object", "properties": {"weapon_detected": {"type": "boolean", "description": "A boolean value whether any weapon was detected"}, "detection_results": {"type": "array", "items": {"type": "string", "description": "Array of detected weapons", "enum": ["gun", "heavy weapon", "knife"]}}, "frames": {"type": "array", "items": {"type": "object", "properties": {"frame-number": {"type": "integer", "description": "Video frame number where object was found"}, "label": {"type": "string", "description": "Type of detected object"}, "confidence": {"type": "number", "format": "decimal", "description": "Percentage of probability of identifying the object"}}}}}, "example": {"weapon_detected": true, "detection_results": ["gun", "heavy weapon"], "frames": [{"frame-number": 4, "label": "gun", "score": 0.95}, {"frame-number": 100, "label": "heavy weapon", "score": 0.51}]}}
    ai_results_contentmoderation_nsfw: {"type": "object", "properties": {"nsfw_detected": {"type": "boolean", "description": "A boolean value whether any Not Safe For Work content was detected"}, "detection_results": {"type": "array", "items": {"type": "string", "description": "Array of detected category", "enum": ["nsfw"]}}, "frames": {"type": "array", "items": {"type": "object", "properties": {"frame-number": {"type": "integer", "description": "Video frame number where object was found"}, "label": {"type": "string", "description": "Type of detected object"}, "confidence": {"type": "number", "format": "decimal", "description": "Percentage of probability of identifying the object"}}}}}, "example": {"porn_detected": true, "detection_results": ["nsfw"], "frames": [{"frame-number": 4, "label": "nsfw", "score": "1.0"}, {"frame-number": 100, "label": "nsfw", "score": 0.51}]}}
    ai_results_contentmoderation_hardnudity: {"type": "object", "properties": {"porn_detected": {"type": "boolean", "description": "A boolean value whether any nudity was detected"}, "detection_results": {"type": "array", "items": {"type": "string", "description": "Array of detected nudity category", "enum": ["ANUS_EXPOSED", "BUTTOCKS_EXPOSED", "FEMALE_BREAST_EXPOSED", "FEMALE_GENITALIA_EXPOSED", "MALE_BREAST_EXPOSED", "MALE_GENITALIA_EXPOSED"]}}, "frames": {"type": "array", "items": {"type": "object", "properties": {"frame-number": {"type": "integer", "description": "Video frame number where object was found"}, "label": {"type": "string", "description": "Type of detected object"}, "confidence": {"type": "number", "format": "decimal", "description": "Percentage of probability of identifying the object"}}}}}, "example": {"porn_detected": true, "detection_results": ["FEMALE_BREAST_EXPOSED", "MALE_GENITALIA_EXPOSED"], "frames": [{"frame-number": 4, "label": "FEMALE_BREAST_EXPOSED", "score": 0.95}, {"frame-number": 100, "label": "MALE_GENITALIA_EXPOSED", "score": 0.51}]}}
    ai_results_contentmoderation_softnudity: {"type": "object", "properties": {"porn_detected": {"type": "boolean", "description": "A boolean value whether any nudity and other body part was detected"}, "detection_results": {"type": "array", "items": {"type": "string", "description": "Array of detected nudity or body part category", "enum": ["ANUS_COVERED", "ANUS_EXPOSED", "ARMPITS_COVERED", "ARMPITS_EXPOSED", "BELLY_COVERED", "BELLY_EXPOSED", "BUTTOCKS_COVERED", "BUTTOCKS_EXPOSED", "FACE_FEMALE", "FACE_MALE", "FEET_COVERED", "FEET_EXPOSED", "FEMALE_BREAST_COVERED", "FEMALE_BREAST_EXPOSED", "FEMALE_GENITALIA_COVERED", "FEMALE_GENITALIA_EXPOSED", "MALE_BREAST_EXPOSED", "MALE_GENITALIA_EXPOSED"]}}, "frames": {"type": "array", "items": {"type": "object", "properties": {"frame-number": {"type": "integer", "description": "Video frame number where object was found"}, "label": {"type": "string", "description": "Type of detected object"}, "confidence": {"type": "number", "format": "decimal", "description": "Percentage of probability of identifying the object"}}}}}, "example": {"porn_detected": true, "detection_results": ["FACE_FEMALE", "FACE_MALE"], "frames": [{"frame-number": 4, "label": "FACE_FEMALE", "score": 0.95}, {"frame-number": 100, "label": "FACE_MALE", "score": 0.51}]}}
    ai_results_contentmoderation_casm: {"type": "object", "properties": {"child_pornography_detected": {"type": "boolean", "description": "A boolean value whether child pornography was detected"}, "detection_results": {"type": "array", "items": {"type": "string", "description": "An array with the detected age of children in the video, if the video contains elements of nudity or porn is detected", "enum": ["0-2", "3-9", "10-19"]}}, "frames": {"type": "array", "items": {"type": "object", "properties": {"frame-number": {"type": "integer", "description": "Video frame number where object was found"}, "label": {"type": "string", "description": "Type of detected object"}, "confidence": {"type": "number", "format": "decimal", "description": "Percentage of probability of identifying the object"}}}}}, "example": {"child_pornography_detected": true, "detection_results": ["3-9", "10-19"], "frames": [{"frame-number": 4, "label": "FACE_MALE", "score": 0.95, "age": "3-9", "age_confidence": 0.65}, {"frame-number": 100, "label": "FACE_FEMALE", "score": 0.81, "age": "10-19", "age_confidence": 0.75}]}}
    ai_results_failure: {"type": "object", "required": ["error"], "properties": {"error": {"type": "string"}}, "example": {"error": "Unsupported file type: https://domain.com/video.zip"}}
    ai_post_response_result: {"type": "object", "properties": {"result": {"type": "string", "description": "A textual explicit description of the result of the operation"}}, "example": {"result": "Task has been cancelled successfully."}}
    ai_post_response_error404: {"allOf": ["$ref": "#/components/schemas/ai_post_response_error"], "example": {"error": "Task not found"}}
    ai_post_response_error: {"type": "object", "properties": {"error": {"type": "string", "description": "A textual explicit description of the operation execution error, if something went wrong"}}, "example": {"error": "Cannot cancel task because it is already in status REVOKED."}}
    ai_response_info_language: {"type": "object", "properties": {"supported": {"type": "boolean", "description": "Is the given language pair supported for transcription and translation?"}}, "example": {"supported": true}}
    ai_badrequest: {"type": "object", "properties": {"error": {"type": "string", "description": "Error message"}}, "example": {"error": "Invalid config type"}}
    cdn_uniqs: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["uniqs", "type"], "properties": {"uniqs": {"type": "integer"}, "type": {"type": "string"}}}}}, "example": {"data": [{"uniqs": 100, "type": "vod"}, {"uniqs": 300, "type": "live"}]}}
    error_common: {"required": ["data", "errors"], "type": "object", "properties": {"data": {"type": "array", "items": {"type": "string"}}, "errors": {"type": "array", "items": {"type": "string"}}}}
    views: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "date", "type"], "properties": {"views": {"type": "integer"}, "date": {"type": "string"}, "type": {"type": "string"}, "host": {"type": "string"}, "os": {"type": "string"}, "browser": {"type": "string"}, "platform": {"type": "string"}, "ip": {"type": "string"}, "country": {"type": "string"}, "event": {"type": "string"}, "id": {"type": "integer"}}}}}, "example": {"data": [{"views": 1000, "date": "2024-05-01", "type": "vod"}, {"views": 2000, "date": "2024-05-02", "type": "vod"}, {"views": 1000, "date": "2024-05-01", "type": "live"}]}}
    uniqs: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["unique_ips", "date"], "properties": {"unique_ips": {"type": "integer"}, "date": {"type": "string"}, "type": {"type": "string"}, "host": {"type": "string"}, "os": {"type": "string"}, "browser": {"type": "string"}, "platform": {"type": "string"}, "ip": {"type": "string"}, "country": {"type": "string"}, "event": {"type": "string"}, "id": {"type": "integer"}}}}}, "example": {"data": [{"unique_ips": 100, "date": "2022-10-15", "type": "vod"}, {"unique_ips": 300, "date": "2022-10-15", "type": "live"}]}}
    countries: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "country", "country_name"], "properties": {"views": {"type": "integer"}, "country": {"type": "string"}, "country_name": {"type": "string"}}}}}, "example": {"data": [{"views": 100500, "country": "AU", "country_name": "Australia"}, {"views": 3000, "country": "US", "country_name": "United States"}]}}
    regions: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "region", "region_name"], "properties": {"views": {"type": "integer"}, "region": {"type": "string"}, "region_name": {"type": "string"}}}}}, "example": {"data": [{"views": 100500, "region": "ACT", "region_name": "Australian Capital Territory"}, {"views": 3000, "region": "SA", "region_name": "South Australia"}]}}
    popular: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "id"], "properties": {"views": {"type": "integer"}, "id": {"type": "string"}}}}}, "example": {"data": [{"views": 100500, "id": 12345}, {"views": 3000, "id": 65432}]}}
    browsers: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "browser"], "properties": {"views": {"type": "integer"}, "browser": {"type": "string"}}}}}, "example": {"data": [{"views": 100500, "browser": "Chrome Mobile iOS"}, {"views": 3000, "browser": "Mobile Safari"}]}}
    systems: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "os"], "properties": {"views": {"type": "integer"}, "os": {"type": "string"}}}}}, "example": {"data": [{"views": 100500, "os": "Windows"}, {"views": 3000, "os": "Android"}]}}
    embeds: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "embed_url"], "properties": {"views": {"type": "integer"}, "embed_url": {"type": "string"}}}}}, "example": {"data": [{"views": 100500, "embed_url": "https://example.com/xxx-yyy"}, {"views": 3000, "embed_url": "https://example.com/xxx-zzz"}]}}
    hosts: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["views", "host"], "properties": {"views": {"type": "integer"}, "host": {"type": "string"}}}}}, "example": {"data": [{"views": 100500, "embed_url": "example.com"}, {"views": 3000, "embed_url": "simple.com"}]}}
    heatmap: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["viewers"], "properties": {"viewers": {"type": "integer"}, "seconds": {"type": "integer"}, "time": {"type": "string"}}}}}, "example": {"data": [{"viewers": 100500, "seconds": 500}, {"viewers": 3000, "seconds": 1000}]}}
    ffprobe: {"type": "object", "properties": {"data": {"type": "array", "items": {"type": "object", "required": ["time", "avg_bitrate", "sum_frames", "max_height", "max_fps", "max_keyframe_interval"], "properties": {"time": {"type": "string"}, "avg_bitrate": {"type": "number"}, "sum_frames": {"type": "integer"}, "max_height": {"type": "integer"}, "max_fps": {"type": "number"}, "max_keyframe_interval": {"type": "integer"}}}}}, "example": {"data": [{"time": "2006-01-02 15:04:05", "avg_bitrate": 3500.5, "sum_frames": 500, "max_height": 1080, "max_fps": 25, "max_keyframe_interval": 1}]}}
    streamstat: {"type": "array", "items": {"type": "object", "required": ["client", "metrics"], "properties": {"client": {"type": "integer"}, "metrics": {"type": "object", "required": ["streams"], "properties": {"streams": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of transcoding minutes"}}}}}}, "example": [{"client": 123, "metrics": {"streams": [[1640995210, 10], [1640995310, 10], [1640995410, 10], [1640995510, 20], [1640995610, 20]]}}]}
    max_stream: {"type": "array", "items": {"type": "object", "required": ["client", "metrics"], "properties": {"client": {"type": "integer"}, "metrics": {"type": "object", "required": ["streams"], "properties": {"streams": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of transcoding minutes"}}}}}}, "example": [{"client": 123, "metrics": {"streams": [[1640995210, 10], [1640995310, 10], [1640995410, 10], [1640995510, 20], [1640995610, 20]]}}]}
    storage: {"type": "array", "items": {"type": "object", "required": ["client", "metrics"], "properties": {"client": {"type": "integer"}, "metrics": {"type": "object", "required": ["storage", "max_volume_usage"], "properties": {"storage": {"type": "array", "items": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of byte"}}}, "max_volume_usage": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of byte"}}}}}}, "example": [{"client": 123, "metrics": {"storage": [[1640995210, 10000000000], [1640995310, 12000000000], [1640995410, 16000000000], [1640995510, 20000000000], [1640995610, 10000000000]], "max_volume_usage": [1640995510, 20000000000]}}]}
    meet: {"type": "array", "items": {"type": "object", "required": ["client", "metrics"], "properties": {"client": {"type": "integer"}, "metrics": {"type": "object", "required": ["storage", "max_volume_usage"], "properties": {"meet": {"type": "array", "items": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of byte"}}}, "max_meet_usage": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of byte"}}}}}}, "example": [{"client": 123, "metrics": {"meet": [[1640995210, 10], [1640995310, 120], [1640995410, 130], [1640995510, 200], [1640995610, 100]], "max_meet_usage": [1640995510, 200]}}]}
    vod_stat: {"type": "array", "items": {"type": "object", "required": ["client", "metrics"], "properties": {"client": {"type": "integer"}, "metrics": {"type": "object", "required": ["vod"], "properties": {"vod": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of transcoding minutes"}}}}}}, "example": [{"client": 123, "metrics": {"vod": [[1640995210, 10], [1640995310, 10], [1640995410, 10], [1640995510, 20], [1640995610, 20]]}}]}
    vod_watching_total: {"type": "array", "items": {"type": "object", "required": ["client", "duration"], "properties": {"client": {"type": "integer"}, "duration": {"type": "integer", "format": "int64", "description": "count of minutes"}, "slug": {"type": "string"}, "client_user_id": {"type": "integer"}}}, "example": [{"client": 123, "client_user_id": 102, "duration": 1000}]}
    stream_stat: {"type": "array", "items": {"type": "object", "required": ["client", "metrics"], "properties": {"client": {"type": "integer"}, "metrics": {"type": "object", "required": ["streams"], "properties": {"streams": {"type": "array", "items": {"type": "integer", "format": "int64", "description": "first value in array is timestamp, second is count of transcoding minutes"}}}}}}, "example": [{"client": 123, "metrics": {"streams": [[1640995210, 10], [1640995310, 10], [1640995410, 10], [1640995510, 20], [1640995610, 20]]}}]}
    stream_watching_total: {"type": "array", "items": {"type": "object", "required": ["client", "duration"], "properties": {"client": {"type": "integer"}, "duration": {"type": "integer", "format": "int64", "description": "count of minutes"}, "stream_id": {"type": "string"}, "client_user_id": {"type": "integer"}}}, "example": [{"client": 123, "client_user_id": 102, "duration": 1000}]}
  requestBodies:
    playlist: {"content": {"application/json": {"schema": {"allOf": ["$ref": "#/components/schemas/playlist"]}}}}
  responses:
    error_bad_request: {"description": "Bad Request", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/error_common"}, "examples": {"missingParam": {"summary": "Missing query param", "value": {"data": [], "errors": ["from: query param is not set"]}}}}}}
    error_internal_server: {"description": "Internal Server Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/error_common"}, "examples": {"internalServerError": {"summary": "Internal Server Error", "value": {"data": [], "errors": ["internal server error"]}}}}}}
  securitySchemes: {"APIKey": {"description": "API key for authentication.", "type": "http", "scheme": "APIKey", "in": "header"}}
