---
title: "How to migrate data from S3 and EFS to Gcore"
description: "This guide explains how to migrate your data from Amazon S3 or EFS to Gcore with the help of rclone."
---

Gcore offers powerful storage solutions compatible with [S3](https://gcore.com/docs/storage) and [NFS](https://gcore.com/docs/cloud/file-shares/about-file-shares).

This guide explains how to migrate your data from Amazon S3 or EFS to Gcore with the help of [rclone](https://rclone.org/), a popular CLI tool for cloud storage management.

<Info>
  **AWS bills outgoing traffic**. If you want to migrate a large amount of data, [check the transfer costs first](https://calculator.aws/#/createCalculator/DataTransfer)\!
</Info>

## Migrate data from S3 to Gcore

### Gcore Object storage

If you want to keep processes as close as possible to your AWS infrastructure, [Gcore object storage](https://gcore.com/docs/storage) is a good choice for the migration.

Following this guide requires a Linux machine with **public Internet access installed with rclone**.

#### Step 1. Collect AWS account credentials

You can use your AWS CLI user or create a new one via IAM, but **ensure the user has read access to your source bucket**.

You need the following AWS credentials and bucket details:

- Access key ID
- Secret access key
- Target bucket region
- Target bucket name

#### Step 2. Create a Gcore object storage bucket

Create a new object storage bucket. Follow [this guide](https://gcore.com/docs/storage/create-an-s3-or-sftp-storage) to learn how. At the end of this process, you’ll get the following Gcore credentials and bucket details required for the migration:

- Access key ID
- Secret access key
- Hostname/endpoint
- Destination bucket name

#### Step 3. Configure rclone remotes

Add rclone remotes for AWS and Gcore to your rclone config at:

```sh
~/.config/rclone/rclone.conf
```

Add the following remote configurations to the file and replace the placeholders with the information from the previous steps.

```ini
[aws-s3]
type = s3
provider = AWS
access_key_id = <AWS_ACCESS_KEY_ID>
secret_access_key = <AWS_SECRET_ACCESS_KEY>
region = <AWS_REGION>
acl = private

[gcore-os]
type = s3
provider = Other
access_key_id = <GCORE_ACCESS_KEY_ID>
secret_access_key = <GCORE_SECRET_ACCESS_KEY>
endpoint = <GCORE_STORAGE_ENPOINT>
acl = private
```

#### Step 4. Migrate the data

Run the following rclone command to migrate your data from S3 to Gcore Storage:

```sh
rclone sync aws-s3://<SOURCE_BUCKET> gcore-os://<DESTINATION_BUCKET>
```

Replace the `SOURCE_BUCKET` with the name of your Amazon S3 bucket and the `DESTINATION_BUCKET` with the name of the Gcore object storage bucket.

### Gcore file share (NFS)

If you want to use the data from S3 via NFS mounts inside an instance or a container, consider [Gcore file shares](https://gcore.com/docs/cloud/file-shares/about-file-shares).

Following this guide **requires a Gcore instance with access to the public Internet**. It should have Linux and rclone installed.

#### Step 1. Collect  AWS account credentials

You can use your AWS CLI user or create a new one via IAM, but **ensure the user has read access to your source bucket**.

You need the following AWS credentials and bucket details:

- Access key ID
- Secret access key
- Bucket region
- Bucket name

#### Step 2. Create and mount a Gcore file share

Create a new file share, as explained in [this guide](https://gcore.com/docs/cloud/file-shares/configure-file-shares). At the end of this process, you should have the mount path of your file share.

#### Step 3. Configure rclone remote

Add the rclone remote for AWS to your rclone config at:

```sh
~/.config/rclone/rclone.conf
```

Add the following remote configurations to the file, using the information from the previous steps instead of the placeholders.

```ini
[aws-s3]
type = s3
provider = AWS
access_key_id = <AWS_ACCESS_KEY_ID>
secret_access_key = <AWS_SECRET_ACCESS_KEY>
region = <AWS_REGION>
acl = private
```

#### Step 4. Migrate the data

Run the rclone sync command to migrate your data from S3 to a file share:

```sh
rclone sync aws-s3://<SOURCE_BUCKET> <DESTINATION_PATH>
```

Replace the `SOURCE_BUCKET` with the name of your Amazon S3 bucket and the `DESTINATION_PATH` with the Gcore file share mount path from Step 2.

## Migrate data from EFS to Gcore

### Gcore object storage

Migrate your data from Amazon EFS to Gcore object storage for backup.

Following this guide **requires an EC2 instance with access to the EFS** you want to back up and public Internet access. It needs to have Linux and [rclone](https://rclone.org/install/) installed.

#### Step 1. Create a Gcore object storage bucket

Create a new object storage bucket, as explained in [this guide](https://gcore.com/docs/storage/create-an-s3-or-sftp-storage). At the end of this process, you’ll get the following required info:

- Access key ID
- Secret access key
- Hostname/endpoint
- Bucket name

#### Step 2. Configure rclone remote

Add the rclone remotes for Gcore to your rclone config at:

```sh
~/.config/rclone/rclone.conf
```

Add the following remote configurations to the file, using the credentials from the previous steps instead of the placeholders.

```ini
[gcore-os]
type = s3
provider = Other
access_key_id = <GCORE_ACCESS_KEY_ID>
secret_access_key = <GCORE_SECRET_ACCESS_KEY>
endpoint = <GCORE_STORAGE_ENPOINT>
acl = private
```

#### Step 4. Migrate the data

Run the following rclone command to migrate your data from S3 to Gcore Storage:

```sh
rclone sync <SOURCE_PATH> gcore-os://<DESTINATION_BUCKET>
```

Replace the `SOURCE_PATH` with your Amazon EFS mount path, and the `DESTINATION_BUCKET` with the Gcore object storage bucket name you created in the previous step.

### Gcore file share (NFS)

Because Gcore files shares and Amazon EFS are private to their cloud providers' infrastructure, you can’t easily move data directly between them. This guide explains how to do it with Gcore object storage. So, before you move on, **follow all the steps from the “object storage” section above** to get your data into a Gcore object storage bucket.

Following this guide **requires a Gcore instance with access to the public Internet**. It should have Linux and rclone installed.

#### Step 1. Create and mount a Gcore file share

Create a new file share, as explained in [this guide](https://gcore.com/docs/cloud/file-shares/configure-file-shares). At the end of this process, you should have the mount path of your file share.

#### Step 2. Configure rclone

Next, add the rclone remote for Gcore to your rclone config at:

```sh
~/.config/rclone/rclone.conf
```

Add the following remote configurations to the file, using the credentials from the previous section instead of the placeholders.

```ini
[gcore-os]
type = s3
provider = Other
access_key_id = <GCORE_ACCESS_KEY_ID>
secret_access_key = <GCORE_SECRET_ACCESS_KEY>
endpoint = <GCORE_STORAGE_ENPOINT>
acl = private
```

#### Step 3. Migrate the data

Run the following rclone command to move your data from Gcore Storage to a Gcore file share:

```sh
rclone sync gcore-os://<SOURCE_BUCKET> <DESTINATION_PATH>
```

Replace the `SOURCE_BUCKET` with the name of your Gcore object storage bucket and the `DESTINATION_PATH` with the Gcore file share mount path from the previous step.