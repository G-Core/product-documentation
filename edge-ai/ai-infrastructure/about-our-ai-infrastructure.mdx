---
title: GPU cloud infrastructure
sidebarTitle: About GPU cloud
---

Gcore [GPU Cloud](https://gcore.com/cloud/ai-gpu) provides high-performance compute clusters designed for machine learning tasks.

## AI GPU infrastructure

Train your ML models with the latest [NVIDIA GPUs](https://www.nvidia.com/en-us/data-center/data-center-gpus/). We offer a wide range of Bare Metal servers and Virtual Machines powered by NVIDIA A100, H100, and L40S GPUs.

Pick the configuration and reservation plan that best fits your computing requirements.

| **Specification**          | **Characteristics**                                                                                                                 | **Use case**                                                                                                          | **Performance**                                                                                                           |
|----------------------------|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| H100 with Infiniband   | - 8x Nvidia H100 80GB<br/>- 2 Intel Xeon 8480+<br/>- 2TB RAM<br/>- 2x 960GB<br/>- 8x 3.84 TB NVMe<br/>- 3.2 Tbit/s Infiniband<br/>- 2x100Gbit/s Ethernet | Optimized for distributed training of Large Language Models.                                                           | Ultimate performance for compute-intensive tasks that require a significant exchange of data by the network.              |
| bm3‑ai‑ndp<wbr/>‑1xlarge‑h100‑80‑8   | - 8× Nvidia H100 80 GB<br />- 2× Intel Xeon 8480+<br/>- 2 TB RAM; 2× 1.92 TB NVMe SSD<br/>- 6× 3.84 TB NVMe SSD<br/>- 3.2 Tbit/s Infiniband<br/>- 2× 25 Gbit/s Ethernet | Distributed training of large language models and latency‑sensitive inference at scale.                                                           | Peak throughput for high‑speed multi‑node workloads.              |
| A100 with Infiniband   | - 8x Nvidia A100 80GB<br/>- 2 Intel Xeon 8468<br/>- 2TB RAM<br/>- 2x 960GB SSD<br/>- 8x 3.84 TB NVMe<br/>- 800Gbit/s Infiniband           | Distributed training for ML models and a broad range of HPC workloads.                                                | Well-balanced in performance and price.                                                                                   |
| A100 without Infiniband | - 8x Nvidia A100 80GB<br/>- 2 Intel Xeon 8468<br/>- 2TB RAM<br/>- 2x 960GB SSD<br/>- 8x 3.84 TB NVMe<br/>- 2x100Gbit/s Ethernet           | Training and fine-tuning of models on single nodes.<br/><br/>Inference for large models.<br/>Multi-user HPC cluster.     | The best solution for inference models that require more than 48GB vRAM.                                                  |
| L40                    | - 8x Nvidia L40S<br/>- 2x Intel Xeon 8468<br/>- 2TB RAM<br/>- 4x 7.68TB NVMe SSD<br/>- 2x25Gbit/s Ethernet                               | Model inference.<br/><br/>Fine-tuning for small and medium-size models.                                                 | The best solution for inference models that require less than 48GB vRAM.                                                  |

  
Explore our competitive pricing on the [AI GPU Cloud infrastructure pricing page](https://gcore.com/cloud/ai-gpu).

## Tools supported by GCore GPU cloud

**Tool class** | **List of tools** | **Explanation**  
---|---|---  
Framework | TensorFlow, Keras, PyTorch, Paddle Paddle, ONNX, Hugging Face | Your model is supposed to use one of these frameworks for correct work.  
Data platforms | PostgreSQL, Hadoop, Spark, Vertika | You can set up a connection between our cluster and your data platforms of these types to make them work together.  
Programming languages | JavaScript, R, Swift, Python | Your model is supposed to be written in one of these languages for correct work.  
Resources for receiving and processing data | Storm, Spark, Kafka, PySpark, MS SQL, Oracle, MongoDB | You can set up a connection between our cluster and your resources of these types to make them work together.  
Exploration and visualization tools | Seaborn, Matplotlib, TensorBoard | You can connect our cluster to these tools to visualize your model.